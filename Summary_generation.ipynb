{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "from imports import *\n",
    "import clean_data_loader as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"amazon_dataset/Reviews.csv\")\n",
    "reviews = reviews.dropna()\n",
    "reviews = reviews.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Score','Time'], 1)\n",
    "reviews = reviews.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unclean_summaries=reviews.Summary\n",
    "unclean_texts=reviews.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import preprocessing as pre\n",
    "\n",
    "def text_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    \n",
    "    text = pre.clean_text(text) #for any new summary use clean... if already cleaned then skip\n",
    "    \n",
    "    return [cl.vocab_to_int.get(word, cl.vocab_to_int['<UNK>']) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANDOM\t=\t= 18366\n",
      "\n",
      "\n",
      "RANDOM CHOSEN REVIEW - UNCLEANED - \t=\t love the oat meal cooking in cool water add spices eat, will buy again add ripe banana good needs no sugar\n",
      "\n",
      "ORIGINAL SUMMARY OF THE ABOVE REVIEW - UNCLEANED - \t=\t VERY TASTY  WITH ADDED SPICE\n",
      "\n",
      "\n",
      "RANDOM CHOSEN REVIEW - CLEANED - \t=\t love oat meal cooking cool water add spices eat buy add ripe banana good needs sugar\n",
      "\n",
      "ORIGINAL SUMMARY OF THE ABOVE REVIEW - CLEANED - \t=\t very tasty with added spice\n",
      "INFO:tensorflow:Restoring parameters from ./model_checkpoints/LSTM_BI_ATTN/best_model.ckpt\n",
      "  GENERATED SUMMARY\t=\t: great tasting add meal\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(10,500000)\n",
    "input_sentence = cl.clean_texts[random]\n",
    "inp_summ=cl.clean_summaries[random]\n",
    "\n",
    "text_int = text_to_seq(input_sentence)\n",
    "\n",
    "print (\"\\nRANDOM\\t=\\t=\",random)\n",
    "\n",
    "print (\"\\n\\nRANDOM CHOSEN REVIEW - UNCLEANED - \\t=\\t\",unclean_texts[random])\n",
    "print (\"\\nORIGINAL SUMMARY OF THE ABOVE REVIEW - UNCLEANED - \\t=\\t\",unclean_summaries[random])\n",
    "\n",
    "print (\"\\n\\nRANDOM CHOSEN REVIEW - CLEANED - \\t=\\t\",input_sentence)\n",
    "print (\"\\nORIGINAL SUMMARY OF THE ABOVE REVIEW - CLEANED - \\t=\\t\",inp_summ)\n",
    "\n",
    "#checkpoint = \"./best_model.ckpt\"\n",
    "\n",
    "checkpoint ='./model_checkpoints/LSTM_BI_ATTN/best_model.ckpt'\n",
    "batch_size=32\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    # The input tensors for inference\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    inference_logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    source_seq_len = loaded_graph.get_tensor_by_name('source_seq_len:0')\n",
    "    target_seq_len = loaded_graph.get_tensor_by_name('target_seq_len:0')\n",
    "    keep_probability = loaded_graph.get_tensor_by_name('keep_probability:0')\n",
    "\n",
    "    # Run the graph to get the summary logits\n",
    "    summary_logits = sess.run(inference_logits, { input_data: [text_int] * batch_size,\n",
    "                                                  target_seq_len: [np.random.randint(5,8)],\n",
    "                                                  source_seq_len: [len(text_int)] * batch_size,\n",
    "                                                  keep_probability: 1.0\n",
    "                                                })\n",
    "    # This returns a batch_size - length matrix of logits, so we just need the first one\n",
    "    summary_logits = summary_logits[0]\n",
    "    \n",
    "pad = cl.vocab_to_int[\"<PAD>\"] \n",
    "\n",
    "\n",
    "print('  GENERATED SUMMARY\\t=\\t: {}'.format(\" \".join([cl.int_to_vocab[i] for i in summary_logits if i != pad])))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
