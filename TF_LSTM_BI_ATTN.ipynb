{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import clean_data_loader as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from imports import *\n",
    "import tensorflow_code as tc\n",
    "\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "from tensorflow.contrib.rnn import GRUCell, LSTMCell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######\n",
      "Training Bidirectional / LSTMCell / Attention\n",
      "#######\n",
      "BIDRECTIONAL ENCODER\n",
      "ENCODER BASE CELL IS LSTM\n",
      "DECODER BASE CELL LSTM\n",
      "DECODER ATTENTOIN IS TRUE\n",
      "Epoch   1/100 Batch   20/1562 - Loss:  5.533, Seconds: 3.89\n",
      "Epoch   1/100 Batch   40/1562 - Loss:  3.241, Seconds: 3.48\n",
      "Epoch   1/100 Batch   60/1562 - Loss:  3.231, Seconds: 3.08\n",
      "Epoch   1/100 Batch   80/1562 - Loss:  3.146, Seconds: 2.87\n",
      "Epoch   1/100 Batch  100/1562 - Loss:  3.037, Seconds: 3.50\n",
      "Epoch   1/100 Batch  120/1562 - Loss:  3.089, Seconds: 3.13\n",
      "Epoch   1/100 Batch  140/1562 - Loss:  3.173, Seconds: 3.32\n",
      "Epoch   1/100 Batch  160/1562 - Loss:  3.129, Seconds: 2.91\n",
      "Epoch   1/100 Batch  180/1562 - Loss:  3.131, Seconds: 3.76\n",
      "Epoch   1/100 Batch  200/1562 - Loss:  3.008, Seconds: 3.14\n",
      "Epoch   1/100 Batch  220/1562 - Loss:  3.123, Seconds: 3.14\n",
      "Epoch   1/100 Batch  240/1562 - Loss:  3.130, Seconds: 2.87\n",
      "Epoch   1/100 Batch  260/1562 - Loss:  2.943, Seconds: 4.14\n",
      "Epoch   1/100 Batch  280/1562 - Loss:  2.911, Seconds: 3.30\n",
      "Epoch   1/100 Batch  300/1562 - Loss:  2.863, Seconds: 4.14\n",
      "Average loss for this update: 3.239 -- New Record!\n",
      "Epoch   1/100 Batch  320/1562 - Loss:  2.875, Seconds: 3.54\n",
      "Epoch   1/100 Batch  340/1562 - Loss:  2.957, Seconds: 3.29\n",
      "Epoch   1/100 Batch  360/1562 - Loss:  2.933, Seconds: 3.88\n",
      "Epoch   1/100 Batch  380/1562 - Loss:  2.877, Seconds: 2.85\n",
      "Epoch   1/100 Batch  400/1562 - Loss:  2.858, Seconds: 4.13\n",
      "Epoch   1/100 Batch  420/1562 - Loss:  2.849, Seconds: 3.52\n",
      "Epoch   1/100 Batch  440/1562 - Loss:  3.167, Seconds: 3.42\n",
      "Epoch   1/100 Batch  460/1562 - Loss:  2.809, Seconds: 3.14\n",
      "Epoch   1/100 Batch  480/1562 - Loss:  2.897, Seconds: 3.54\n",
      "Epoch   1/100 Batch  500/1562 - Loss:  2.988, Seconds: 3.75\n",
      "Epoch   1/100 Batch  520/1562 - Loss:  2.917, Seconds: 4.22\n",
      "Epoch   1/100 Batch  540/1562 - Loss:  2.958, Seconds: 3.12\n",
      "Epoch   1/100 Batch  560/1562 - Loss:  2.953, Seconds: 3.56\n",
      "Epoch   1/100 Batch  580/1562 - Loss:  2.631, Seconds: 3.58\n",
      "Epoch   1/100 Batch  600/1562 - Loss:  2.711, Seconds: 3.43\n",
      "Epoch   1/100 Batch  620/1562 - Loss:  2.734, Seconds: 3.76\n",
      "Average loss for this update: 2.872 -- New Record!\n",
      "Epoch   1/100 Batch  640/1562 - Loss:  2.809, Seconds: 3.40\n",
      "Epoch   1/100 Batch  660/1562 - Loss:  2.751, Seconds: 3.55\n",
      "Epoch   1/100 Batch  680/1562 - Loss:  2.680, Seconds: 4.12\n",
      "Epoch   1/100 Batch  700/1562 - Loss:  2.938, Seconds: 3.23\n",
      "Epoch   1/100 Batch  720/1562 - Loss:  3.117, Seconds: 3.96\n",
      "Epoch   1/100 Batch  740/1562 - Loss:  2.994, Seconds: 3.74\n",
      "Epoch   1/100 Batch  760/1562 - Loss:  2.970, Seconds: 2.96\n",
      "Epoch   1/100 Batch  780/1562 - Loss:  2.878, Seconds: 4.28\n",
      "Epoch   1/100 Batch  800/1562 - Loss:  2.748, Seconds: 3.39\n",
      "Epoch   1/100 Batch  820/1562 - Loss:  2.893, Seconds: 3.82\n",
      "Epoch   1/100 Batch  840/1562 - Loss:  2.648, Seconds: 3.58\n",
      "Epoch   1/100 Batch  860/1562 - Loss:  2.636, Seconds: 3.59\n",
      "Epoch   1/100 Batch  880/1562 - Loss:  2.442, Seconds: 3.16\n",
      "Epoch   1/100 Batch  900/1562 - Loss:  2.712, Seconds: 4.05\n",
      "Epoch   1/100 Batch  920/1562 - Loss:  2.684, Seconds: 3.40\n",
      "Average loss for this update: 2.791 -- New Record!\n",
      "Epoch   1/100 Batch  940/1562 - Loss:  2.656, Seconds: 3.20\n",
      "Epoch   1/100 Batch  960/1562 - Loss:  2.812, Seconds: 3.82\n",
      "Epoch   1/100 Batch  980/1562 - Loss:  2.916, Seconds: 3.87\n",
      "Epoch   1/100 Batch 1000/1562 - Loss:  2.904, Seconds: 3.64\n",
      "Epoch   1/100 Batch 1020/1562 - Loss:  2.766, Seconds: 3.26\n",
      "Epoch   1/100 Batch 1040/1562 - Loss:  2.898, Seconds: 3.64\n",
      "Epoch   1/100 Batch 1060/1562 - Loss:  2.774, Seconds: 3.43\n",
      "Epoch   1/100 Batch 1080/1562 - Loss:  2.763, Seconds: 4.25\n",
      "Epoch   1/100 Batch 1100/1562 - Loss:  2.772, Seconds: 3.29\n",
      "Epoch   1/100 Batch 1120/1562 - Loss:  2.654, Seconds: 3.73\n",
      "Epoch   1/100 Batch 1140/1562 - Loss:  2.622, Seconds: 3.67\n",
      "Epoch   1/100 Batch 1160/1562 - Loss:  2.723, Seconds: 3.50\n",
      "Epoch   1/100 Batch 1180/1562 - Loss:  2.593, Seconds: 3.03\n",
      "Epoch   1/100 Batch 1200/1562 - Loss:  2.791, Seconds: 4.04\n",
      "Epoch   1/100 Batch 1220/1562 - Loss:  2.697, Seconds: 3.41\n",
      "Epoch   1/100 Batch 1240/1562 - Loss:  2.579, Seconds: 3.61\n",
      "Average loss for this update: 2.745 -- New Record!\n",
      "Epoch   1/100 Batch 1260/1562 - Loss:  2.833, Seconds: 3.47\n",
      "Epoch   1/100 Batch 1280/1562 - Loss:  2.923, Seconds: 3.94\n",
      "Epoch   1/100 Batch 1300/1562 - Loss:  2.930, Seconds: 3.34\n",
      "Epoch   1/100 Batch 1320/1562 - Loss:  2.909, Seconds: 3.96\n",
      "Epoch   1/100 Batch 1340/1562 - Loss:  2.758, Seconds: 3.50\n",
      "Epoch   1/100 Batch 1360/1562 - Loss:  2.806, Seconds: 3.72\n",
      "Epoch   1/100 Batch 1380/1562 - Loss:  2.712, Seconds: 3.85\n",
      "Epoch   1/100 Batch 1400/1562 - Loss:  2.580, Seconds: 3.87\n",
      "Epoch   1/100 Batch 1420/1562 - Loss:  2.724, Seconds: 3.32\n",
      "Epoch   1/100 Batch 1440/1562 - Loss:  2.686, Seconds: 3.70\n",
      "Epoch   1/100 Batch 1460/1562 - Loss:  2.612, Seconds: 3.90\n",
      "Epoch   1/100 Batch 1480/1562 - Loss:  2.376, Seconds: 3.91\n",
      "Epoch   1/100 Batch 1500/1562 - Loss:  2.598, Seconds: 3.66\n",
      "Epoch   1/100 Batch 1520/1562 - Loss:  2.641, Seconds: 4.33\n",
      "Epoch   1/100 Batch 1540/1562 - Loss:  2.885, Seconds: 3.74\n",
      "Average loss for this update: 2.74 -- New Record!\n",
      "Epoch   1/100 Batch 1560/1562 - Loss:  2.792, Seconds: 3.95\n",
      "Epoch   2/100 Batch   20/1562 - Loss:  2.806, Seconds: 3.85\n",
      "Epoch   2/100 Batch   40/1562 - Loss:  2.414, Seconds: 3.44\n",
      "Epoch   2/100 Batch   60/1562 - Loss:  2.579, Seconds: 3.01\n",
      "Epoch   2/100 Batch   80/1562 - Loss:  2.554, Seconds: 2.86\n",
      "Epoch   2/100 Batch  100/1562 - Loss:  2.428, Seconds: 3.46\n",
      "Epoch   2/100 Batch  120/1562 - Loss:  2.506, Seconds: 3.10\n",
      "Epoch   2/100 Batch  140/1562 - Loss:  2.584, Seconds: 3.36\n",
      "Epoch   2/100 Batch  160/1562 - Loss:  2.541, Seconds: 2.93\n",
      "Epoch   2/100 Batch  180/1562 - Loss:  2.571, Seconds: 3.71\n",
      "Epoch   2/100 Batch  200/1562 - Loss:  2.448, Seconds: 3.08\n",
      "Epoch   2/100 Batch  220/1562 - Loss:  2.548, Seconds: 3.07\n",
      "Epoch   2/100 Batch  240/1562 - Loss:  2.563, Seconds: 2.89\n",
      "Epoch   2/100 Batch  260/1562 - Loss:  2.471, Seconds: 4.11\n",
      "Epoch   2/100 Batch  280/1562 - Loss:  2.381, Seconds: 3.33\n",
      "Epoch   2/100 Batch  300/1562 - Loss:  2.314, Seconds: 4.08\n",
      "Average loss for this update: 2.512 -- New Record!\n",
      "Epoch   2/100 Batch  320/1562 - Loss:  2.349, Seconds: 3.60\n",
      "Epoch   2/100 Batch  340/1562 - Loss:  2.439, Seconds: 3.26\n",
      "Epoch   2/100 Batch  360/1562 - Loss:  2.441, Seconds: 3.89\n",
      "Epoch   2/100 Batch  380/1562 - Loss:  2.310, Seconds: 2.84\n",
      "Epoch   2/100 Batch  400/1562 - Loss:  2.334, Seconds: 4.12\n",
      "Epoch   2/100 Batch  420/1562 - Loss:  2.403, Seconds: 3.61\n",
      "Epoch   2/100 Batch  440/1562 - Loss:  2.638, Seconds: 3.37\n",
      "Epoch   2/100 Batch  460/1562 - Loss:  2.313, Seconds: 3.13\n",
      "Epoch   2/100 Batch  480/1562 - Loss:  2.383, Seconds: 3.56\n",
      "Epoch   2/100 Batch  500/1562 - Loss:  2.512, Seconds: 3.77\n",
      "Epoch   2/100 Batch  520/1562 - Loss:  2.410, Seconds: 4.21\n",
      "Epoch   2/100 Batch  540/1562 - Loss:  2.427, Seconds: 3.11\n",
      "Epoch   2/100 Batch  560/1562 - Loss:  2.431, Seconds: 3.48\n",
      "Epoch   2/100 Batch  580/1562 - Loss:  2.093, Seconds: 3.63\n",
      "Epoch   2/100 Batch  600/1562 - Loss:  2.138, Seconds: 3.37\n",
      "Epoch   2/100 Batch  620/1562 - Loss:  2.213, Seconds: 3.79\n",
      "Average loss for this update: 2.356 -- New Record!\n",
      "Epoch   2/100 Batch  640/1562 - Loss:  2.303, Seconds: 3.37\n",
      "Epoch   2/100 Batch  660/1562 - Loss:  2.202, Seconds: 3.56\n",
      "Epoch   2/100 Batch  680/1562 - Loss:  2.175, Seconds: 4.12\n",
      "Epoch   2/100 Batch  700/1562 - Loss:  2.387, Seconds: 3.17\n",
      "Epoch   2/100 Batch  720/1562 - Loss:  2.670, Seconds: 4.01\n",
      "Epoch   2/100 Batch  740/1562 - Loss:  2.547, Seconds: 3.74\n",
      "Epoch   2/100 Batch  760/1562 - Loss:  2.487, Seconds: 3.00\n",
      "Epoch   2/100 Batch  780/1562 - Loss:  2.419, Seconds: 4.26\n",
      "Epoch   2/100 Batch  800/1562 - Loss:  2.289, Seconds: 3.43\n",
      "Epoch   2/100 Batch  820/1562 - Loss:  2.421, Seconds: 3.84\n",
      "Epoch   2/100 Batch  840/1562 - Loss:  2.213, Seconds: 3.67\n",
      "Epoch   2/100 Batch  860/1562 - Loss:  2.185, Seconds: 3.68\n",
      "Epoch   2/100 Batch  880/1562 - Loss:  1.951, Seconds: 3.20\n",
      "Epoch   2/100 Batch  900/1562 - Loss:  2.216, Seconds: 3.96\n",
      "Epoch   2/100 Batch  920/1562 - Loss:  2.242, Seconds: 3.36\n",
      "Average loss for this update: 2.312 -- New Record!\n",
      "Epoch   2/100 Batch  940/1562 - Loss:  2.157, Seconds: 3.23\n",
      "Epoch   2/100 Batch  960/1562 - Loss:  2.309, Seconds: 3.83\n",
      "Epoch   2/100 Batch  980/1562 - Loss:  2.472, Seconds: 3.92\n",
      "Epoch   2/100 Batch 1000/1562 - Loss:  2.463, Seconds: 3.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2/100 Batch 1020/1562 - Loss:  2.328, Seconds: 3.34\n",
      "Epoch   2/100 Batch 1040/1562 - Loss:  2.458, Seconds: 3.72\n",
      "Epoch   2/100 Batch 1060/1562 - Loss:  2.309, Seconds: 3.41\n",
      "Epoch   2/100 Batch 1080/1562 - Loss:  2.300, Seconds: 4.30\n",
      "Epoch   2/100 Batch 1100/1562 - Loss:  2.325, Seconds: 3.29\n",
      "Epoch   2/100 Batch 1120/1562 - Loss:  2.198, Seconds: 3.64\n",
      "Epoch   2/100 Batch 1140/1562 - Loss:  2.128, Seconds: 3.59\n",
      "Epoch   2/100 Batch 1160/1562 - Loss:  2.172, Seconds: 3.44\n",
      "Epoch   2/100 Batch 1180/1562 - Loss:  2.067, Seconds: 3.03\n",
      "Epoch   2/100 Batch 1200/1562 - Loss:  2.348, Seconds: 4.04\n",
      "Epoch   2/100 Batch 1220/1562 - Loss:  2.203, Seconds: 3.43\n",
      "Epoch   2/100 Batch 1240/1562 - Loss:  2.060, Seconds: 3.66\n",
      "Average loss for this update: 2.271 -- New Record!\n",
      "Epoch   2/100 Batch 1260/1562 - Loss:  2.425, Seconds: 3.53\n",
      "Epoch   2/100 Batch 1280/1562 - Loss:  2.532, Seconds: 3.90\n",
      "Epoch   2/100 Batch 1300/1562 - Loss:  2.499, Seconds: 3.35\n",
      "Epoch   2/100 Batch 1320/1562 - Loss:  2.462, Seconds: 3.94\n",
      "Epoch   2/100 Batch 1340/1562 - Loss:  2.337, Seconds: 3.55\n",
      "Epoch   2/100 Batch 1360/1562 - Loss:  2.388, Seconds: 3.69\n",
      "Epoch   2/100 Batch 1380/1562 - Loss:  2.291, Seconds: 3.87\n",
      "Epoch   2/100 Batch 1400/1562 - Loss:  2.110, Seconds: 3.91\n",
      "Epoch   2/100 Batch 1420/1562 - Loss:  2.180, Seconds: 3.26\n",
      "Epoch   2/100 Batch 1440/1562 - Loss:  2.171, Seconds: 3.71\n",
      "Epoch   2/100 Batch 1460/1562 - Loss:  2.193, Seconds: 3.87\n",
      "Epoch   2/100 Batch 1480/1562 - Loss:  1.950, Seconds: 3.83\n",
      "Epoch   2/100 Batch 1500/1562 - Loss:  2.145, Seconds: 3.73\n",
      "Epoch   2/100 Batch 1520/1562 - Loss:  2.352, Seconds: 4.39\n",
      "Epoch   2/100 Batch 1540/1562 - Loss:  2.584, Seconds: 3.77\n",
      "Average loss for this update: 2.322-- No Improvement.\n",
      "Epoch   2/100 Batch 1560/1562 - Loss:  2.497, Seconds: 3.94\n",
      "Epoch   3/100 Batch   20/1562 - Loss:  2.566, Seconds: 3.95\n",
      "Epoch   3/100 Batch   40/1562 - Loss:  2.185, Seconds: 3.43\n",
      "Epoch   3/100 Batch   60/1562 - Loss:  2.346, Seconds: 3.10\n",
      "Epoch   3/100 Batch   80/1562 - Loss:  2.286, Seconds: 2.87\n",
      "Epoch   3/100 Batch  100/1562 - Loss:  2.138, Seconds: 3.47\n",
      "Epoch   3/100 Batch  120/1562 - Loss:  2.232, Seconds: 3.12\n",
      "Epoch   3/100 Batch  140/1562 - Loss:  2.284, Seconds: 3.32\n",
      "Epoch   3/100 Batch  160/1562 - Loss:  2.231, Seconds: 2.91\n",
      "Epoch   3/100 Batch  180/1562 - Loss:  2.296, Seconds: 3.77\n",
      "Epoch   3/100 Batch  200/1562 - Loss:  2.139, Seconds: 3.12\n",
      "Epoch   3/100 Batch  220/1562 - Loss:  2.241, Seconds: 3.08\n",
      "Epoch   3/100 Batch  240/1562 - Loss:  2.250, Seconds: 2.93\n",
      "Epoch   3/100 Batch  260/1562 - Loss:  2.199, Seconds: 4.22\n",
      "Epoch   3/100 Batch  280/1562 - Loss:  2.064, Seconds: 3.25\n",
      "Epoch   3/100 Batch  300/1562 - Loss:  1.961, Seconds: 4.11\n",
      "Average loss for this update: 2.221 -- New Record!\n",
      "Epoch   3/100 Batch  320/1562 - Loss:  1.982, Seconds: 3.55\n",
      "Epoch   3/100 Batch  340/1562 - Loss:  2.123, Seconds: 3.35\n",
      "Epoch   3/100 Batch  360/1562 - Loss:  2.121, Seconds: 3.86\n",
      "Epoch   3/100 Batch  380/1562 - Loss:  1.959, Seconds: 2.87\n",
      "Epoch   3/100 Batch  400/1562 - Loss:  2.023, Seconds: 4.07\n",
      "Epoch   3/100 Batch  420/1562 - Loss:  2.149, Seconds: 3.53\n",
      "Epoch   3/100 Batch  440/1562 - Loss:  2.322, Seconds: 3.34\n",
      "Epoch   3/100 Batch  460/1562 - Loss:  2.033, Seconds: 3.11\n",
      "Epoch   3/100 Batch  480/1562 - Loss:  2.069, Seconds: 3.56\n",
      "Epoch   3/100 Batch  500/1562 - Loss:  2.209, Seconds: 3.78\n",
      "Epoch   3/100 Batch  520/1562 - Loss:  2.046, Seconds: 4.19\n",
      "Epoch   3/100 Batch  540/1562 - Loss:  2.105, Seconds: 3.21\n",
      "Epoch   3/100 Batch  560/1562 - Loss:  2.101, Seconds: 3.52\n",
      "Epoch   3/100 Batch  580/1562 - Loss:  1.773, Seconds: 3.55\n",
      "Epoch   3/100 Batch  600/1562 - Loss:  1.767, Seconds: 3.34\n",
      "Epoch   3/100 Batch  620/1562 - Loss:  1.895, Seconds: 3.74\n",
      "Average loss for this update: 2.037 -- New Record!\n",
      "Epoch   3/100 Batch  640/1562 - Loss:  1.983, Seconds: 3.43\n",
      "Epoch   3/100 Batch  660/1562 - Loss:  1.873, Seconds: 3.56\n",
      "Epoch   3/100 Batch  680/1562 - Loss:  1.865, Seconds: 4.12\n",
      "Epoch   3/100 Batch  700/1562 - Loss:  2.078, Seconds: 3.19\n",
      "Epoch   3/100 Batch  720/1562 - Loss:  2.383, Seconds: 4.03\n",
      "Epoch   3/100 Batch  740/1562 - Loss:  2.281, Seconds: 3.84\n",
      "Epoch   3/100 Batch  760/1562 - Loss:  2.182, Seconds: 2.91\n",
      "Epoch   3/100 Batch  780/1562 - Loss:  2.126, Seconds: 4.22\n",
      "Epoch   3/100 Batch  800/1562 - Loss:  1.982, Seconds: 3.44\n",
      "Epoch   3/100 Batch  820/1562 - Loss:  2.105, Seconds: 3.78\n",
      "Epoch   3/100 Batch  840/1562 - Loss:  1.943, Seconds: 3.64\n",
      "Epoch   3/100 Batch  860/1562 - Loss:  1.876, Seconds: 3.60\n",
      "Epoch   3/100 Batch  880/1562 - Loss:  1.617, Seconds: 3.17\n",
      "Epoch   3/100 Batch  900/1562 - Loss:  1.899, Seconds: 4.00\n",
      "Epoch   3/100 Batch  920/1562 - Loss:  1.974, Seconds: 3.44\n",
      "Average loss for this update: 2.01 -- New Record!\n",
      "Epoch   3/100 Batch  940/1562 - Loss:  1.849, Seconds: 3.29\n",
      "Epoch   3/100 Batch  960/1562 - Loss:  1.988, Seconds: 3.80\n",
      "Epoch   3/100 Batch  980/1562 - Loss:  2.164, Seconds: 3.86\n",
      "Epoch   3/100 Batch 1000/1562 - Loss:  2.161, Seconds: 3.61\n",
      "Epoch   3/100 Batch 1020/1562 - Loss:  2.034, Seconds: 3.24\n",
      "Epoch   3/100 Batch 1040/1562 - Loss:  2.154, Seconds: 3.74\n",
      "Epoch   3/100 Batch 1060/1562 - Loss:  2.016, Seconds: 3.44\n",
      "Epoch   3/100 Batch 1080/1562 - Loss:  1.972, Seconds: 4.29\n",
      "Epoch   3/100 Batch 1100/1562 - Loss:  2.022, Seconds: 3.22\n",
      "Epoch   3/100 Batch 1120/1562 - Loss:  1.895, Seconds: 3.62\n",
      "Epoch   3/100 Batch 1140/1562 - Loss:  1.801, Seconds: 3.68\n",
      "Epoch   3/100 Batch 1160/1562 - Loss:  1.816, Seconds: 3.41\n",
      "Epoch   3/100 Batch 1180/1562 - Loss:  1.752, Seconds: 3.04\n",
      "Epoch   3/100 Batch 1200/1562 - Loss:  2.039, Seconds: 4.04\n",
      "Epoch   3/100 Batch 1220/1562 - Loss:  1.898, Seconds: 3.49\n",
      "Epoch   3/100 Batch 1240/1562 - Loss:  1.743, Seconds: 3.77\n",
      "Average loss for this update: 1.959 -- New Record!\n",
      "Epoch   3/100 Batch 1260/1562 - Loss:  2.141, Seconds: 3.51\n",
      "Epoch   3/100 Batch 1280/1562 - Loss:  2.250, Seconds: 3.92\n",
      "Epoch   3/100 Batch 1300/1562 - Loss:  2.212, Seconds: 3.26\n",
      "Epoch   3/100 Batch 1320/1562 - Loss:  2.132, Seconds: 3.83\n",
      "Epoch   3/100 Batch 1340/1562 - Loss:  2.033, Seconds: 3.48\n",
      "Epoch   3/100 Batch 1360/1562 - Loss:  2.072, Seconds: 3.69\n",
      "Epoch   3/100 Batch 1380/1562 - Loss:  1.996, Seconds: 3.90\n",
      "Epoch   3/100 Batch 1400/1562 - Loss:  1.813, Seconds: 3.87\n",
      "Epoch   3/100 Batch 1420/1562 - Loss:  1.813, Seconds: 3.35\n",
      "Epoch   3/100 Batch 1440/1562 - Loss:  1.838, Seconds: 3.92\n",
      "Epoch   3/100 Batch 1460/1562 - Loss:  1.899, Seconds: 3.89\n",
      "Epoch   3/100 Batch 1480/1562 - Loss:  1.680, Seconds: 3.83\n",
      "Epoch   3/100 Batch 1500/1562 - Loss:  1.842, Seconds: 3.69\n",
      "Epoch   3/100 Batch 1520/1562 - Loss:  2.120, Seconds: 4.36\n",
      "Epoch   3/100 Batch 1540/1562 - Loss:  2.360, Seconds: 3.80\n",
      "Average loss for this update: 2.03-- No Improvement.\n",
      "Epoch   3/100 Batch 1560/1562 - Loss:  2.288, Seconds: 3.89\n",
      "Epoch   4/100 Batch   20/1562 - Loss:  2.367, Seconds: 3.89\n",
      "Epoch   4/100 Batch   40/1562 - Loss:  2.014, Seconds: 3.53\n",
      "Epoch   4/100 Batch   60/1562 - Loss:  2.181, Seconds: 3.09\n",
      "Epoch   4/100 Batch   80/1562 - Loss:  2.077, Seconds: 2.85\n",
      "Epoch   4/100 Batch  100/1562 - Loss:  1.919, Seconds: 3.46\n",
      "Epoch   4/100 Batch  120/1562 - Loss:  1.998, Seconds: 3.04\n",
      "Epoch   4/100 Batch  140/1562 - Loss:  2.050, Seconds: 3.30\n",
      "Epoch   4/100 Batch  160/1562 - Loss:  1.989, Seconds: 2.88\n",
      "Epoch   4/100 Batch  180/1562 - Loss:  2.070, Seconds: 3.69\n",
      "Epoch   4/100 Batch  200/1562 - Loss:  1.906, Seconds: 3.07\n",
      "Epoch   4/100 Batch  220/1562 - Loss:  1.988, Seconds: 3.07\n",
      "Epoch   4/100 Batch  240/1562 - Loss:  1.979, Seconds: 2.93\n",
      "Epoch   4/100 Batch  260/1562 - Loss:  1.975, Seconds: 4.13\n",
      "Epoch   4/100 Batch  280/1562 - Loss:  1.820, Seconds: 3.36\n",
      "Epoch   4/100 Batch  300/1562 - Loss:  1.687, Seconds: 4.15\n",
      "Average loss for this update: 1.991-- No Improvement.\n",
      "Epoch   4/100 Batch  320/1562 - Loss:  1.696, Seconds: 3.50\n",
      "Epoch   4/100 Batch  340/1562 - Loss:  1.865, Seconds: 3.24\n",
      "Epoch   4/100 Batch  360/1562 - Loss:  1.882, Seconds: 3.90\n",
      "Epoch   4/100 Batch  380/1562 - Loss:  1.718, Seconds: 2.88\n",
      "Epoch   4/100 Batch  400/1562 - Loss:  1.798, Seconds: 4.11\n",
      "Epoch   4/100 Batch  420/1562 - Loss:  1.927, Seconds: 3.59\n",
      "Epoch   4/100 Batch  440/1562 - Loss:  2.054, Seconds: 3.39\n",
      "Epoch   4/100 Batch  460/1562 - Loss:  1.798, Seconds: 3.18\n",
      "Epoch   4/100 Batch  480/1562 - Loss:  1.834, Seconds: 3.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4/100 Batch  500/1562 - Loss:  1.948, Seconds: 3.81\n",
      "Epoch   4/100 Batch  520/1562 - Loss:  1.764, Seconds: 4.21\n",
      "Epoch   4/100 Batch  540/1562 - Loss:  1.869, Seconds: 3.15\n",
      "Epoch   4/100 Batch  560/1562 - Loss:  1.847, Seconds: 3.68\n",
      "Epoch   4/100 Batch  580/1562 - Loss:  1.533, Seconds: 3.60\n",
      "Epoch   4/100 Batch  600/1562 - Loss:  1.496, Seconds: 3.36\n",
      "Epoch   4/100 Batch  620/1562 - Loss:  1.651, Seconds: 3.71\n",
      "Average loss for this update: 1.79 -- New Record!\n",
      "Epoch   4/100 Batch  640/1562 - Loss:  1.742, Seconds: 3.41\n",
      "Epoch   4/100 Batch  660/1562 - Loss:  1.666, Seconds: 3.64\n",
      "Epoch   4/100 Batch  680/1562 - Loss:  1.637, Seconds: 4.22\n",
      "Epoch   4/100 Batch  700/1562 - Loss:  1.836, Seconds: 3.17\n",
      "Epoch   4/100 Batch  720/1562 - Loss:  2.134, Seconds: 4.02\n",
      "Epoch   4/100 Batch  740/1562 - Loss:  2.011, Seconds: 3.75\n",
      "Epoch   4/100 Batch  760/1562 - Loss:  1.936, Seconds: 3.03\n",
      "Epoch   4/100 Batch  780/1562 - Loss:  1.896, Seconds: 4.25\n",
      "Epoch   4/100 Batch  800/1562 - Loss:  1.748, Seconds: 3.40\n",
      "Epoch   4/100 Batch  820/1562 - Loss:  1.849, Seconds: 3.88\n",
      "Epoch   4/100 Batch  840/1562 - Loss:  1.729, Seconds: 3.58\n",
      "Epoch   4/100 Batch  860/1562 - Loss:  1.651, Seconds: 3.61\n",
      "Epoch   4/100 Batch  880/1562 - Loss:  1.406, Seconds: 3.20\n",
      "Epoch   4/100 Batch  900/1562 - Loss:  1.666, Seconds: 4.05\n",
      "Epoch   4/100 Batch  920/1562 - Loss:  1.767, Seconds: 3.39\n",
      "Average loss for this update: 1.778 -- New Record!\n",
      "Epoch   4/100 Batch  940/1562 - Loss:  1.626, Seconds: 3.17\n",
      "Epoch   4/100 Batch  960/1562 - Loss:  1.734, Seconds: 3.86\n",
      "Epoch   4/100 Batch  980/1562 - Loss:  1.913, Seconds: 3.87\n",
      "Epoch   4/100 Batch 1000/1562 - Loss:  1.894, Seconds: 3.62\n",
      "Epoch   4/100 Batch 1020/1562 - Loss:  1.794, Seconds: 3.34\n",
      "Epoch   4/100 Batch 1040/1562 - Loss:  1.905, Seconds: 3.57\n",
      "Epoch   4/100 Batch 1060/1562 - Loss:  1.774, Seconds: 3.39\n",
      "Epoch   4/100 Batch 1080/1562 - Loss:  1.728, Seconds: 4.27\n",
      "Epoch   4/100 Batch 1100/1562 - Loss:  1.816, Seconds: 3.19\n",
      "Epoch   4/100 Batch 1120/1562 - Loss:  1.678, Seconds: 3.68\n",
      "Epoch   4/100 Batch 1140/1562 - Loss:  1.567, Seconds: 3.60\n",
      "Epoch   4/100 Batch 1160/1562 - Loss:  1.569, Seconds: 3.48\n",
      "Epoch   4/100 Batch 1180/1562 - Loss:  1.547, Seconds: 3.08\n",
      "Epoch   4/100 Batch 1200/1562 - Loss:  1.812, Seconds: 4.02\n",
      "Epoch   4/100 Batch 1220/1562 - Loss:  1.687, Seconds: 3.54\n",
      "Epoch   4/100 Batch 1240/1562 - Loss:  1.509, Seconds: 3.63\n",
      "Average loss for this update: 1.724 -- New Record!\n",
      "Epoch   4/100 Batch 1260/1562 - Loss:  1.898, Seconds: 3.50\n",
      "Epoch   4/100 Batch 1280/1562 - Loss:  2.023, Seconds: 3.87\n",
      "Epoch   4/100 Batch 1300/1562 - Loss:  1.969, Seconds: 3.25\n",
      "Epoch   4/100 Batch 1320/1562 - Loss:  1.880, Seconds: 3.93\n",
      "Epoch   4/100 Batch 1340/1562 - Loss:  1.812, Seconds: 3.55\n",
      "Epoch   4/100 Batch 1360/1562 - Loss:  1.817, Seconds: 3.76\n",
      "Epoch   4/100 Batch 1380/1562 - Loss:  1.773, Seconds: 3.87\n",
      "Epoch   4/100 Batch 1400/1562 - Loss:  1.597, Seconds: 3.84\n",
      "Epoch   4/100 Batch 1420/1562 - Loss:  1.544, Seconds: 3.27\n",
      "Epoch   4/100 Batch 1440/1562 - Loss:  1.608, Seconds: 3.70\n",
      "Epoch   4/100 Batch 1460/1562 - Loss:  1.672, Seconds: 3.86\n",
      "Epoch   4/100 Batch 1480/1562 - Loss:  1.498, Seconds: 3.83\n",
      "Epoch   4/100 Batch 1500/1562 - Loss:  1.634, Seconds: 3.69\n",
      "Epoch   4/100 Batch 1520/1562 - Loss:  1.933, Seconds: 4.36\n",
      "Epoch   4/100 Batch 1540/1562 - Loss:  2.186, Seconds: 3.72\n",
      "Average loss for this update: 1.808-- No Improvement.\n",
      "Epoch   4/100 Batch 1560/1562 - Loss:  2.112, Seconds: 3.94\n",
      "Epoch   5/100 Batch   20/1562 - Loss:  2.174, Seconds: 3.87\n",
      "Epoch   5/100 Batch   40/1562 - Loss:  1.843, Seconds: 3.47\n",
      "Epoch   5/100 Batch   60/1562 - Loss:  2.032, Seconds: 3.09\n",
      "Epoch   5/100 Batch   80/1562 - Loss:  1.893, Seconds: 2.86\n",
      "Epoch   5/100 Batch  100/1562 - Loss:  1.723, Seconds: 3.50\n",
      "Epoch   5/100 Batch  120/1562 - Loss:  1.797, Seconds: 3.12\n",
      "Epoch   5/100 Batch  140/1562 - Loss:  1.849, Seconds: 3.28\n",
      "Epoch   5/100 Batch  160/1562 - Loss:  1.795, Seconds: 2.87\n",
      "Epoch   5/100 Batch  180/1562 - Loss:  1.871, Seconds: 3.67\n",
      "Epoch   5/100 Batch  200/1562 - Loss:  1.714, Seconds: 3.14\n",
      "Epoch   5/100 Batch  220/1562 - Loss:  1.773, Seconds: 3.10\n",
      "Epoch   5/100 Batch  240/1562 - Loss:  1.792, Seconds: 2.84\n",
      "Epoch   5/100 Batch  260/1562 - Loss:  1.781, Seconds: 4.13\n",
      "Epoch   5/100 Batch  280/1562 - Loss:  1.609, Seconds: 3.26\n",
      "Epoch   5/100 Batch  300/1562 - Loss:  1.492, Seconds: 4.04\n",
      "Average loss for this update: 1.798-- No Improvement.\n",
      "Epoch   5/100 Batch  320/1562 - Loss:  1.503, Seconds: 3.48\n",
      "Epoch   5/100 Batch  340/1562 - Loss:  1.664, Seconds: 3.22\n",
      "Epoch   5/100 Batch  360/1562 - Loss:  1.689, Seconds: 3.92\n",
      "Epoch   5/100 Batch  380/1562 - Loss:  1.532, Seconds: 2.91\n",
      "Epoch   5/100 Batch  400/1562 - Loss:  1.614, Seconds: 4.08\n",
      "Epoch   5/100 Batch  420/1562 - Loss:  1.730, Seconds: 3.63\n",
      "Epoch   5/100 Batch  440/1562 - Loss:  1.827, Seconds: 3.35\n",
      "Epoch   5/100 Batch  460/1562 - Loss:  1.617, Seconds: 3.13\n",
      "Epoch   5/100 Batch  480/1562 - Loss:  1.629, Seconds: 3.60\n",
      "Epoch   5/100 Batch  500/1562 - Loss:  1.735, Seconds: 3.75\n",
      "Epoch   5/100 Batch  520/1562 - Loss:  1.562, Seconds: 4.19\n",
      "Epoch   5/100 Batch  540/1562 - Loss:  1.669, Seconds: 3.13\n",
      "Epoch   5/100 Batch  560/1562 - Loss:  1.647, Seconds: 3.61\n",
      "Epoch   5/100 Batch  580/1562 - Loss:  1.352, Seconds: 3.69\n",
      "Epoch   5/100 Batch  600/1562 - Loss:  1.303, Seconds: 3.35\n",
      "Epoch   5/100 Batch  620/1562 - Loss:  1.477, Seconds: 3.79\n",
      "Average loss for this update: 1.596 -- New Record!\n",
      "Epoch   5/100 Batch  640/1562 - Loss:  1.565, Seconds: 3.35\n",
      "Epoch   5/100 Batch  660/1562 - Loss:  1.483, Seconds: 3.58\n",
      "Epoch   5/100 Batch  680/1562 - Loss:  1.458, Seconds: 4.09\n",
      "Epoch   5/100 Batch  700/1562 - Loss:  1.661, Seconds: 3.17\n",
      "Epoch   5/100 Batch  720/1562 - Loss:  1.898, Seconds: 3.95\n",
      "Epoch   5/100 Batch  740/1562 - Loss:  1.800, Seconds: 3.76\n",
      "Epoch   5/100 Batch  760/1562 - Loss:  1.737, Seconds: 3.08\n",
      "Epoch   5/100 Batch  780/1562 - Loss:  1.708, Seconds: 4.21\n",
      "Epoch   5/100 Batch  800/1562 - Loss:  1.552, Seconds: 3.39\n",
      "Epoch   5/100 Batch  820/1562 - Loss:  1.639, Seconds: 3.80\n",
      "Epoch   5/100 Batch  840/1562 - Loss:  1.554, Seconds: 3.67\n",
      "Epoch   5/100 Batch  860/1562 - Loss:  1.489, Seconds: 3.61\n",
      "Epoch   5/100 Batch  880/1562 - Loss:  1.242, Seconds: 3.23\n",
      "Epoch   5/100 Batch  900/1562 - Loss:  1.500, Seconds: 4.05\n",
      "Epoch   5/100 Batch  920/1562 - Loss:  1.603, Seconds: 3.40\n",
      "Average loss for this update: 1.591 -- New Record!\n",
      "Epoch   5/100 Batch  940/1562 - Loss:  1.440, Seconds: 3.25\n",
      "Epoch   5/100 Batch  960/1562 - Loss:  1.532, Seconds: 3.80\n",
      "Epoch   5/100 Batch  980/1562 - Loss:  1.696, Seconds: 3.79\n",
      "Epoch   5/100 Batch 1000/1562 - Loss:  1.676, Seconds: 3.62\n",
      "Epoch   5/100 Batch 1020/1562 - Loss:  1.610, Seconds: 3.30\n",
      "Epoch   5/100 Batch 1040/1562 - Loss:  1.719, Seconds: 3.59\n",
      "Epoch   5/100 Batch 1060/1562 - Loss:  1.572, Seconds: 3.39\n",
      "Epoch   5/100 Batch 1080/1562 - Loss:  1.543, Seconds: 4.20\n",
      "Epoch   5/100 Batch 1100/1562 - Loss:  1.638, Seconds: 3.25\n",
      "Epoch   5/100 Batch 1120/1562 - Loss:  1.501, Seconds: 3.64\n",
      "Epoch   5/100 Batch 1140/1562 - Loss:  1.391, Seconds: 3.59\n",
      "Epoch   5/100 Batch 1160/1562 - Loss:  1.402, Seconds: 3.40\n",
      "Epoch   5/100 Batch 1180/1562 - Loss:  1.383, Seconds: 3.06\n",
      "Epoch   5/100 Batch 1200/1562 - Loss:  1.639, Seconds: 4.01\n",
      "Epoch   5/100 Batch 1220/1562 - Loss:  1.517, Seconds: 3.43\n",
      "Epoch   5/100 Batch 1240/1562 - Loss:  1.348, Seconds: 3.63\n",
      "Average loss for this update: 1.54 -- New Record!\n",
      "Epoch   5/100 Batch 1260/1562 - Loss:  1.688, Seconds: 3.52\n",
      "Epoch   5/100 Batch 1280/1562 - Loss:  1.813, Seconds: 3.98\n",
      "Epoch   5/100 Batch 1300/1562 - Loss:  1.786, Seconds: 3.26\n",
      "Epoch   5/100 Batch 1320/1562 - Loss:  1.685, Seconds: 3.89\n",
      "Epoch   5/100 Batch 1340/1562 - Loss:  1.635, Seconds: 3.53\n",
      "Epoch   5/100 Batch 1360/1562 - Loss:  1.627, Seconds: 3.57\n",
      "Epoch   5/100 Batch 1380/1562 - Loss:  1.595, Seconds: 3.87\n",
      "Epoch   5/100 Batch 1400/1562 - Loss:  1.423, Seconds: 3.88\n",
      "Epoch   5/100 Batch 1420/1562 - Loss:  1.346, Seconds: 3.22\n",
      "Epoch   5/100 Batch 1440/1562 - Loss:  1.440, Seconds: 3.64\n",
      "Epoch   5/100 Batch 1460/1562 - Loss:  1.493, Seconds: 3.92\n",
      "Epoch   5/100 Batch 1480/1562 - Loss:  1.350, Seconds: 3.93\n",
      "Epoch   5/100 Batch 1500/1562 - Loss:  1.471, Seconds: 3.70\n",
      "Epoch   5/100 Batch 1520/1562 - Loss:  1.771, Seconds: 4.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5/100 Batch 1540/1562 - Loss:  2.017, Seconds: 3.75\n",
      "Average loss for this update: 1.629-- No Improvement.\n",
      "Epoch   5/100 Batch 1560/1562 - Loss:  1.971, Seconds: 4.00\n",
      "Epoch   6/100 Batch   20/1562 - Loss:  1.986, Seconds: 3.86\n",
      "Epoch   6/100 Batch   40/1562 - Loss:  1.693, Seconds: 3.48\n",
      "Epoch   6/100 Batch   60/1562 - Loss:  1.899, Seconds: 3.04\n",
      "Epoch   6/100 Batch   80/1562 - Loss:  1.725, Seconds: 2.86\n",
      "Epoch   6/100 Batch  100/1562 - Loss:  1.572, Seconds: 3.42\n",
      "Epoch   6/100 Batch  120/1562 - Loss:  1.623, Seconds: 3.10\n",
      "Epoch   6/100 Batch  140/1562 - Loss:  1.668, Seconds: 3.28\n",
      "Epoch   6/100 Batch  160/1562 - Loss:  1.614, Seconds: 2.94\n",
      "Epoch   6/100 Batch  180/1562 - Loss:  1.701, Seconds: 3.67\n",
      "Epoch   6/100 Batch  200/1562 - Loss:  1.560, Seconds: 3.03\n",
      "Epoch   6/100 Batch  220/1562 - Loss:  1.609, Seconds: 3.05\n",
      "Epoch   6/100 Batch  240/1562 - Loss:  1.608, Seconds: 2.91\n",
      "Epoch   6/100 Batch  260/1562 - Loss:  1.614, Seconds: 4.16\n",
      "Epoch   6/100 Batch  280/1562 - Loss:  1.465, Seconds: 3.24\n",
      "Epoch   6/100 Batch  300/1562 - Loss:  1.345, Seconds: 4.06\n",
      "Average loss for this update: 1.635-- No Improvement.\n",
      "Epoch   6/100 Batch  320/1562 - Loss:  1.342, Seconds: 3.53\n",
      "Epoch   6/100 Batch  340/1562 - Loss:  1.488, Seconds: 3.31\n",
      "Epoch   6/100 Batch  360/1562 - Loss:  1.533, Seconds: 3.94\n",
      "Epoch   6/100 Batch  380/1562 - Loss:  1.372, Seconds: 2.96\n",
      "Epoch   6/100 Batch  400/1562 - Loss:  1.489, Seconds: 4.11\n",
      "Epoch   6/100 Batch  420/1562 - Loss:  1.569, Seconds: 3.54\n",
      "Epoch   6/100 Batch  440/1562 - Loss:  1.648, Seconds: 3.39\n",
      "Epoch   6/100 Batch  460/1562 - Loss:  1.456, Seconds: 3.18\n",
      "Epoch   6/100 Batch  480/1562 - Loss:  1.448, Seconds: 3.59\n",
      "Epoch   6/100 Batch  500/1562 - Loss:  1.569, Seconds: 3.70\n",
      "Epoch   6/100 Batch  520/1562 - Loss:  1.396, Seconds: 4.23\n",
      "Epoch   6/100 Batch  540/1562 - Loss:  1.484, Seconds: 3.16\n",
      "Epoch   6/100 Batch  560/1562 - Loss:  1.473, Seconds: 3.58\n",
      "Epoch   6/100 Batch  580/1562 - Loss:  1.209, Seconds: 3.50\n",
      "Epoch   6/100 Batch  600/1562 - Loss:  1.148, Seconds: 3.30\n",
      "Epoch   6/100 Batch  620/1562 - Loss:  1.322, Seconds: 3.80\n",
      "Average loss for this update: 1.434 -- New Record!\n",
      "Epoch   6/100 Batch  640/1562 - Loss:  1.422, Seconds: 3.37\n",
      "Epoch   6/100 Batch  660/1562 - Loss:  1.337, Seconds: 3.48\n",
      "Epoch   6/100 Batch  680/1562 - Loss:  1.317, Seconds: 4.21\n",
      "Epoch   6/100 Batch  700/1562 - Loss:  1.506, Seconds: 3.26\n",
      "Epoch   6/100 Batch  720/1562 - Loss:  1.716, Seconds: 4.00\n",
      "Epoch   6/100 Batch  740/1562 - Loss:  1.608, Seconds: 3.82\n",
      "Epoch   6/100 Batch  760/1562 - Loss:  1.575, Seconds: 2.99\n",
      "Epoch   6/100 Batch  780/1562 - Loss:  1.548, Seconds: 4.23\n",
      "Epoch   6/100 Batch  800/1562 - Loss:  1.405, Seconds: 3.39\n",
      "Epoch   6/100 Batch  820/1562 - Loss:  1.477, Seconds: 3.81\n",
      "Epoch   6/100 Batch  840/1562 - Loss:  1.416, Seconds: 3.65\n",
      "Epoch   6/100 Batch  860/1562 - Loss:  1.359, Seconds: 3.86\n",
      "Epoch   6/100 Batch  880/1562 - Loss:  1.109, Seconds: 3.24\n",
      "Epoch   6/100 Batch  900/1562 - Loss:  1.368, Seconds: 3.97\n",
      "Epoch   6/100 Batch  920/1562 - Loss:  1.455, Seconds: 3.49\n",
      "Average loss for this update: 1.44-- No Improvement.\n",
      "Epoch   6/100 Batch  940/1562 - Loss:  1.305, Seconds: 3.19\n",
      "Epoch   6/100 Batch  960/1562 - Loss:  1.367, Seconds: 3.85\n",
      "Epoch   6/100 Batch  980/1562 - Loss:  1.509, Seconds: 3.85\n",
      "Epoch   6/100 Batch 1000/1562 - Loss:  1.500, Seconds: 3.63\n",
      "Epoch   6/100 Batch 1020/1562 - Loss:  1.467, Seconds: 3.22\n",
      "Epoch   6/100 Batch 1040/1562 - Loss:  1.559, Seconds: 3.59\n",
      "Epoch   6/100 Batch 1060/1562 - Loss:  1.418, Seconds: 3.43\n",
      "Epoch   6/100 Batch 1080/1562 - Loss:  1.386, Seconds: 4.33\n",
      "Epoch   6/100 Batch 1100/1562 - Loss:  1.478, Seconds: 3.28\n",
      "Epoch   6/100 Batch 1120/1562 - Loss:  1.375, Seconds: 3.65\n",
      "Epoch   6/100 Batch 1140/1562 - Loss:  1.255, Seconds: 3.68\n",
      "Epoch   6/100 Batch 1160/1562 - Loss:  1.261, Seconds: 3.41\n",
      "Epoch   6/100 Batch 1180/1562 - Loss:  1.262, Seconds: 3.04\n",
      "Epoch   6/100 Batch 1200/1562 - Loss:  1.476, Seconds: 4.10\n",
      "Epoch   6/100 Batch 1220/1562 - Loss:  1.389, Seconds: 3.46\n",
      "Epoch   6/100 Batch 1240/1562 - Loss:  1.211, Seconds: 3.63\n",
      "Average loss for this update: 1.39 -- New Record!\n",
      "Epoch   6/100 Batch 1260/1562 - Loss:  1.523, Seconds: 3.43\n",
      "Epoch   6/100 Batch 1280/1562 - Loss:  1.630, Seconds: 3.84\n",
      "Epoch   6/100 Batch 1300/1562 - Loss:  1.610, Seconds: 3.33\n",
      "Epoch   6/100 Batch 1320/1562 - Loss:  1.522, Seconds: 3.81\n",
      "Epoch   6/100 Batch 1340/1562 - Loss:  1.468, Seconds: 3.52\n",
      "Epoch   6/100 Batch 1360/1562 - Loss:  1.455, Seconds: 3.64\n",
      "Epoch   6/100 Batch 1380/1562 - Loss:  1.458, Seconds: 3.90\n",
      "Epoch   6/100 Batch 1400/1562 - Loss:  1.298, Seconds: 3.87\n",
      "Epoch   6/100 Batch 1420/1562 - Loss:  1.190, Seconds: 3.39\n",
      "Epoch   6/100 Batch 1440/1562 - Loss:  1.298, Seconds: 3.77\n",
      "Epoch   6/100 Batch 1460/1562 - Loss:  1.326, Seconds: 3.91\n",
      "Epoch   6/100 Batch 1480/1562 - Loss:  1.236, Seconds: 3.87\n",
      "Epoch   6/100 Batch 1500/1562 - Loss:  1.340, Seconds: 3.68\n",
      "Epoch   6/100 Batch 1520/1562 - Loss:  1.635, Seconds: 4.43\n",
      "Epoch   6/100 Batch 1540/1562 - Loss:  1.848, Seconds: 3.69\n",
      "Average loss for this update: 1.476-- No Improvement.\n",
      "Epoch   6/100 Batch 1560/1562 - Loss:  1.842, Seconds: 3.92\n",
      "Epoch   7/100 Batch   20/1562 - Loss:  1.807, Seconds: 3.90\n",
      "Epoch   7/100 Batch   40/1562 - Loss:  1.560, Seconds: 3.44\n",
      "Epoch   7/100 Batch   60/1562 - Loss:  1.758, Seconds: 3.14\n",
      "Epoch   7/100 Batch   80/1562 - Loss:  1.576, Seconds: 2.82\n",
      "Epoch   7/100 Batch  100/1562 - Loss:  1.430, Seconds: 3.45\n",
      "Epoch   7/100 Batch  120/1562 - Loss:  1.490, Seconds: 3.09\n",
      "Epoch   7/100 Batch  140/1562 - Loss:  1.537, Seconds: 3.32\n",
      "Epoch   7/100 Batch  160/1562 - Loss:  1.472, Seconds: 2.90\n",
      "Epoch   7/100 Batch  180/1562 - Loss:  1.547, Seconds: 3.59\n",
      "Epoch   7/100 Batch  200/1562 - Loss:  1.430, Seconds: 3.08\n",
      "Epoch   7/100 Batch  220/1562 - Loss:  1.446, Seconds: 3.10\n",
      "Epoch   7/100 Batch  240/1562 - Loss:  1.468, Seconds: 2.86\n",
      "Epoch   7/100 Batch  260/1562 - Loss:  1.481, Seconds: 4.06\n",
      "Epoch   7/100 Batch  280/1562 - Loss:  1.333, Seconds: 3.21\n",
      "Epoch   7/100 Batch  300/1562 - Loss:  1.222, Seconds: 4.15\n",
      "Average loss for this update: 1.492-- No Improvement.\n",
      "Epoch   7/100 Batch  320/1562 - Loss:  1.205, Seconds: 3.49\n",
      "Epoch   7/100 Batch  340/1562 - Loss:  1.375, Seconds: 3.43\n",
      "Epoch   7/100 Batch  360/1562 - Loss:  1.386, Seconds: 3.92\n",
      "Epoch   7/100 Batch  380/1562 - Loss:  1.250, Seconds: 2.86\n",
      "Epoch   7/100 Batch  400/1562 - Loss:  1.368, Seconds: 4.11\n",
      "Epoch   7/100 Batch  420/1562 - Loss:  1.424, Seconds: 3.56\n",
      "Epoch   7/100 Batch  440/1562 - Loss:  1.501, Seconds: 3.33\n",
      "Epoch   7/100 Batch  460/1562 - Loss:  1.333, Seconds: 3.22\n",
      "Epoch   7/100 Batch  480/1562 - Loss:  1.309, Seconds: 3.51\n",
      "Epoch   7/100 Batch  500/1562 - Loss:  1.411, Seconds: 3.76\n",
      "Epoch   7/100 Batch  520/1562 - Loss:  1.261, Seconds: 4.10\n",
      "Epoch   7/100 Batch  540/1562 - Loss:  1.358, Seconds: 3.13\n",
      "Epoch   7/100 Batch  560/1562 - Loss:  1.351, Seconds: 3.48\n",
      "Epoch   7/100 Batch  580/1562 - Loss:  1.087, Seconds: 3.58\n",
      "Epoch   7/100 Batch  600/1562 - Loss:  1.055, Seconds: 3.40\n",
      "Epoch   7/100 Batch  620/1562 - Loss:  1.218, Seconds: 3.84\n",
      "Average loss for this update: 1.307 -- New Record!\n",
      "Epoch   7/100 Batch  640/1562 - Loss:  1.305, Seconds: 3.37\n",
      "Epoch   7/100 Batch  660/1562 - Loss:  1.213, Seconds: 3.54\n",
      "Epoch   7/100 Batch  680/1562 - Loss:  1.200, Seconds: 4.12\n",
      "Epoch   7/100 Batch  700/1562 - Loss:  1.356, Seconds: 3.20\n",
      "Epoch   7/100 Batch  720/1562 - Loss:  1.531, Seconds: 3.99\n",
      "Epoch   7/100 Batch  740/1562 - Loss:  1.453, Seconds: 3.82\n",
      "Epoch   7/100 Batch  760/1562 - Loss:  1.438, Seconds: 2.99\n",
      "Epoch   7/100 Batch  780/1562 - Loss:  1.414, Seconds: 4.29\n",
      "Epoch   7/100 Batch  800/1562 - Loss:  1.249, Seconds: 3.43\n",
      "Epoch   7/100 Batch  820/1562 - Loss:  1.336, Seconds: 3.85\n",
      "Epoch   7/100 Batch  840/1562 - Loss:  1.296, Seconds: 3.57\n",
      "Epoch   7/100 Batch  860/1562 - Loss:  1.239, Seconds: 3.60\n",
      "Epoch   7/100 Batch  880/1562 - Loss:  1.005, Seconds: 3.15\n",
      "Epoch   7/100 Batch  900/1562 - Loss:  1.244, Seconds: 3.96\n",
      "Epoch   7/100 Batch  920/1562 - Loss:  1.330, Seconds: 3.36\n",
      "Average loss for this update: 1.306 -- New Record!\n",
      "Epoch   7/100 Batch  940/1562 - Loss:  1.178, Seconds: 3.22\n",
      "Epoch   7/100 Batch  960/1562 - Loss:  1.223, Seconds: 3.86\n",
      "Epoch   7/100 Batch  980/1562 - Loss:  1.383, Seconds: 3.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7/100 Batch 1000/1562 - Loss:  1.347, Seconds: 3.63\n",
      "Epoch   7/100 Batch 1020/1562 - Loss:  1.343, Seconds: 3.32\n",
      "Epoch   7/100 Batch 1040/1562 - Loss:  1.418, Seconds: 3.62\n",
      "Epoch   7/100 Batch 1060/1562 - Loss:  1.293, Seconds: 3.41\n",
      "Epoch   7/100 Batch 1080/1562 - Loss:  1.263, Seconds: 4.23\n",
      "Epoch   7/100 Batch 1100/1562 - Loss:  1.354, Seconds: 3.21\n",
      "Epoch   7/100 Batch 1120/1562 - Loss:  1.268, Seconds: 3.68\n",
      "Epoch   7/100 Batch 1140/1562 - Loss:  1.147, Seconds: 3.69\n",
      "Epoch   7/100 Batch 1160/1562 - Loss:  1.137, Seconds: 3.47\n",
      "Epoch   7/100 Batch 1180/1562 - Loss:  1.165, Seconds: 3.05\n",
      "Epoch   7/100 Batch 1200/1562 - Loss:  1.370, Seconds: 4.02\n",
      "Epoch   7/100 Batch 1220/1562 - Loss:  1.274, Seconds: 3.42\n",
      "Epoch   7/100 Batch 1240/1562 - Loss:  1.093, Seconds: 3.69\n",
      "Average loss for this update: 1.268 -- New Record!\n",
      "Epoch   7/100 Batch 1260/1562 - Loss:  1.379, Seconds: 3.51\n",
      "Epoch   7/100 Batch 1280/1562 - Loss:  1.490, Seconds: 3.86\n",
      "Epoch   7/100 Batch 1300/1562 - Loss:  1.464, Seconds: 3.33\n",
      "Epoch   7/100 Batch 1320/1562 - Loss:  1.373, Seconds: 3.91\n",
      "Epoch   7/100 Batch 1340/1562 - Loss:  1.359, Seconds: 3.47\n",
      "Epoch   7/100 Batch 1360/1562 - Loss:  1.333, Seconds: 3.70\n",
      "Epoch   7/100 Batch 1380/1562 - Loss:  1.339, Seconds: 3.84\n",
      "Epoch   7/100 Batch 1400/1562 - Loss:  1.178, Seconds: 3.90\n",
      "Epoch   7/100 Batch 1420/1562 - Loss:  1.085, Seconds: 3.23\n",
      "Epoch   7/100 Batch 1440/1562 - Loss:  1.182, Seconds: 3.68\n",
      "Epoch   7/100 Batch 1460/1562 - Loss:  1.201, Seconds: 4.41\n",
      "Epoch   7/100 Batch 1480/1562 - Loss:  1.119, Seconds: 3.91\n",
      "Epoch   7/100 Batch 1500/1562 - Loss:  1.233, Seconds: 3.75\n",
      "Epoch   7/100 Batch 1520/1562 - Loss:  1.487, Seconds: 4.46\n",
      "Epoch   7/100 Batch 1540/1562 - Loss:  1.712, Seconds: 3.83\n",
      "Average loss for this update: 1.349-- No Improvement.\n",
      "Epoch   7/100 Batch 1560/1562 - Loss:  1.716, Seconds: 4.01\n",
      "Epoch   8/100 Batch   20/1562 - Loss:  1.676, Seconds: 3.92\n",
      "Epoch   8/100 Batch   40/1562 - Loss:  1.442, Seconds: 3.45\n",
      "Epoch   8/100 Batch   60/1562 - Loss:  1.635, Seconds: 3.08\n",
      "Epoch   8/100 Batch   80/1562 - Loss:  1.443, Seconds: 2.88\n",
      "Epoch   8/100 Batch  100/1562 - Loss:  1.310, Seconds: 3.46\n",
      "Epoch   8/100 Batch  120/1562 - Loss:  1.357, Seconds: 3.11\n",
      "Epoch   8/100 Batch  140/1562 - Loss:  1.396, Seconds: 3.28\n",
      "Epoch   8/100 Batch  160/1562 - Loss:  1.359, Seconds: 2.85\n",
      "Epoch   8/100 Batch  180/1562 - Loss:  1.420, Seconds: 3.71\n",
      "Epoch   8/100 Batch  200/1562 - Loss:  1.305, Seconds: 3.07\n",
      "Epoch   8/100 Batch  220/1562 - Loss:  1.335, Seconds: 3.12\n",
      "Epoch   8/100 Batch  240/1562 - Loss:  1.320, Seconds: 2.87\n",
      "Epoch   8/100 Batch  260/1562 - Loss:  1.362, Seconds: 4.05\n",
      "Epoch   8/100 Batch  280/1562 - Loss:  1.230, Seconds: 3.28\n",
      "Epoch   8/100 Batch  300/1562 - Loss:  1.127, Seconds: 4.12\n",
      "Average loss for this update: 1.37-- No Improvement.\n",
      "Epoch   8/100 Batch  320/1562 - Loss:  1.113, Seconds: 3.52\n",
      "Epoch   8/100 Batch  340/1562 - Loss:  1.243, Seconds: 3.32\n",
      "Epoch   8/100 Batch  360/1562 - Loss:  1.267, Seconds: 3.89\n",
      "Epoch   8/100 Batch  380/1562 - Loss:  1.148, Seconds: 2.86\n",
      "Epoch   8/100 Batch  400/1562 - Loss:  1.261, Seconds: 4.05\n",
      "Epoch   8/100 Batch  420/1562 - Loss:  1.297, Seconds: 3.63\n",
      "Epoch   8/100 Batch  440/1562 - Loss:  1.364, Seconds: 3.39\n",
      "Epoch   8/100 Batch  460/1562 - Loss:  1.229, Seconds: 3.07\n",
      "Epoch   8/100 Batch  480/1562 - Loss:  1.180, Seconds: 3.55\n",
      "Epoch   8/100 Batch  500/1562 - Loss:  1.299, Seconds: 3.77\n",
      "Epoch   8/100 Batch  520/1562 - Loss:  1.151, Seconds: 4.21\n",
      "Epoch   8/100 Batch  540/1562 - Loss:  1.241, Seconds: 3.11\n",
      "Epoch   8/100 Batch  560/1562 - Loss:  1.230, Seconds: 3.54\n",
      "Epoch   8/100 Batch 1280/1562 - Loss:  1.352, Seconds: 3.88\n",
      "Epoch   8/100 Batch 1300/1562 - Loss:  1.349, Seconds: 3.33\n",
      "Epoch   8/100 Batch 1320/1562 - Loss:  1.269, Seconds: 3.91\n",
      "Epoch   8/100 Batch 1340/1562 - Loss:  1.252, Seconds: 3.45\n",
      "Epoch   8/100 Batch 1360/1562 - Loss:  1.217, Seconds: 3.77\n",
      "Epoch   8/100 Batch 1380/1562 - Loss:  1.221, Seconds: 3.88\n",
      "Epoch   8/100 Batch 1400/1562 - Loss:  1.106, Seconds: 3.86\n",
      "Epoch   8/100 Batch 1420/1562 - Loss:  0.975, Seconds: 3.26\n",
      "Epoch   8/100 Batch 1440/1562 - Loss:  1.088, Seconds: 3.65\n",
      "Epoch   8/100 Batch 1460/1562 - Loss:  1.117, Seconds: 3.92\n",
      "Epoch   8/100 Batch 1480/1562 - Loss:  1.045, Seconds: 3.94\n",
      "Epoch   8/100 Batch 1500/1562 - Loss:  1.123, Seconds: 3.66\n",
      "Epoch   8/100 Batch 1520/1562 - Loss:  1.391, Seconds: 4.35\n",
      "Epoch   8/100 Batch 1540/1562 - Loss:  1.592, Seconds: 3.75\n",
      "Average loss for this update: 1.243-- No Improvement.\n",
      "Epoch   8/100 Batch 1560/1562 - Loss:  1.599, Seconds: 3.98\n",
      "Epoch   9/100 Batch   20/1562 - Loss:  1.554, Seconds: 3.86\n",
      "Epoch   9/100 Batch   40/1562 - Loss:  1.337, Seconds: 3.46\n",
      "Epoch   9/100 Batch   60/1562 - Loss:  1.517, Seconds: 3.06\n",
      "Epoch   9/100 Batch   80/1562 - Loss:  1.339, Seconds: 2.88\n",
      "Epoch   9/100 Batch  100/1562 - Loss:  1.208, Seconds: 3.38\n",
      "Epoch   9/100 Batch  120/1562 - Loss:  1.247, Seconds: 3.10\n",
      "Epoch   9/100 Batch  140/1562 - Loss:  1.309, Seconds: 3.26\n",
      "Epoch   9/100 Batch  160/1562 - Loss:  1.245, Seconds: 2.86\n",
      "Epoch   9/100 Batch  180/1562 - Loss:  1.298, Seconds: 3.70\n",
      "Epoch   9/100 Batch  200/1562 - Loss:  1.188, Seconds: 3.12\n",
      "Epoch   9/100 Batch  220/1562 - Loss:  1.242, Seconds: 3.14\n",
      "Epoch   9/100 Batch  240/1562 - Loss:  1.218, Seconds: 2.83\n",
      "Epoch   9/100 Batch  260/1562 - Loss:  1.257, Seconds: 4.16\n",
      "Epoch   9/100 Batch  280/1562 - Loss:  1.130, Seconds: 3.36\n",
      "Epoch   9/100 Batch  300/1562 - Loss:  1.034, Seconds: 4.27\n",
      "Average loss for this update: 1.264-- No Improvement.\n",
      "Epoch   9/100 Batch  320/1562 - Loss:  1.015, Seconds: 3.60\n",
      "Epoch   9/100 Batch  340/1562 - Loss:  1.146, Seconds: 3.31\n",
      "Epoch   9/100 Batch  360/1562 - Loss:  1.166, Seconds: 4.00\n",
      "Epoch   9/100 Batch  380/1562 - Loss:  1.067, Seconds: 2.91\n",
      "Epoch   9/100 Batch  400/1562 - Loss:  1.164, Seconds: 4.21\n",
      "Epoch   9/100 Batch  420/1562 - Loss:  1.191, Seconds: 3.54\n",
      "Epoch   9/100 Batch  440/1562 - Loss:  1.254, Seconds: 3.40\n",
      "Epoch   9/100 Batch  460/1562 - Loss:  1.138, Seconds: 3.13\n",
      "Epoch   9/100 Batch  480/1562 - Loss:  1.086, Seconds: 3.55\n",
      "Epoch   9/100 Batch  500/1562 - Loss:  1.203, Seconds: 3.74\n",
      "Epoch   9/100 Batch  520/1562 - Loss:  1.062, Seconds: 4.19\n",
      "Epoch   9/100 Batch  540/1562 - Loss:  1.148, Seconds: 3.11\n",
      "Epoch   9/100 Batch  560/1562 - Loss:  1.138, Seconds: 3.60\n",
      "Epoch   9/100 Batch  580/1562 - Loss:  0.925, Seconds: 3.48\n",
      "Epoch   9/100 Batch  600/1562 - Loss:  0.886, Seconds: 3.38\n",
      "Epoch   9/100 Batch  620/1562 - Loss:  1.031, Seconds: 3.82\n",
      "Average loss for this update: 1.103 -- New Record!\n",
      "Epoch   9/100 Batch  640/1562 - Loss:  1.113, Seconds: 3.40\n",
      "Epoch   9/100 Batch  660/1562 - Loss:  1.064, Seconds: 3.62\n",
      "Epoch   9/100 Batch  680/1562 - Loss:  1.025, Seconds: 4.27\n",
      "Epoch   9/100 Batch  700/1562 - Loss:  1.135, Seconds: 3.19\n",
      "Epoch   9/100 Batch  720/1562 - Loss:  1.264, Seconds: 4.01\n",
      "Epoch   9/100 Batch  740/1562 - Loss:  1.251, Seconds: 3.76\n",
      "Epoch   9/100 Batch  760/1562 - Loss:  1.239, Seconds: 3.01\n",
      "Epoch   9/100 Batch  780/1562 - Loss:  1.216, Seconds: 4.14\n",
      "Epoch   9/100 Batch  800/1562 - Loss:  1.068, Seconds: 3.42\n",
      "Epoch   9/100 Batch  820/1562 - Loss:  1.122, Seconds: 3.80\n",
      "Epoch   9/100 Batch  840/1562 - Loss:  1.102, Seconds: 3.65\n",
      "Epoch   9/100 Batch  860/1562 - Loss:  1.061, Seconds: 3.57\n",
      "Epoch   9/100 Batch  880/1562 - Loss:  0.862, Seconds: 3.24\n",
      "Epoch   9/100 Batch  900/1562 - Loss:  1.075, Seconds: 4.06\n",
      "Epoch   9/100 Batch  920/1562 - Loss:  1.118, Seconds: 3.43\n",
      "Average loss for this update: 1.113-- No Improvement.\n",
      "Epoch   9/100 Batch  940/1562 - Loss:  0.991, Seconds: 3.15\n",
      "Epoch   9/100 Batch  960/1562 - Loss:  1.043, Seconds: 3.75\n",
      "Epoch   9/100 Batch  980/1562 - Loss:  1.152, Seconds: 3.89\n",
      "Epoch   9/100 Batch 1000/1562 - Loss:  1.138, Seconds: 3.72\n",
      "Epoch   9/100 Batch 1020/1562 - Loss:  1.145, Seconds: 3.29\n",
      "Epoch   9/100 Batch 1040/1562 - Loss:  1.203, Seconds: 3.65\n",
      "Epoch   9/100 Batch 1060/1562 - Loss:  1.082, Seconds: 3.41\n",
      "Epoch   9/100 Batch 1080/1562 - Loss:  1.069, Seconds: 4.26\n",
      "Epoch   9/100 Batch 1100/1562 - Loss:  1.166, Seconds: 3.32\n",
      "Epoch   9/100 Batch 1120/1562 - Loss:  1.100, Seconds: 3.64\n",
      "Epoch   9/100 Batch 1140/1562 - Loss:  1.002, Seconds: 3.61\n",
      "Epoch   9/100 Batch 1160/1562 - Loss:  0.969, Seconds: 3.43\n",
      "Epoch   9/100 Batch 1180/1562 - Loss:  0.996, Seconds: 3.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9/100 Batch 1200/1562 - Loss:  1.165, Seconds: 4.05\n",
      "Epoch   9/100 Batch 1220/1562 - Loss:  1.096, Seconds: 3.36\n",
      "Epoch   9/100 Batch 1240/1562 - Loss:  0.930, Seconds: 3.68\n",
      "Average loss for this update: 1.08 -- New Record!\n",
      "Epoch   9/100 Batch 1260/1562 - Loss:  1.157, Seconds: 3.59\n",
      "Epoch   9/100 Batch 1280/1562 - Loss:  1.243, Seconds: 3.84\n",
      "Epoch   9/100 Batch 1300/1562 - Loss:  1.246, Seconds: 3.29\n",
      "Epoch   9/100 Batch 1320/1562 - Loss:  1.168, Seconds: 3.86\n",
      "Epoch   9/100 Batch 1340/1562 - Loss:  1.140, Seconds: 3.51\n",
      "Epoch   9/100 Batch 1360/1562 - Loss:  1.115, Seconds: 3.67\n",
      "Epoch   9/100 Batch 1380/1562 - Loss:  1.146, Seconds: 4.01\n",
      "Epoch   9/100 Batch 1400/1562 - Loss:  1.017, Seconds: 4.01\n",
      "Epoch   9/100 Batch 1420/1562 - Loss:  0.903, Seconds: 3.26\n",
      "Epoch   9/100 Batch 1440/1562 - Loss:  1.009, Seconds: 3.70\n",
      "Epoch   9/100 Batch 1460/1562 - Loss:  1.016, Seconds: 3.95\n",
      "Epoch   9/100 Batch 1480/1562 - Loss:  0.963, Seconds: 3.90\n",
      "Epoch   9/100 Batch 1500/1562 - Loss:  1.044, Seconds: 3.72\n",
      "Epoch   9/100 Batch 1520/1562 - Loss:  1.290, Seconds: 4.37\n",
      "Epoch   9/100 Batch 1540/1562 - Loss:  1.483, Seconds: 3.66\n",
      "Average loss for this update: 1.148-- No Improvement.\n",
      "Epoch   9/100 Batch 1560/1562 - Loss:  1.500, Seconds: 3.94\n",
      "Epoch  10/100 Batch   20/1562 - Loss:  1.436, Seconds: 3.83\n",
      "Epoch  10/100 Batch   40/1562 - Loss:  1.252, Seconds: 3.47\n",
      "Epoch  10/100 Batch   60/1562 - Loss:  1.429, Seconds: 3.05\n",
      "Epoch  10/100 Batch   80/1562 - Loss:  1.265, Seconds: 2.88\n",
      "Epoch  10/100 Batch  100/1562 - Loss:  1.126, Seconds: 3.44\n",
      "Epoch  10/100 Batch  120/1562 - Loss:  1.154, Seconds: 3.09\n",
      "Epoch  10/100 Batch  140/1562 - Loss:  1.207, Seconds: 3.25\n",
      "Epoch  10/100 Batch  160/1562 - Loss:  1.155, Seconds: 2.87\n",
      "Epoch  10/100 Batch  180/1562 - Loss:  1.192, Seconds: 3.72\n",
      "Epoch  10/100 Batch  200/1562 - Loss:  1.107, Seconds: 3.04\n",
      "Epoch  10/100 Batch  220/1562 - Loss:  1.142, Seconds: 3.14\n",
      "Epoch  10/100 Batch  240/1562 - Loss:  1.109, Seconds: 2.88\n",
      "Epoch  10/100 Batch  260/1562 - Loss:  1.165, Seconds: 4.13\n",
      "Epoch  10/100 Batch  280/1562 - Loss:  1.052, Seconds: 3.31\n",
      "Epoch  10/100 Batch  300/1562 - Loss:  0.960, Seconds: 4.11\n",
      "Average loss for this update: 1.173-- No Improvement.\n",
      "Epoch  10/100 Batch  320/1562 - Loss:  0.939, Seconds: 3.54\n",
      "Epoch  10/100 Batch  340/1562 - Loss:  1.053, Seconds: 3.25\n",
      "Epoch  10/100 Batch  360/1562 - Loss:  1.086, Seconds: 3.91\n",
      "Epoch  10/100 Batch  380/1562 - Loss:  0.983, Seconds: 2.94\n",
      "Epoch  10/100 Batch  400/1562 - Loss:  1.084, Seconds: 4.09\n",
      "Epoch  10/100 Batch  420/1562 - Loss:  1.100, Seconds: 3.54\n",
      "Epoch  10/100 Batch  440/1562 - Loss:  1.184, Seconds: 3.36\n",
      "Epoch  10/100 Batch  460/1562 - Loss:  1.064, Seconds: 3.18\n",
      "Epoch  10/100 Batch  480/1562 - Loss:  0.994, Seconds: 3.56\n",
      "Epoch  10/100 Batch  500/1562 - Loss:  1.105, Seconds: 3.77\n",
      "Epoch  10/100 Batch  520/1562 - Loss:  1.003, Seconds: 4.13\n",
      "Epoch  10/100 Batch  540/1562 - Loss:  1.064, Seconds: 3.12\n",
      "Epoch  10/100 Batch  560/1562 - Loss:  1.067, Seconds: 3.55\n",
      "Epoch  10/100 Batch  580/1562 - Loss:  0.868, Seconds: 3.58\n",
      "Epoch  10/100 Batch  600/1562 - Loss:  0.817, Seconds: 3.41\n",
      "Epoch  10/100 Batch  620/1562 - Loss:  0.962, Seconds: 3.76\n",
      "Average loss for this update: 1.025 -- New Record!\n",
      "Epoch  10/100 Batch  640/1562 - Loss:  1.036, Seconds: 3.40\n",
      "Epoch  10/100 Batch  660/1562 - Loss:  0.999, Seconds: 3.57\n",
      "Epoch  10/100 Batch  680/1562 - Loss:  0.943, Seconds: 4.13\n",
      "Epoch  10/100 Batch  700/1562 - Loss:  1.066, Seconds: 3.21\n",
      "Epoch  10/100 Batch  720/1562 - Loss:  1.165, Seconds: 4.00\n",
      "Epoch  10/100 Batch  740/1562 - Loss:  1.168, Seconds: 3.79\n",
      "Epoch  10/100 Batch  760/1562 - Loss:  1.150, Seconds: 2.95\n",
      "Epoch  10/100 Batch  780/1562 - Loss:  1.136, Seconds: 4.19\n",
      "Epoch  10/100 Batch  800/1562 - Loss:  0.989, Seconds: 3.43\n",
      "Epoch  10/100 Batch  820/1562 - Loss:  1.041, Seconds: 3.81\n",
      "Epoch  10/100 Batch  840/1562 - Loss:  1.029, Seconds: 3.58\n",
      "Epoch  10/100 Batch  860/1562 - Loss:  0.990, Seconds: 3.63\n",
      "Epoch  10/100 Batch  880/1562 - Loss:  0.803, Seconds: 3.15\n",
      "Epoch  10/100 Batch  900/1562 - Loss:  1.007, Seconds: 4.08\n",
      "Epoch  10/100 Batch  920/1562 - Loss:  1.035, Seconds: 3.41\n",
      "Average loss for this update: 1.035-- No Improvement.\n",
      "Epoch  10/100 Batch  940/1562 - Loss:  0.915, Seconds: 3.20\n",
      "Epoch  10/100 Batch  960/1562 - Loss:  0.972, Seconds: 3.84\n",
      "Epoch  10/100 Batch  980/1562 - Loss:  1.069, Seconds: 3.82\n",
      "Epoch  10/100 Batch 1000/1562 - Loss:  1.046, Seconds: 3.67\n",
      "Epoch  10/100 Batch 1020/1562 - Loss:  1.053, Seconds: 3.18\n",
      "Epoch  10/100 Batch 1040/1562 - Loss:  1.131, Seconds: 3.69\n",
      "Epoch  10/100 Batch 1060/1562 - Loss:  1.012, Seconds: 3.44\n",
      "Epoch  10/100 Batch 1080/1562 - Loss:  1.014, Seconds: 4.22\n",
      "Epoch  10/100 Batch 1100/1562 - Loss:  1.088, Seconds: 3.23\n",
      "Epoch  10/100 Batch 1120/1562 - Loss:  1.028, Seconds: 3.68\n",
      "Epoch  10/100 Batch 1140/1562 - Loss:  0.929, Seconds: 3.64\n",
      "Epoch  10/100 Batch 1160/1562 - Loss:  0.904, Seconds: 3.52\n",
      "Epoch  10/100 Batch 1180/1562 - Loss:  0.943, Seconds: 3.09\n",
      "Epoch  10/100 Batch 1200/1562 - Loss:  1.088, Seconds: 3.98\n",
      "Epoch  10/100 Batch 1220/1562 - Loss:  1.020, Seconds: 3.44\n",
      "Epoch  10/100 Batch 1240/1562 - Loss:  0.861, Seconds: 3.75\n",
      "Average loss for this update: 1.007 -- New Record!\n",
      "Epoch  10/100 Batch 1260/1562 - Loss:  1.069, Seconds: 3.46\n",
      "Epoch  10/100 Batch 1280/1562 - Loss:  1.154, Seconds: 3.89\n",
      "Epoch  10/100 Batch 1300/1562 - Loss:  1.137, Seconds: 3.31\n",
      "Epoch  10/100 Batch 1320/1562 - Loss:  1.090, Seconds: 3.92\n",
      "Epoch  10/100 Batch 1340/1562 - Loss:  1.079, Seconds: 3.56\n",
      "Epoch  10/100 Batch 1360/1562 - Loss:  1.042, Seconds: 3.71\n",
      "Epoch  10/100 Batch 1380/1562 - Loss:  1.049, Seconds: 3.94\n",
      "Epoch  10/100 Batch 1400/1562 - Loss:  0.953, Seconds: 3.90\n",
      "Epoch  10/100 Batch 1420/1562 - Loss:  0.829, Seconds: 3.24\n",
      "Epoch  10/100 Batch 1440/1562 - Loss:  0.933, Seconds: 3.72\n",
      "Epoch  10/100 Batch 1460/1562 - Loss:  0.941, Seconds: 3.91\n",
      "Epoch  10/100 Batch 1480/1562 - Loss:  0.889, Seconds: 3.90\n",
      "Epoch  10/100 Batch 1500/1562 - Loss:  0.976, Seconds: 3.70\n",
      "Epoch  10/100 Batch 1520/1562 - Loss:  1.203, Seconds: 4.48\n",
      "Epoch  10/100 Batch 1540/1562 - Loss:  1.382, Seconds: 3.74\n",
      "Average loss for this update: 1.066-- No Improvement.\n",
      "Epoch  10/100 Batch 1560/1562 - Loss:  1.405, Seconds: 3.97\n",
      "Epoch  11/100 Batch   20/1562 - Loss:  1.333, Seconds: 3.96\n",
      "Epoch  11/100 Batch   40/1562 - Loss:  1.175, Seconds: 3.43\n",
      "Epoch  11/100 Batch   60/1562 - Loss:  1.351, Seconds: 3.07\n",
      "Epoch  11/100 Batch   80/1562 - Loss:  1.156, Seconds: 2.86\n",
      "Epoch  11/100 Batch  100/1562 - Loss:  1.047, Seconds: 3.51\n",
      "Epoch  11/100 Batch  120/1562 - Loss:  1.065, Seconds: 3.15\n",
      "Epoch  11/100 Batch  140/1562 - Loss:  1.119, Seconds: 3.36\n",
      "Epoch  11/100 Batch  160/1562 - Loss:  1.060, Seconds: 2.95\n",
      "Epoch  11/100 Batch  180/1562 - Loss:  1.113, Seconds: 3.69\n",
      "Epoch  11/100 Batch  200/1562 - Loss:  1.009, Seconds: 3.09\n",
      "Epoch  11/100 Batch  220/1562 - Loss:  1.076, Seconds: 3.09\n",
      "Epoch  11/100 Batch  240/1562 - Loss:  1.036, Seconds: 2.92\n",
      "Epoch  11/100 Batch  260/1562 - Loss:  1.081, Seconds: 4.15\n",
      "Epoch  11/100 Batch  280/1562 - Loss:  0.987, Seconds: 3.38\n",
      "Epoch  11/100 Batch  300/1562 - Loss:  0.891, Seconds: 4.11\n",
      "Average loss for this update: 1.091-- No Improvement.\n",
      "Epoch  11/100 Batch  320/1562 - Loss:  0.882, Seconds: 3.56\n",
      "Epoch  11/100 Batch  340/1562 - Loss:  0.981, Seconds: 3.33\n",
      "Epoch  11/100 Batch  360/1562 - Loss:  1.004, Seconds: 3.94\n",
      "Epoch  11/100 Batch  380/1562 - Loss:  0.906, Seconds: 2.86\n",
      "Epoch  11/100 Batch  400/1562 - Loss:  1.001, Seconds: 4.13\n",
      "Epoch  11/100 Batch  420/1562 - Loss:  1.031, Seconds: 3.54\n",
      "Epoch  11/100 Batch  440/1562 - Loss:  1.087, Seconds: 3.39\n",
      "Epoch  11/100 Batch  460/1562 - Loss:  1.007, Seconds: 3.23\n",
      "Epoch  11/100 Batch  480/1562 - Loss:  0.943, Seconds: 3.56\n",
      "Epoch  11/100 Batch  500/1562 - Loss:  1.032, Seconds: 3.74\n",
      "Epoch  11/100 Batch  520/1562 - Loss:  0.918, Seconds: 4.20\n",
      "Epoch  11/100 Batch  540/1562 - Loss:  1.000, Seconds: 3.20\n",
      "Epoch  11/100 Batch  560/1562 - Loss:  0.989, Seconds: 3.54\n",
      "Epoch  11/100 Batch  580/1562 - Loss:  0.812, Seconds: 3.53\n",
      "Epoch  11/100 Batch  600/1562 - Loss:  0.777, Seconds: 3.38\n",
      "Epoch  11/100 Batch  620/1562 - Loss:  0.900, Seconds: 3.78\n",
      "Average loss for this update: 0.956 -- New Record!\n",
      "Epoch  11/100 Batch  640/1562 - Loss:  0.976, Seconds: 3.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11/100 Batch  660/1562 - Loss:  0.940, Seconds: 3.50\n",
      "Epoch  11/100 Batch  680/1562 - Loss:  0.882, Seconds: 4.15\n",
      "Epoch  11/100 Batch  700/1562 - Loss:  0.983, Seconds: 3.22\n",
      "Epoch  11/100 Batch  720/1562 - Loss:  1.083, Seconds: 4.11\n",
      "Epoch  11/100 Batch  740/1562 - Loss:  1.075, Seconds: 3.85\n",
      "Epoch  11/100 Batch  760/1562 - Loss:  1.068, Seconds: 2.98\n",
      "Epoch  11/100 Batch  780/1562 - Loss:  1.057, Seconds: 4.20\n",
      "Epoch  11/100 Batch  800/1562 - Loss:  0.936, Seconds: 3.44\n",
      "Epoch  11/100 Batch  820/1562 - Loss:  0.967, Seconds: 3.70\n",
      "Epoch  11/100 Batch  840/1562 - Loss:  0.964, Seconds: 3.57\n",
      "Epoch  11/100 Batch  860/1562 - Loss:  0.922, Seconds: 3.58\n",
      "Epoch  11/100 Batch  880/1562 - Loss:  0.743, Seconds: 3.15\n",
      "Epoch  11/100 Batch  900/1562 - Loss:  0.935, Seconds: 4.34\n",
      "Epoch  11/100 Batch  920/1562 - Loss:  0.978, Seconds: 3.53\n",
      "Average loss for this update: 0.965-- No Improvement.\n",
      "Epoch  11/100 Batch  940/1562 - Loss:  0.859, Seconds: 3.19\n",
      "Epoch  11/100 Batch  960/1562 - Loss:  0.901, Seconds: 3.85\n",
      "Epoch  11/100 Batch  980/1562 - Loss:  1.006, Seconds: 3.83\n",
      "Epoch  11/100 Batch 1000/1562 - Loss:  1.000, Seconds: 3.61\n",
      "Epoch  11/100 Batch 1020/1562 - Loss:  0.987, Seconds: 3.24\n",
      "Epoch  11/100 Batch 1040/1562 - Loss:  1.063, Seconds: 3.65\n",
      "Epoch  11/100 Batch 1060/1562 - Loss:  0.963, Seconds: 3.46\n",
      "Epoch  11/100 Batch 1080/1562 - Loss:  0.930, Seconds: 4.27\n",
      "Epoch  11/100 Batch 1100/1562 - Loss:  1.039, Seconds: 3.27\n",
      "Epoch  11/100 Batch 1120/1562 - Loss:  0.960, Seconds: 3.59\n",
      "Epoch  11/100 Batch 1140/1562 - Loss:  0.866, Seconds: 3.66\n",
      "Epoch  11/100 Batch 1160/1562 - Loss:  0.849, Seconds: 3.44\n",
      "Epoch  11/100 Batch 1180/1562 - Loss:  0.881, Seconds: 2.99\n",
      "Epoch  11/100 Batch 1200/1562 - Loss:  1.024, Seconds: 4.11\n",
      "Epoch  11/100 Batch 1220/1562 - Loss:  0.953, Seconds: 3.39\n",
      "Epoch  11/100 Batch 1240/1562 - Loss:  0.798, Seconds: 3.67\n",
      "Average loss for this update: 0.945 -- New Record!\n",
      "Epoch  11/100 Batch 1260/1562 - Loss:  0.981, Seconds: 3.51\n",
      "Epoch  11/100 Batch 1280/1562 - Loss:  1.067, Seconds: 3.97\n",
      "Epoch  11/100 Batch 1300/1562 - Loss:  1.070, Seconds: 3.49\n",
      "Epoch  11/100 Batch 1320/1562 - Loss:  1.012, Seconds: 3.89\n",
      "Epoch  11/100 Batch 1340/1562 - Loss:  1.003, Seconds: 3.43\n",
      "Epoch  11/100 Batch 1360/1562 - Loss:  0.975, Seconds: 3.63\n",
      "Epoch  11/100 Batch 1380/1562 - Loss:  0.989, Seconds: 3.84\n",
      "Epoch  11/100 Batch 1400/1562 - Loss:  0.873, Seconds: 3.93\n",
      "Epoch  11/100 Batch 1420/1562 - Loss:  0.772, Seconds: 3.35\n",
      "Epoch  11/100 Batch 1440/1562 - Loss:  0.872, Seconds: 3.62\n",
      "Epoch  11/100 Batch 1460/1562 - Loss:  0.878, Seconds: 3.94\n",
      "Epoch  11/100 Batch 1480/1562 - Loss:  0.845, Seconds: 3.94\n",
      "Epoch  11/100 Batch 1500/1562 - Loss:  0.898, Seconds: 3.75\n",
      "Epoch  11/100 Batch 1520/1562 - Loss:  1.120, Seconds: 4.36\n",
      "Epoch  11/100 Batch 1540/1562 - Loss:  1.288, Seconds: 3.90\n",
      "Average loss for this update: 0.993-- No Improvement.\n",
      "Epoch  11/100 Batch 1560/1562 - Loss:  1.315, Seconds: 3.90\n",
      "Epoch  12/100 Batch   20/1562 - Loss:  1.255, Seconds: 3.83\n",
      "Epoch  12/100 Batch   40/1562 - Loss:  1.106, Seconds: 3.48\n",
      "Epoch  12/100 Batch   60/1562 - Loss:  1.273, Seconds: 3.12\n",
      "Epoch  12/100 Batch   80/1562 - Loss:  1.084, Seconds: 2.92\n",
      "Epoch  12/100 Batch  100/1562 - Loss:  0.971, Seconds: 3.53\n",
      "Epoch  12/100 Batch  120/1562 - Loss:  0.989, Seconds: 3.07\n",
      "Epoch  12/100 Batch  140/1562 - Loss:  1.044, Seconds: 3.25\n",
      "Epoch  12/100 Batch  160/1562 - Loss:  1.011, Seconds: 2.81\n",
      "Epoch  12/100 Batch  180/1562 - Loss:  1.029, Seconds: 3.74\n",
      "Epoch  12/100 Batch  200/1562 - Loss:  0.943, Seconds: 3.04\n",
      "Epoch  12/100 Batch  220/1562 - Loss:  0.996, Seconds: 2.99\n",
      "Epoch  12/100 Batch  240/1562 - Loss:  0.961, Seconds: 2.88\n",
      "Epoch  12/100 Batch  260/1562 - Loss:  1.010, Seconds: 4.13\n",
      "Epoch  12/100 Batch  280/1562 - Loss:  0.913, Seconds: 3.30\n",
      "Epoch  12/100 Batch  300/1562 - Loss:  0.828, Seconds: 4.18\n",
      "Average loss for this update: 1.019-- No Improvement.\n",
      "Epoch  12/100 Batch  320/1562 - Loss:  0.825, Seconds: 3.47\n",
      "Epoch  12/100 Batch  340/1562 - Loss:  0.916, Seconds: 3.38\n",
      "Epoch  12/100 Batch  360/1562 - Loss:  0.937, Seconds: 3.90\n",
      "Epoch  12/100 Batch  380/1562 - Loss:  0.858, Seconds: 2.99\n",
      "Epoch  12/100 Batch  400/1562 - Loss:  0.925, Seconds: 4.21\n",
      "Epoch  12/100 Batch  420/1562 - Loss:  0.949, Seconds: 3.45\n",
      "Epoch  12/100 Batch  440/1562 - Loss:  1.023, Seconds: 3.37\n",
      "Epoch  12/100 Batch  460/1562 - Loss:  0.942, Seconds: 3.18\n",
      "Epoch  12/100 Batch  480/1562 - Loss:  0.883, Seconds: 3.61\n",
      "Epoch  12/100 Batch  500/1562 - Loss:  0.968, Seconds: 3.86\n",
      "Epoch  12/100 Batch  520/1562 - Loss:  0.858, Seconds: 4.13\n",
      "Epoch  12/100 Batch  540/1562 - Loss:  0.937, Seconds: 3.18\n",
      "Epoch  12/100 Batch  560/1562 - Loss:  0.922, Seconds: 3.54\n",
      "Epoch  12/100 Batch  580/1562 - Loss:  0.752, Seconds: 3.56\n",
      "Epoch  12/100 Batch  600/1562 - Loss:  0.722, Seconds: 3.35\n",
      "Epoch  12/100 Batch  620/1562 - Loss:  0.834, Seconds: 3.72\n",
      "Average loss for this update: 0.892 -- New Record!\n",
      "Epoch  12/100 Batch  640/1562 - Loss:  0.910, Seconds: 3.37\n",
      "Epoch  12/100 Batch  660/1562 - Loss:  0.879, Seconds: 3.60\n",
      "Epoch  12/100 Batch  680/1562 - Loss:  0.823, Seconds: 4.19\n",
      "Epoch  12/100 Batch  700/1562 - Loss:  0.908, Seconds: 3.23\n",
      "Epoch  12/100 Batch  720/1562 - Loss:  1.004, Seconds: 3.95\n",
      "Epoch  12/100 Batch  740/1562 - Loss:  1.030, Seconds: 3.77\n",
      "Epoch  12/100 Batch  760/1562 - Loss:  0.999, Seconds: 3.03\n",
      "Epoch  12/100 Batch  780/1562 - Loss:  0.977, Seconds: 4.16\n",
      "Epoch  12/100 Batch  800/1562 - Loss:  0.884, Seconds: 3.40\n",
      "Epoch  12/100 Batch  820/1562 - Loss:  0.918, Seconds: 3.83\n",
      "Epoch  12/100 Batch  840/1562 - Loss:  0.910, Seconds: 3.67\n",
      "Epoch  12/100 Batch  860/1562 - Loss:  0.861, Seconds: 3.59\n",
      "Epoch  12/100 Batch  880/1562 - Loss:  0.693, Seconds: 3.21\n",
      "Epoch  12/100 Batch  900/1562 - Loss:  0.878, Seconds: 3.97\n",
      "Epoch  12/100 Batch  920/1562 - Loss:  0.905, Seconds: 3.37\n",
      "Average loss for this update: 0.903-- No Improvement.\n",
      "Epoch  12/100 Batch  940/1562 - Loss:  0.795, Seconds: 3.15\n",
      "Epoch  12/100 Batch  960/1562 - Loss:  0.853, Seconds: 3.76\n",
      "Epoch  12/100 Batch  980/1562 - Loss:  0.918, Seconds: 3.84\n",
      "Epoch  12/100 Batch 1000/1562 - Loss:  0.929, Seconds: 3.55\n",
      "Epoch  12/100 Batch 1020/1562 - Loss:  0.936, Seconds: 3.14\n",
      "Epoch  12/100 Batch 1040/1562 - Loss:  0.991, Seconds: 3.64\n",
      "Epoch  12/100 Batch 1060/1562 - Loss:  0.890, Seconds: 3.48\n",
      "Epoch  12/100 Batch 1080/1562 - Loss:  0.882, Seconds: 4.25\n",
      "Epoch  12/100 Batch 1100/1562 - Loss:  0.946, Seconds: 3.22\n",
      "Epoch  12/100 Batch 1120/1562 - Loss:  0.913, Seconds: 3.66\n",
      "Epoch  12/100 Batch 1140/1562 - Loss:  0.815, Seconds: 3.62\n",
      "Epoch  12/100 Batch 1160/1562 - Loss:  0.796, Seconds: 3.40\n",
      "Epoch  12/100 Batch 1180/1562 - Loss:  0.824, Seconds: 3.04\n",
      "Epoch  12/100 Batch 1200/1562 - Loss:  0.965, Seconds: 4.14\n",
      "Epoch  12/100 Batch 1220/1562 - Loss:  0.895, Seconds: 3.47\n",
      "Epoch  12/100 Batch 1240/1562 - Loss:  0.740, Seconds: 3.57\n",
      "Average loss for this update: 0.883 -- New Record!\n",
      "Epoch  12/100 Batch 1260/1562 - Loss:  0.940, Seconds: 3.47\n",
      "Epoch  12/100 Batch 1280/1562 - Loss:  0.986, Seconds: 3.90\n",
      "Epoch  12/100 Batch 1300/1562 - Loss:  1.021, Seconds: 3.30\n",
      "Epoch  12/100 Batch 1320/1562 - Loss:  0.942, Seconds: 3.90\n",
      "Epoch  12/100 Batch 1340/1562 - Loss:  0.941, Seconds: 3.41\n",
      "Epoch  12/100 Batch 1360/1562 - Loss:  0.913, Seconds: 3.68\n",
      "Epoch  12/100 Batch 1380/1562 - Loss:  0.945, Seconds: 3.88\n",
      "Epoch  12/100 Batch 1400/1562 - Loss:  0.834, Seconds: 3.88\n",
      "Epoch  12/100 Batch 1420/1562 - Loss:  0.717, Seconds: 3.27\n",
      "Epoch  12/100 Batch 1440/1562 - Loss:  0.798, Seconds: 3.69\n",
      "Epoch  12/100 Batch 1460/1562 - Loss:  0.820, Seconds: 3.92\n",
      "Epoch  12/100 Batch 1480/1562 - Loss:  0.786, Seconds: 3.88\n",
      "Epoch  12/100 Batch 1500/1562 - Loss:  0.858, Seconds: 3.73\n",
      "Epoch  12/100 Batch 1520/1562 - Loss:  1.042, Seconds: 4.36\n",
      "Epoch  12/100 Batch 1540/1562 - Loss:  1.231, Seconds: 3.81\n",
      "Average loss for this update: 0.934-- No Improvement.\n",
      "Epoch  12/100 Batch 1560/1562 - Loss:  1.244, Seconds: 3.99\n",
      "Epoch  13/100 Batch   20/1562 - Loss:  1.180, Seconds: 3.84\n",
      "Epoch  13/100 Batch   40/1562 - Loss:  1.029, Seconds: 3.68\n",
      "Epoch  13/100 Batch   60/1562 - Loss:  1.194, Seconds: 3.10\n",
      "Epoch  13/100 Batch   80/1562 - Loss:  1.011, Seconds: 2.85\n",
      "Epoch  13/100 Batch  100/1562 - Loss:  0.927, Seconds: 3.41\n",
      "Epoch  13/100 Batch  120/1562 - Loss:  0.919, Seconds: 3.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13/100 Batch  140/1562 - Loss:  0.969, Seconds: 3.28\n",
      "Epoch  13/100 Batch  160/1562 - Loss:  0.931, Seconds: 2.85\n",
      "Epoch  13/100 Batch  180/1562 - Loss:  0.955, Seconds: 3.69\n",
      "Epoch  13/100 Batch  200/1562 - Loss:  0.891, Seconds: 3.00\n",
      "Epoch  13/100 Batch  220/1562 - Loss:  0.935, Seconds: 3.26\n",
      "Epoch  13/100 Batch  240/1562 - Loss:  0.885, Seconds: 2.91\n",
      "Epoch  13/100 Batch  260/1562 - Loss:  0.960, Seconds: 4.13\n",
      "Epoch  13/100 Batch  280/1562 - Loss:  0.854, Seconds: 3.36\n",
      "Epoch  13/100 Batch  300/1562 - Loss:  0.791, Seconds: 4.13\n",
      "Average loss for this update: 0.953-- No Improvement.\n",
      "Epoch  13/100 Batch  320/1562 - Loss:  0.765, Seconds: 3.60\n",
      "Epoch  13/100 Batch  340/1562 - Loss:  0.842, Seconds: 3.34\n",
      "Epoch  13/100 Batch  360/1562 - Loss:  0.886, Seconds: 3.87\n",
      "Epoch  13/100 Batch  380/1562 - Loss:  0.809, Seconds: 2.87\n",
      "Epoch  13/100 Batch  400/1562 - Loss:  0.871, Seconds: 4.14\n",
      "Epoch  13/100 Batch  420/1562 - Loss:  0.894, Seconds: 3.54\n",
      "Epoch  13/100 Batch  440/1562 - Loss:  0.945, Seconds: 3.32\n",
      "Epoch  13/100 Batch  460/1562 - Loss:  0.880, Seconds: 3.12\n",
      "Epoch  13/100 Batch  480/1562 - Loss:  0.812, Seconds: 3.49\n",
      "Epoch  13/100 Batch  500/1562 - Loss:  0.898, Seconds: 3.65\n",
      "Epoch  13/100 Batch  520/1562 - Loss:  0.801, Seconds: 4.12\n",
      "Epoch  13/100 Batch  540/1562 - Loss:  0.871, Seconds: 3.16\n",
      "Epoch  13/100 Batch  560/1562 - Loss:  0.861, Seconds: 3.52\n",
      "Epoch  13/100 Batch  580/1562 - Loss:  0.711, Seconds: 3.47\n",
      "Epoch  13/100 Batch  600/1562 - Loss:  0.689, Seconds: 3.31\n",
      "Epoch  13/100 Batch  620/1562 - Loss:  0.777, Seconds: 3.67\n",
      "Average loss for this update: 0.834 -- New Record!\n",
      "Epoch  13/100 Batch  640/1562 - Loss:  0.855, Seconds: 3.30\n",
      "Epoch  13/100 Batch  660/1562 - Loss:  0.811, Seconds: 3.52\n",
      "Epoch  13/100 Batch  680/1562 - Loss:  0.789, Seconds: 4.16\n",
      "Epoch  13/100 Batch  700/1562 - Loss:  0.852, Seconds: 3.18\n",
      "Epoch  13/100 Batch  720/1562 - Loss:  0.923, Seconds: 4.03\n",
      "Epoch  13/100 Batch  740/1562 - Loss:  0.950, Seconds: 3.81\n",
      "Epoch  13/100 Batch  760/1562 - Loss:  0.931, Seconds: 3.01\n",
      "Epoch  13/100 Batch  780/1562 - Loss:  0.917, Seconds: 4.28\n",
      "Epoch  13/100 Batch  800/1562 - Loss:  0.837, Seconds: 3.36\n",
      "Epoch  13/100 Batch  820/1562 - Loss:  0.840, Seconds: 3.82\n",
      "Epoch  13/100 Batch  840/1562 - Loss:  0.855, Seconds: 3.58\n",
      "Epoch  13/100 Batch  860/1562 - Loss:  0.813, Seconds: 3.64\n",
      "Epoch  13/100 Batch  880/1562 - Loss:  0.645, Seconds: 3.15\n",
      "Epoch  13/100 Batch  900/1562 - Loss:  0.833, Seconds: 3.96\n",
      "Epoch  13/100 Batch  920/1562 - Loss:  0.862, Seconds: 3.46\n",
      "Average loss for this update: 0.846-- No Improvement.\n",
      "Epoch  13/100 Batch  940/1562 - Loss:  0.762, Seconds: 3.18\n",
      "Epoch  13/100 Batch  960/1562 - Loss:  0.790, Seconds: 3.77\n",
      "Epoch  13/100 Batch  980/1562 - Loss:  0.848, Seconds: 3.86\n",
      "Epoch  13/100 Batch 1000/1562 - Loss:  0.869, Seconds: 3.74\n",
      "Epoch  13/100 Batch 1020/1562 - Loss:  0.868, Seconds: 3.17\n",
      "Epoch  13/100 Batch 1040/1562 - Loss:  0.933, Seconds: 3.60\n",
      "Epoch  13/100 Batch 1060/1562 - Loss:  0.841, Seconds: 3.44\n",
      "Epoch  13/100 Batch 1080/1562 - Loss:  0.831, Seconds: 4.26\n",
      "Epoch  13/100 Batch 1100/1562 - Loss:  0.905, Seconds: 3.23\n",
      "Epoch  13/100 Batch 1120/1562 - Loss:  0.863, Seconds: 3.71\n",
      "Epoch  13/100 Batch 1140/1562 - Loss:  0.764, Seconds: 3.72\n",
      "Epoch  13/100 Batch 1160/1562 - Loss:  0.763, Seconds: 3.48\n",
      "Epoch  13/100 Batch 1180/1562 - Loss:  0.782, Seconds: 3.06\n",
      "Epoch  13/100 Batch 1200/1562 - Loss:  0.912, Seconds: 4.06\n",
      "Epoch  13/100 Batch 1220/1562 - Loss:  0.839, Seconds: 3.44\n",
      "Epoch  13/100 Batch 1240/1562 - Loss:  0.699, Seconds: 3.74\n",
      "Average loss for this update: 0.831 -- New Record!\n",
      "Epoch  13/100 Batch 1260/1562 - Loss:  0.871, Seconds: 3.48\n",
      "Epoch  13/100 Batch 1280/1562 - Loss:  0.910, Seconds: 3.93\n",
      "Epoch  13/100 Batch 1300/1562 - Loss:  0.944, Seconds: 3.28\n",
      "Epoch  13/100 Batch 1320/1562 - Loss:  0.904, Seconds: 3.86\n",
      "Epoch  13/100 Batch 1340/1562 - Loss:  0.879, Seconds: 3.49\n",
      "Epoch  13/100 Batch 1360/1562 - Loss:  0.862, Seconds: 3.67\n",
      "Epoch  13/100 Batch 1380/1562 - Loss:  0.878, Seconds: 3.91\n",
      "Epoch  13/100 Batch 1400/1562 - Loss:  0.769, Seconds: 4.17\n",
      "Epoch  13/100 Batch 1420/1562 - Loss:  0.665, Seconds: 3.36\n",
      "Epoch  13/100 Batch 1440/1562 - Loss:  0.760, Seconds: 3.66\n",
      "Epoch  13/100 Batch 1460/1562 - Loss:  0.784, Seconds: 3.96\n",
      "Epoch  13/100 Batch 1480/1562 - Loss:  0.749, Seconds: 3.92\n",
      "Epoch  13/100 Batch 1500/1562 - Loss:  0.796, Seconds: 3.77\n",
      "Epoch  13/100 Batch 1520/1562 - Loss:  0.989, Seconds: 4.40\n",
      "Epoch  13/100 Batch 1540/1562 - Loss:  1.155, Seconds: 3.79\n",
      "Average loss for this update: 0.876-- No Improvement.\n",
      "Epoch  13/100 Batch 1560/1562 - Loss:  1.184, Seconds: 3.97\n",
      "Epoch  14/100 Batch   20/1562 - Loss:  1.103, Seconds: 3.94\n",
      "Epoch  14/100 Batch   40/1562 - Loss:  0.976, Seconds: 3.48\n",
      "Epoch  14/100 Batch   60/1562 - Loss:  1.139, Seconds: 3.06\n",
      "Epoch  14/100 Batch   80/1562 - Loss:  0.962, Seconds: 2.85\n",
      "Epoch  14/100 Batch  100/1562 - Loss:  0.861, Seconds: 3.45\n",
      "Epoch  14/100 Batch  120/1562 - Loss:  0.871, Seconds: 3.11\n",
      "Epoch  14/100 Batch  140/1562 - Loss:  0.919, Seconds: 3.33\n",
      "Epoch  14/100 Batch  160/1562 - Loss:  0.874, Seconds: 2.90\n",
      "Epoch  14/100 Batch  180/1562 - Loss:  0.900, Seconds: 3.67\n",
      "Epoch  14/100 Batch  200/1562 - Loss:  0.832, Seconds: 3.09\n",
      "Epoch  14/100 Batch  220/1562 - Loss:  0.882, Seconds: 3.11\n",
      "Epoch  14/100 Batch  240/1562 - Loss:  0.842, Seconds: 3.00\n",
      "Epoch  14/100 Batch  260/1562 - Loss:  0.895, Seconds: 4.05\n",
      "Epoch  14/100 Batch  280/1562 - Loss:  0.811, Seconds: 3.32\n",
      "Epoch  14/100 Batch  300/1562 - Loss:  0.749, Seconds: 4.12\n",
      "Average loss for this update: 0.899-- No Improvement.\n",
      "Epoch  14/100 Batch  320/1562 - Loss:  0.724, Seconds: 3.49\n",
      "Epoch  14/100 Batch  340/1562 - Loss:  0.795, Seconds: 3.33\n",
      "Epoch  14/100 Batch  360/1562 - Loss:  0.799, Seconds: 4.00\n",
      "Epoch  14/100 Batch  380/1562 - Loss:  0.755, Seconds: 2.90\n",
      "Epoch  14/100 Batch  400/1562 - Loss:  0.820, Seconds: 4.13\n",
      "Epoch  14/100 Batch  420/1562 - Loss:  0.853, Seconds: 3.59\n",
      "Epoch  14/100 Batch  440/1562 - Loss:  0.904, Seconds: 3.33\n",
      "Epoch  14/100 Batch  460/1562 - Loss:  0.837, Seconds: 3.12\n",
      "Epoch  14/100 Batch  480/1562 - Loss:  0.747, Seconds: 3.55\n",
      "Epoch  14/100 Batch  500/1562 - Loss:  0.862, Seconds: 3.81\n",
      "Epoch  14/100 Batch  520/1562 - Loss:  0.762, Seconds: 4.13\n",
      "Epoch  14/100 Batch  540/1562 - Loss:  0.834, Seconds: 3.09\n",
      "Epoch  14/100 Batch  560/1562 - Loss:  0.793, Seconds: 3.53\n",
      "Epoch  14/100 Batch  580/1562 - Loss:  0.669, Seconds: 3.56\n",
      "Epoch  14/100 Batch  600/1562 - Loss:  0.631, Seconds: 3.40\n",
      "Epoch  14/100 Batch  620/1562 - Loss:  0.746, Seconds: 3.82\n",
      "Average loss for this update: 0.785 -- New Record!\n",
      "Epoch  14/100 Batch  640/1562 - Loss:  0.801, Seconds: 3.39\n",
      "Epoch  14/100 Batch  660/1562 - Loss:  0.781, Seconds: 3.65\n",
      "Epoch  14/100 Batch  680/1562 - Loss:  0.714, Seconds: 4.19\n",
      "Epoch  14/100 Batch  700/1562 - Loss:  0.802, Seconds: 3.23\n",
      "Epoch  14/100 Batch  720/1562 - Loss:  0.882, Seconds: 4.08\n",
      "Epoch  14/100 Batch  740/1562 - Loss:  0.889, Seconds: 3.90\n",
      "Epoch  14/100 Batch  760/1562 - Loss:  0.869, Seconds: 3.03\n",
      "Epoch  14/100 Batch  780/1562 - Loss:  0.873, Seconds: 4.28\n",
      "Epoch  14/100 Batch  800/1562 - Loss:  0.792, Seconds: 3.40\n",
      "Epoch  14/100 Batch  820/1562 - Loss:  0.794, Seconds: 3.80\n",
      "Epoch  14/100 Batch  840/1562 - Loss:  0.810, Seconds: 3.75\n",
      "Epoch  14/100 Batch  860/1562 - Loss:  0.762, Seconds: 3.57\n",
      "Epoch  14/100 Batch  880/1562 - Loss:  0.597, Seconds: 3.18\n",
      "Epoch  14/100 Batch  900/1562 - Loss:  0.776, Seconds: 4.01\n",
      "Epoch  14/100 Batch  920/1562 - Loss:  0.818, Seconds: 3.42\n",
      "Average loss for this update: 0.795-- No Improvement.\n",
      "Epoch  14/100 Batch  940/1562 - Loss:  0.703, Seconds: 3.21\n",
      "Epoch  14/100 Batch  960/1562 - Loss:  0.734, Seconds: 3.81\n",
      "Epoch  14/100 Batch  980/1562 - Loss:  0.805, Seconds: 3.88\n",
      "Epoch  14/100 Batch 1000/1562 - Loss:  0.798, Seconds: 3.67\n",
      "Epoch  14/100 Batch 1020/1562 - Loss:  0.824, Seconds: 3.25\n",
      "Epoch  14/100 Batch 1040/1562 - Loss:  0.861, Seconds: 3.68\n",
      "Epoch  14/100 Batch 1060/1562 - Loss:  0.774, Seconds: 3.46\n",
      "Epoch  14/100 Batch 1080/1562 - Loss:  0.777, Seconds: 4.25\n",
      "Epoch  14/100 Batch 1100/1562 - Loss:  0.856, Seconds: 3.29\n",
      "Epoch  14/100 Batch 1120/1562 - Loss:  0.804, Seconds: 3.68\n",
      "Epoch  14/100 Batch 1140/1562 - Loss:  0.737, Seconds: 3.59\n",
      "Epoch  14/100 Batch 1160/1562 - Loss:  0.715, Seconds: 3.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14/100 Batch 1180/1562 - Loss:  0.734, Seconds: 3.09\n",
      "Epoch  14/100 Batch 1200/1562 - Loss:  0.854, Seconds: 4.09\n",
      "Epoch  14/100 Batch 1220/1562 - Loss:  0.772, Seconds: 3.52\n",
      "Epoch  14/100 Batch 1240/1562 - Loss:  0.643, Seconds: 3.58\n",
      "Average loss for this update: 0.776 -- New Record!\n",
      "Epoch  14/100 Batch 1260/1562 - Loss:  0.806, Seconds: 3.46\n",
      "Epoch  14/100 Batch 1280/1562 - Loss:  0.854, Seconds: 3.96\n",
      "Epoch  14/100 Batch 1300/1562 - Loss:  0.886, Seconds: 3.31\n",
      "Epoch  14/100 Batch 1320/1562 - Loss:  0.848, Seconds: 3.85\n",
      "Epoch  14/100 Batch 1340/1562 - Loss:  0.809, Seconds: 3.46\n",
      "Epoch  14/100 Batch 1360/1562 - Loss:  0.795, Seconds: 3.66\n",
      "Epoch  14/100 Batch 1380/1562 - Loss:  0.833, Seconds: 3.88\n",
      "Epoch  14/100 Batch 1400/1562 - Loss:  0.724, Seconds: 3.91\n",
      "Epoch  14/100 Batch 1420/1562 - Loss:  0.622, Seconds: 3.39\n",
      "Epoch  14/100 Batch 1440/1562 - Loss:  0.725, Seconds: 3.64\n",
      "Epoch  14/100 Batch 1460/1562 - Loss:  0.734, Seconds: 3.92\n",
      "Epoch  14/100 Batch 1480/1562 - Loss:  0.709, Seconds: 3.95\n",
      "Epoch  14/100 Batch 1500/1562 - Loss:  0.759, Seconds: 3.67\n",
      "Epoch  14/100 Batch 1520/1562 - Loss:  0.923, Seconds: 4.41\n",
      "Epoch  14/100 Batch 1540/1562 - Loss:  1.108, Seconds: 3.77\n",
      "Average loss for this update: 0.824-- No Improvement.\n",
      "Epoch  14/100 Batch 1560/1562 - Loss:  1.112, Seconds: 4.01\n",
      "Epoch  15/100 Batch   20/1562 - Loss:  1.034, Seconds: 3.92\n",
      "Epoch  15/100 Batch   40/1562 - Loss:  0.917, Seconds: 3.43\n",
      "Epoch  15/100 Batch   60/1562 - Loss:  1.056, Seconds: 3.09\n",
      "Epoch  15/100 Batch   80/1562 - Loss:  0.914, Seconds: 2.85\n",
      "Epoch  15/100 Batch  100/1562 - Loss:  0.825, Seconds: 3.48\n",
      "Epoch  15/100 Batch  120/1562 - Loss:  0.807, Seconds: 3.07\n",
      "Epoch  15/100 Batch  140/1562 - Loss:  0.862, Seconds: 3.34\n",
      "Epoch  15/100 Batch  160/1562 - Loss:  0.816, Seconds: 2.94\n",
      "Epoch  15/100 Batch  180/1562 - Loss:  0.840, Seconds: 3.65\n",
      "Epoch  15/100 Batch  200/1562 - Loss:  0.766, Seconds: 3.11\n",
      "Epoch  15/100 Batch  220/1562 - Loss:  0.821, Seconds: 3.13\n",
      "Epoch  15/100 Batch  240/1562 - Loss:  0.774, Seconds: 2.88\n",
      "Epoch  15/100 Batch  260/1562 - Loss:  0.845, Seconds: 4.13\n",
      "Epoch  15/100 Batch  280/1562 - Loss:  0.751, Seconds: 3.36\n",
      "Epoch  15/100 Batch  300/1562 - Loss:  0.695, Seconds: 4.12\n",
      "Average loss for this update: 0.841-- No Improvement.\n",
      "Epoch  15/100 Batch  320/1562 - Loss:  0.680, Seconds: 3.54\n",
      "Epoch  15/100 Batch  340/1562 - Loss:  0.745, Seconds: 3.22\n",
      "Epoch  15/100 Batch  360/1562 - Loss:  0.779, Seconds: 3.92\n",
      "Epoch  15/100 Batch  380/1562 - Loss:  0.714, Seconds: 2.90\n",
      "Epoch  15/100 Batch  400/1562 - Loss:  0.766, Seconds: 4.17\n",
      "Epoch  15/100 Batch  420/1562 - Loss:  0.777, Seconds: 3.60\n",
      "Epoch  15/100 Batch  440/1562 - Loss:  0.843, Seconds: 3.37\n",
      "Epoch  15/100 Batch  460/1562 - Loss:  0.786, Seconds: 3.12\n",
      "Epoch  15/100 Batch  480/1562 - Loss:  0.704, Seconds: 3.54\n",
      "Epoch  15/100 Batch  500/1562 - Loss:  0.811, Seconds: 3.79\n",
      "Epoch  15/100 Batch  520/1562 - Loss:  0.721, Seconds: 4.21\n",
      "Epoch  15/100 Batch  540/1562 - Loss:  0.775, Seconds: 3.06\n",
      "Epoch  15/100 Batch  560/1562 - Loss:  0.746, Seconds: 3.51\n",
      "Epoch  15/100 Batch  580/1562 - Loss:  0.624, Seconds: 3.58\n",
      "Epoch  15/100 Batch  600/1562 - Loss:  0.601, Seconds: 3.37\n",
      "Epoch  15/100 Batch  620/1562 - Loss:  0.691, Seconds: 3.79\n",
      "Average loss for this update: 0.737 -- New Record!\n",
      "Epoch  15/100 Batch  640/1562 - Loss:  0.757, Seconds: 3.38\n",
      "Epoch  15/100 Batch  660/1562 - Loss:  0.728, Seconds: 3.55\n",
      "Epoch  15/100 Batch  680/1562 - Loss:  0.689, Seconds: 4.19\n",
      "Epoch  15/100 Batch  700/1562 - Loss:  0.755, Seconds: 3.22\n",
      "Epoch  15/100 Batch  720/1562 - Loss:  0.810, Seconds: 3.95\n",
      "Epoch  15/100 Batch  740/1562 - Loss:  0.840, Seconds: 3.73\n",
      "Epoch  15/100 Batch  760/1562 - Loss:  0.822, Seconds: 3.00\n",
      "Epoch  15/100 Batch  780/1562 - Loss:  0.808, Seconds: 4.22\n",
      "Epoch  15/100 Batch  800/1562 - Loss:  0.748, Seconds: 3.45\n",
      "Epoch  15/100 Batch  820/1562 - Loss:  0.740, Seconds: 3.83\n",
      "Epoch  15/100 Batch  840/1562 - Loss:  0.760, Seconds: 3.62\n",
      "Epoch  15/100 Batch  860/1562 - Loss:  0.704, Seconds: 3.63\n",
      "Epoch  15/100 Batch  880/1562 - Loss:  0.589, Seconds: 3.21\n",
      "Epoch  15/100 Batch  900/1562 - Loss:  0.747, Seconds: 4.11\n",
      "Epoch  15/100 Batch  920/1562 - Loss:  0.762, Seconds: 3.40\n",
      "Average loss for this update: 0.749-- No Improvement.\n",
      "Epoch  15/100 Batch  940/1562 - Loss:  0.662, Seconds: 3.12\n",
      "Epoch  15/100 Batch  960/1562 - Loss:  0.692, Seconds: 3.83\n",
      "Epoch  15/100 Batch  980/1562 - Loss:  0.759, Seconds: 3.80\n",
      "Epoch  15/100 Batch 1000/1562 - Loss:  0.755, Seconds: 3.61\n",
      "Epoch  15/100 Batch 1020/1562 - Loss:  0.790, Seconds: 3.23\n",
      "Epoch  15/100 Batch 1040/1562 - Loss:  0.820, Seconds: 3.65\n",
      "Epoch  15/100 Batch 1060/1562 - Loss:  0.737, Seconds: 3.45\n",
      "Epoch  15/100 Batch 1080/1562 - Loss:  0.731, Seconds: 4.23\n",
      "Epoch  15/100 Batch 1100/1562 - Loss:  0.809, Seconds: 3.18\n",
      "Epoch  15/100 Batch 1120/1562 - Loss:  0.758, Seconds: 3.68\n",
      "Epoch  15/100 Batch 1140/1562 - Loss:  0.698, Seconds: 3.68\n",
      "Epoch  15/100 Batch 1160/1562 - Loss:  0.671, Seconds: 3.47\n",
      "Epoch  15/100 Batch 1180/1562 - Loss:  0.680, Seconds: 3.07\n",
      "Epoch  15/100 Batch 1200/1562 - Loss:  0.798, Seconds: 4.07\n",
      "Epoch  15/100 Batch 1220/1562 - Loss:  0.732, Seconds: 3.47\n",
      "Epoch  15/100 Batch 1240/1562 - Loss:  0.618, Seconds: 3.70\n",
      "Average loss for this update: 0.734 -- New Record!\n",
      "Epoch  15/100 Batch 1260/1562 - Loss:  0.761, Seconds: 3.50\n",
      "Epoch  15/100 Batch 1280/1562 - Loss:  0.803, Seconds: 4.05\n",
      "Epoch  15/100 Batch 1300/1562 - Loss:  0.815, Seconds: 3.29\n",
      "Epoch  15/100 Batch 1320/1562 - Loss:  0.785, Seconds: 3.92\n",
      "Epoch  15/100 Batch 1340/1562 - Loss:  0.767, Seconds: 3.57\n",
      "Epoch  15/100 Batch 1360/1562 - Loss:  0.762, Seconds: 3.70\n",
      "Epoch  15/100 Batch 1380/1562 - Loss:  0.778, Seconds: 3.95\n",
      "Epoch  15/100 Batch 1400/1562 - Loss:  0.696, Seconds: 3.94\n",
      "Epoch  15/100 Batch 1420/1562 - Loss:  0.586, Seconds: 3.32\n",
      "Epoch  15/100 Batch 1440/1562 - Loss:  0.674, Seconds: 3.65\n",
      "Epoch  15/100 Batch 1460/1562 - Loss:  0.682, Seconds: 3.94\n",
      "Epoch  15/100 Batch 1480/1562 - Loss:  0.665, Seconds: 3.87\n",
      "Epoch  15/100 Batch 1500/1562 - Loss:  0.708, Seconds: 3.71\n",
      "Epoch  15/100 Batch 1520/1562 - Loss:  0.884, Seconds: 4.33\n",
      "Epoch  15/100 Batch 1540/1562 - Loss:  1.039, Seconds: 3.73\n",
      "Average loss for this update: 0.773-- No Improvement.\n",
      "Epoch  15/100 Batch 1560/1562 - Loss:  1.037, Seconds: 3.96\n",
      "Epoch  16/100 Batch   20/1562 - Loss:  0.976, Seconds: 3.84\n",
      "Epoch  16/100 Batch   40/1562 - Loss:  0.871, Seconds: 3.47\n",
      "Epoch  16/100 Batch   60/1562 - Loss:  1.012, Seconds: 3.06\n",
      "Epoch  16/100 Batch   80/1562 - Loss:  0.864, Seconds: 2.86\n",
      "Epoch  16/100 Batch  100/1562 - Loss:  0.768, Seconds: 3.50\n",
      "Epoch  16/100 Batch  120/1562 - Loss:  0.754, Seconds: 3.15\n",
      "Epoch  16/100 Batch  140/1562 - Loss:  0.807, Seconds: 3.28\n",
      "Epoch  16/100 Batch  160/1562 - Loss:  0.761, Seconds: 3.00\n",
      "Epoch  16/100 Batch  180/1562 - Loss:  0.796, Seconds: 3.70\n",
      "Epoch  16/100 Batch  200/1562 - Loss:  0.725, Seconds: 3.12\n",
      "Epoch  16/100 Batch  220/1562 - Loss:  0.769, Seconds: 3.12\n",
      "Epoch  16/100 Batch  240/1562 - Loss:  0.743, Seconds: 2.90\n",
      "Epoch  16/100 Batch  260/1562 - Loss:  0.780, Seconds: 4.11\n",
      "Epoch  16/100 Batch  280/1562 - Loss:  0.719, Seconds: 3.28\n",
      "Epoch  16/100 Batch  300/1562 - Loss:  0.652, Seconds: 4.08\n",
      "Average loss for this update: 0.793-- No Improvement.\n",
      "Epoch  16/100 Batch  320/1562 - Loss:  0.650, Seconds: 3.54\n",
      "Epoch  16/100 Batch  340/1562 - Loss:  0.704, Seconds: 3.26\n",
      "Epoch  16/100 Batch  360/1562 - Loss:  0.726, Seconds: 3.91\n",
      "Epoch  16/100 Batch  380/1562 - Loss:  0.661, Seconds: 2.90\n",
      "Epoch  16/100 Batch  400/1562 - Loss:  0.721, Seconds: 4.13\n",
      "Epoch  16/100 Batch  420/1562 - Loss:  0.729, Seconds: 3.56\n",
      "Epoch  16/100 Batch  440/1562 - Loss:  0.815, Seconds: 3.30\n",
      "Epoch  16/100 Batch  460/1562 - Loss:  0.745, Seconds: 3.10\n",
      "Epoch  16/100 Batch  480/1562 - Loss:  0.674, Seconds: 3.53\n",
      "Epoch  16/100 Batch  500/1562 - Loss:  0.767, Seconds: 3.71\n",
      "Epoch  16/100 Batch  520/1562 - Loss:  0.660, Seconds: 4.17\n",
      "Epoch  16/100 Batch  540/1562 - Loss:  0.722, Seconds: 3.14\n",
      "Epoch  16/100 Batch  560/1562 - Loss:  0.708, Seconds: 3.53\n",
      "Epoch  16/100 Batch  580/1562 - Loss:  0.589, Seconds: 3.59\n",
      "Epoch  16/100 Batch  600/1562 - Loss:  0.557, Seconds: 3.31\n",
      "Epoch  16/100 Batch  620/1562 - Loss:  0.668, Seconds: 3.79\n",
      "Average loss for this update: 0.695 -- New Record!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  16/100 Batch  640/1562 - Loss:  0.714, Seconds: 3.39\n",
      "Epoch  16/100 Batch  660/1562 - Loss:  0.685, Seconds: 3.54\n",
      "Epoch  16/100 Batch  680/1562 - Loss:  0.633, Seconds: 4.16\n",
      "Epoch  16/100 Batch  700/1562 - Loss:  0.710, Seconds: 3.19\n",
      "Epoch  16/100 Batch  720/1562 - Loss:  0.758, Seconds: 3.99\n",
      "Epoch  16/100 Batch  740/1562 - Loss:  0.779, Seconds: 3.85\n",
      "Epoch  16/100 Batch  760/1562 - Loss:  0.772, Seconds: 2.98\n",
      "Epoch  16/100 Batch  780/1562 - Loss:  0.766, Seconds: 4.20\n",
      "Epoch  16/100 Batch  800/1562 - Loss:  0.706, Seconds: 3.40\n",
      "Epoch  16/100 Batch  820/1562 - Loss:  0.707, Seconds: 3.85\n",
      "Epoch  16/100 Batch  840/1562 - Loss:  0.719, Seconds: 3.57\n",
      "Epoch  16/100 Batch  860/1562 - Loss:  0.685, Seconds: 3.55\n",
      "Epoch  16/100 Batch  880/1562 - Loss:  0.548, Seconds: 3.18\n",
      "Epoch  16/100 Batch  900/1562 - Loss:  0.700, Seconds: 4.04\n",
      "Epoch  16/100 Batch  920/1562 - Loss:  0.718, Seconds: 3.41\n",
      "Average loss for this update: 0.705-- No Improvement.\n",
      "Epoch  16/100 Batch  940/1562 - Loss:  0.624, Seconds: 3.27\n",
      "Epoch  16/100 Batch  960/1562 - Loss:  0.660, Seconds: 3.88\n",
      "Epoch  16/100 Batch  980/1562 - Loss:  0.700, Seconds: 3.91\n",
      "Epoch  16/100 Batch 1000/1562 - Loss:  0.715, Seconds: 3.69\n",
      "Epoch  16/100 Batch 1020/1562 - Loss:  0.729, Seconds: 3.27\n",
      "Epoch  16/100 Batch 1040/1562 - Loss:  0.760, Seconds: 3.67\n",
      "Epoch  16/100 Batch 1060/1562 - Loss:  0.702, Seconds: 3.48\n",
      "Epoch  16/100 Batch 1080/1562 - Loss:  0.692, Seconds: 4.37\n",
      "Epoch  16/100 Batch 1100/1562 - Loss:  0.751, Seconds: 3.21\n",
      "Epoch  16/100 Batch 1120/1562 - Loss:  0.731, Seconds: 3.65\n",
      "Epoch  16/100 Batch 1140/1562 - Loss:  0.667, Seconds: 3.67\n",
      "Epoch  16/100 Batch 1160/1562 - Loss:  0.630, Seconds: 3.41\n",
      "Epoch  16/100 Batch 1180/1562 - Loss:  0.649, Seconds: 2.99\n",
      "Epoch  16/100 Batch 1200/1562 - Loss:  0.752, Seconds: 4.07\n",
      "Epoch  16/100 Batch 1220/1562 - Loss:  0.696, Seconds: 3.38\n",
      "Epoch  16/100 Batch 1240/1562 - Loss:  0.573, Seconds: 3.62\n",
      "Average loss for this update: 0.691 -- New Record!\n",
      "Epoch  16/100 Batch 1260/1562 - Loss:  0.720, Seconds: 3.54\n",
      "Epoch  16/100 Batch 1280/1562 - Loss:  0.751, Seconds: 3.93\n",
      "Epoch  16/100 Batch 1300/1562 - Loss:  0.775, Seconds: 3.28\n",
      "Epoch  16/100 Batch 1320/1562 - Loss:  0.749, Seconds: 4.02\n",
      "Epoch  16/100 Batch 1340/1562 - Loss:  0.716, Seconds: 3.58\n",
      "Epoch  16/100 Batch 1360/1562 - Loss:  0.711, Seconds: 3.75\n",
      "Epoch  16/100 Batch 1380/1562 - Loss:  0.756, Seconds: 3.98\n",
      "Epoch  16/100 Batch 1400/1562 - Loss:  0.665, Seconds: 3.88\n",
      "Epoch  16/100 Batch 1420/1562 - Loss:  0.555, Seconds: 3.22\n",
      "Epoch  16/100 Batch 1440/1562 - Loss:  0.625, Seconds: 3.67\n",
      "Epoch  16/100 Batch 1460/1562 - Loss:  0.645, Seconds: 3.89\n",
      "Epoch  16/100 Batch 1480/1562 - Loss:  0.636, Seconds: 3.91\n",
      "Epoch  16/100 Batch 1500/1562 - Loss:  0.676, Seconds: 3.70\n",
      "Epoch  16/100 Batch 1520/1562 - Loss:  0.830, Seconds: 4.34\n",
      "Epoch  16/100 Batch 1540/1562 - Loss:  0.966, Seconds: 3.73\n",
      "Average loss for this update: 0.732-- No Improvement.\n",
      "Epoch  16/100 Batch 1560/1562 - Loss:  0.996, Seconds: 3.90\n",
      "Epoch  17/100 Batch   20/1562 - Loss:  0.928, Seconds: 3.85\n",
      "Epoch  17/100 Batch   40/1562 - Loss:  0.819, Seconds: 3.48\n",
      "Epoch  17/100 Batch   60/1562 - Loss:  0.947, Seconds: 3.02\n",
      "Epoch  17/100 Batch   80/1562 - Loss:  0.810, Seconds: 2.86\n",
      "Epoch  17/100 Batch  100/1562 - Loss:  0.726, Seconds: 3.50\n",
      "Epoch  17/100 Batch  120/1562 - Loss:  0.730, Seconds: 3.09\n",
      "Epoch  17/100 Batch  140/1562 - Loss:  0.752, Seconds: 3.29\n",
      "Epoch  17/100 Batch  160/1562 - Loss:  0.723, Seconds: 2.92\n",
      "Epoch  17/100 Batch  180/1562 - Loss:  0.748, Seconds: 3.70\n",
      "Epoch  17/100 Batch  200/1562 - Loss:  0.672, Seconds: 3.14\n",
      "Epoch  17/100 Batch  220/1562 - Loss:  0.728, Seconds: 3.06\n",
      "Epoch  17/100 Batch  240/1562 - Loss:  0.690, Seconds: 2.89\n",
      "Epoch  17/100 Batch  260/1562 - Loss:  0.753, Seconds: 4.10\n",
      "Epoch  17/100 Batch  280/1562 - Loss:  0.661, Seconds: 3.33\n",
      "Epoch  17/100 Batch  300/1562 - Loss:  0.624, Seconds: 4.10\n",
      "Average loss for this update: 0.748-- No Improvement.\n",
      "Epoch  17/100 Batch  320/1562 - Loss:  0.613, Seconds: 3.42\n",
      "Epoch  17/100 Batch  340/1562 - Loss:  0.671, Seconds: 3.39\n",
      "Epoch  17/100 Batch  360/1562 - Loss:  0.675, Seconds: 3.93\n",
      "Epoch  17/100 Batch  380/1562 - Loss:  0.621, Seconds: 2.83\n",
      "Epoch  17/100 Batch  400/1562 - Loss:  0.669, Seconds: 4.10\n",
      "Epoch  17/100 Batch  420/1562 - Loss:  0.685, Seconds: 3.61\n",
      "Epoch  17/100 Batch  440/1562 - Loss:  0.735, Seconds: 3.37\n",
      "Epoch  17/100 Batch  460/1562 - Loss:  0.703, Seconds: 3.20\n",
      "Epoch  17/100 Batch  480/1562 - Loss:  0.624, Seconds: 3.59\n",
      "Epoch  17/100 Batch  500/1562 - Loss:  0.727, Seconds: 3.79\n",
      "Epoch  17/100 Batch  520/1562 - Loss:  0.637, Seconds: 4.15\n",
      "Epoch  17/100 Batch  540/1562 - Loss:  0.703, Seconds: 3.12\n",
      "Epoch  17/100 Batch  560/1562 - Loss:  0.651, Seconds: 3.62\n",
      "Epoch  17/100 Batch  580/1562 - Loss:  0.565, Seconds: 3.47\n",
      "Epoch  17/100 Batch  600/1562 - Loss:  0.518, Seconds: 3.32\n",
      "Epoch  17/100 Batch  620/1562 - Loss:  0.625, Seconds: 3.69\n",
      "Average loss for this update: 0.652 -- New Record!\n",
      "Epoch  17/100 Batch  640/1562 - Loss:  0.676, Seconds: 3.37\n",
      "Epoch  17/100 Batch  660/1562 - Loss:  0.640, Seconds: 3.59\n",
      "Epoch  17/100 Batch  680/1562 - Loss:  0.595, Seconds: 4.14\n",
      "Epoch  17/100 Batch  700/1562 - Loss:  0.673, Seconds: 3.18\n",
      "Epoch  17/100 Batch  720/1562 - Loss:  0.718, Seconds: 3.97\n",
      "Epoch  17/100 Batch  740/1562 - Loss:  0.762, Seconds: 3.88\n",
      "Epoch  17/100 Batch  760/1562 - Loss:  0.729, Seconds: 2.95\n",
      "Epoch  17/100 Batch  780/1562 - Loss:  0.723, Seconds: 4.15\n",
      "Epoch  17/100 Batch  800/1562 - Loss:  0.652, Seconds: 3.39\n",
      "Epoch  17/100 Batch  820/1562 - Loss:  0.655, Seconds: 3.82\n",
      "Epoch  17/100 Batch  840/1562 - Loss:  0.673, Seconds: 3.60\n",
      "Epoch  17/100 Batch  860/1562 - Loss:  0.640, Seconds: 3.62\n",
      "Epoch  17/100 Batch  880/1562 - Loss:  0.527, Seconds: 3.18\n",
      "Epoch  17/100 Batch  900/1562 - Loss:  0.667, Seconds: 3.97\n",
      "Epoch  17/100 Batch  920/1562 - Loss:  0.684, Seconds: 3.63\n",
      "Average loss for this update: 0.665-- No Improvement.\n",
      "Epoch  17/100 Batch  940/1562 - Loss:  0.581, Seconds: 3.20\n",
      "Epoch  17/100 Batch  960/1562 - Loss:  0.633, Seconds: 3.83\n",
      "Epoch  17/100 Batch  980/1562 - Loss:  0.665, Seconds: 3.82\n",
      "Epoch  17/100 Batch 1000/1562 - Loss:  0.674, Seconds: 3.67\n",
      "Epoch  17/100 Batch 1020/1562 - Loss:  0.696, Seconds: 3.25\n",
      "Epoch  17/100 Batch 1040/1562 - Loss:  0.716, Seconds: 3.63\n",
      "Epoch  17/100 Batch 1060/1562 - Loss:  0.651, Seconds: 3.42\n",
      "Epoch  17/100 Batch 1080/1562 - Loss:  0.647, Seconds: 4.32\n",
      "Epoch  17/100 Batch 1100/1562 - Loss:  0.720, Seconds: 3.17\n",
      "Epoch  17/100 Batch 1120/1562 - Loss:  0.687, Seconds: 3.63\n",
      "Epoch  17/100 Batch 1140/1562 - Loss:  0.620, Seconds: 3.63\n",
      "Epoch  17/100 Batch 1160/1562 - Loss:  0.594, Seconds: 3.40\n",
      "Epoch  17/100 Batch 1180/1562 - Loss:  0.626, Seconds: 3.02\n",
      "Epoch  17/100 Batch 1200/1562 - Loss:  0.729, Seconds: 4.08\n",
      "Epoch  17/100 Batch 1220/1562 - Loss:  0.638, Seconds: 3.45\n",
      "Epoch  17/100 Batch 1240/1562 - Loss:  0.536, Seconds: 3.59\n",
      "Average loss for this update: 0.653-- No Improvement.\n",
      "Epoch  17/100 Batch 1260/1562 - Loss:  0.685, Seconds: 3.57\n",
      "Epoch  17/100 Batch 1280/1562 - Loss:  0.717, Seconds: 4.05\n",
      "Epoch  17/100 Batch 1300/1562 - Loss:  0.716, Seconds: 3.34\n",
      "Epoch  17/100 Batch 1320/1562 - Loss:  0.714, Seconds: 3.88\n",
      "Epoch  17/100 Batch 1340/1562 - Loss:  0.674, Seconds: 3.44\n",
      "Epoch  17/100 Batch 1360/1562 - Loss:  0.668, Seconds: 3.65\n",
      "Epoch  17/100 Batch 1380/1562 - Loss:  0.700, Seconds: 3.89\n",
      "Epoch  17/100 Batch 1400/1562 - Loss:  0.615, Seconds: 3.89\n",
      "Epoch  17/100 Batch 1420/1562 - Loss:  0.515, Seconds: 3.29\n",
      "Epoch  17/100 Batch 1440/1562 - Loss:  0.595, Seconds: 3.72\n",
      "Epoch  17/100 Batch 1460/1562 - Loss:  0.603, Seconds: 3.89\n",
      "Epoch  17/100 Batch 1480/1562 - Loss:  0.598, Seconds: 3.90\n",
      "Epoch  17/100 Batch 1500/1562 - Loss:  0.630, Seconds: 3.70\n",
      "Epoch  17/100 Batch 1520/1562 - Loss:  0.785, Seconds: 4.42\n",
      "Epoch  17/100 Batch 1540/1562 - Loss:  0.926, Seconds: 3.79\n",
      "Average loss for this update: 0.689-- No Improvement.\n",
      "Epoch  17/100 Batch 1560/1562 - Loss:  0.949, Seconds: 3.95\n",
      "Epoch  18/100 Batch   20/1562 - Loss:  0.864, Seconds: 3.87\n",
      "Epoch  18/100 Batch   40/1562 - Loss:  0.786, Seconds: 3.46\n",
      "Epoch  18/100 Batch   60/1562 - Loss:  0.896, Seconds: 3.07\n",
      "Epoch  18/100 Batch   80/1562 - Loss:  0.769, Seconds: 2.90\n",
      "Epoch  18/100 Batch  100/1562 - Loss:  0.678, Seconds: 3.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  18/100 Batch  120/1562 - Loss:  0.677, Seconds: 3.18\n",
      "Epoch  18/100 Batch  140/1562 - Loss:  0.727, Seconds: 3.25\n",
      "Epoch  18/100 Batch  160/1562 - Loss:  0.681, Seconds: 2.91\n",
      "Epoch  18/100 Batch  180/1562 - Loss:  0.708, Seconds: 3.74\n",
      "Epoch  18/100 Batch  200/1562 - Loss:  0.645, Seconds: 3.07\n",
      "Epoch  18/100 Batch  220/1562 - Loss:  0.690, Seconds: 3.07\n",
      "Epoch  18/100 Batch  240/1562 - Loss:  0.634, Seconds: 2.85\n",
      "Epoch  18/100 Batch  260/1562 - Loss:  0.712, Seconds: 4.09\n",
      "Epoch  18/100 Batch  280/1562 - Loss:  0.635, Seconds: 3.28\n",
      "Epoch  18/100 Batch  300/1562 - Loss:  0.578, Seconds: 4.11\n",
      "Average loss for this update: 0.705-- No Improvement.\n",
      "Epoch  18/100 Batch  320/1562 - Loss:  0.564, Seconds: 3.52\n",
      "Epoch  18/100 Batch  340/1562 - Loss:  0.627, Seconds: 3.26\n",
      "Epoch  18/100 Batch  360/1562 - Loss:  0.650, Seconds: 3.88\n",
      "Epoch  18/100 Batch  380/1562 - Loss:  0.586, Seconds: 2.87\n",
      "Epoch  18/100 Batch  400/1562 - Loss:  0.624, Seconds: 4.07\n",
      "Epoch  18/100 Batch  420/1562 - Loss:  0.660, Seconds: 3.65\n",
      "Epoch  18/100 Batch  440/1562 - Loss:  0.707, Seconds: 3.26\n",
      "Epoch  18/100 Batch  460/1562 - Loss:  0.669, Seconds: 3.12\n",
      "Epoch  18/100 Batch  480/1562 - Loss:  0.584, Seconds: 3.57\n",
      "Epoch  18/100 Batch  500/1562 - Loss:  0.673, Seconds: 3.78\n",
      "Epoch  18/100 Batch  520/1562 - Loss:  0.603, Seconds: 4.23\n",
      "Epoch  18/100 Batch  540/1562 - Loss:  0.657, Seconds: 3.19\n",
      "Epoch  18/100 Batch  560/1562 - Loss:  0.628, Seconds: 3.61\n",
      "Epoch  18/100 Batch  580/1562 - Loss:  0.534, Seconds: 3.54\n",
      "Epoch  18/100 Batch  600/1562 - Loss:  0.492, Seconds: 3.38\n",
      "Epoch  18/100 Batch  620/1562 - Loss:  0.587, Seconds: 3.78\n",
      "Average loss for this update: 0.617 -- New Record!\n",
      "Epoch  18/100 Batch  640/1562 - Loss:  0.646, Seconds: 3.30\n",
      "Epoch  18/100 Batch  660/1562 - Loss:  0.618, Seconds: 3.55\n",
      "Epoch  18/100 Batch  680/1562 - Loss:  0.564, Seconds: 4.12\n",
      "Epoch  18/100 Batch  700/1562 - Loss:  0.638, Seconds: 3.19\n",
      "Epoch  18/100 Batch  720/1562 - Loss:  0.667, Seconds: 4.02\n",
      "Epoch  18/100 Batch  740/1562 - Loss:  0.704, Seconds: 3.82\n",
      "Epoch  18/100 Batch  760/1562 - Loss:  0.683, Seconds: 3.05\n",
      "Epoch  18/100 Batch  780/1562 - Loss:  0.667, Seconds: 4.24\n",
      "Epoch  18/100 Batch  800/1562 - Loss:  0.623, Seconds: 3.43\n",
      "Epoch  18/100 Batch  820/1562 - Loss:  0.615, Seconds: 3.79\n",
      "Epoch  18/100 Batch  840/1562 - Loss:  0.637, Seconds: 3.62\n",
      "Epoch  18/100 Batch  860/1562 - Loss:  0.603, Seconds: 3.60\n",
      "Epoch  18/100 Batch  880/1562 - Loss:  0.495, Seconds: 3.15\n",
      "Epoch  18/100 Batch  900/1562 - Loss:  0.610, Seconds: 3.99\n",
      "Epoch  18/100 Batch  920/1562 - Loss:  0.635, Seconds: 3.38\n",
      "Average loss for this update: 0.625-- No Improvement.\n",
      "Epoch  18/100 Batch  940/1562 - Loss:  0.549, Seconds: 3.23\n",
      "Epoch  18/100 Batch  960/1562 - Loss:  0.586, Seconds: 3.81\n",
      "Epoch  18/100 Batch  980/1562 - Loss:  0.613, Seconds: 3.91\n",
      "Epoch  18/100 Batch 1000/1562 - Loss:  0.632, Seconds: 3.66\n",
      "Epoch  18/100 Batch 1020/1562 - Loss:  0.648, Seconds: 3.27\n",
      "Epoch  18/100 Batch 1040/1562 - Loss:  0.675, Seconds: 3.59\n",
      "Epoch  18/100 Batch 1060/1562 - Loss:  0.624, Seconds: 3.46\n",
      "Epoch  18/100 Batch 1080/1562 - Loss:  0.620, Seconds: 4.34\n",
      "Epoch  18/100 Batch 1100/1562 - Loss:  0.676, Seconds: 3.28\n",
      "Epoch  18/100 Batch 1120/1562 - Loss:  0.663, Seconds: 3.63\n",
      "Epoch  18/100 Batch 1140/1562 - Loss:  0.597, Seconds: 3.66\n",
      "Epoch  18/100 Batch 1160/1562 - Loss:  0.583, Seconds: 3.46\n",
      "Epoch  18/100 Batch 1180/1562 - Loss:  0.578, Seconds: 3.08\n",
      "Epoch  18/100 Batch 1200/1562 - Loss:  0.682, Seconds: 4.02\n",
      "Epoch  18/100 Batch 1220/1562 - Loss:  0.607, Seconds: 3.47\n",
      "Epoch  18/100 Batch 1240/1562 - Loss:  0.505, Seconds: 3.64\n",
      "Average loss for this update: 0.617 -- New Record!\n",
      "Epoch  18/100 Batch 1260/1562 - Loss:  0.645, Seconds: 3.46\n",
      "Epoch  18/100 Batch 1280/1562 - Loss:  0.676, Seconds: 3.99\n",
      "Epoch  18/100 Batch 1300/1562 - Loss:  0.685, Seconds: 3.27\n",
      "Epoch  18/100 Batch 1320/1562 - Loss:  0.684, Seconds: 3.94\n",
      "Epoch  18/100 Batch 1340/1562 - Loss:  0.640, Seconds: 3.48\n",
      "Epoch  18/100 Batch 1360/1562 - Loss:  0.633, Seconds: 3.66\n",
      "Epoch  18/100 Batch 1380/1562 - Loss:  0.657, Seconds: 3.90\n",
      "Epoch  18/100 Batch 1400/1562 - Loss:  0.588, Seconds: 3.87\n",
      "Epoch  18/100 Batch 1420/1562 - Loss:  0.494, Seconds: 3.36\n",
      "Epoch  18/100 Batch 1440/1562 - Loss:  0.569, Seconds: 3.71\n",
      "Epoch  18/100 Batch 1460/1562 - Loss:  0.573, Seconds: 3.85\n",
      "Epoch  18/100 Batch 1480/1562 - Loss:  0.550, Seconds: 3.89\n",
      "Epoch  18/100 Batch 1500/1562 - Loss:  0.597, Seconds: 3.78\n",
      "Epoch  18/100 Batch 1520/1562 - Loss:  0.735, Seconds: 4.33\n",
      "Epoch  18/100 Batch 1540/1562 - Loss:  0.884, Seconds: 3.77\n",
      "Average loss for this update: 0.652-- No Improvement.\n",
      "Epoch  18/100 Batch 1560/1562 - Loss:  0.887, Seconds: 3.95\n",
      "Epoch  19/100 Batch   20/1562 - Loss:  0.827, Seconds: 3.90\n",
      "Epoch  19/100 Batch   40/1562 - Loss:  0.737, Seconds: 3.50\n",
      "Epoch  19/100 Batch   60/1562 - Loss:  0.858, Seconds: 3.03\n",
      "Epoch  19/100 Batch   80/1562 - Loss:  0.708, Seconds: 2.90\n",
      "Epoch  19/100 Batch  100/1562 - Loss:  0.638, Seconds: 3.40\n",
      "Epoch  19/100 Batch  120/1562 - Loss:  0.646, Seconds: 3.10\n",
      "Epoch  19/100 Batch  140/1562 - Loss:  0.675, Seconds: 3.28\n",
      "Epoch  19/100 Batch  160/1562 - Loss:  0.637, Seconds: 2.92\n",
      "Epoch  19/100 Batch  180/1562 - Loss:  0.672, Seconds: 3.72\n",
      "Epoch  19/100 Batch  200/1562 - Loss:  0.609, Seconds: 3.02\n",
      "Epoch  19/100 Batch  220/1562 - Loss:  0.648, Seconds: 3.13\n",
      "Epoch  19/100 Batch  240/1562 - Loss:  0.609, Seconds: 2.89\n",
      "Epoch  19/100 Batch  260/1562 - Loss:  0.662, Seconds: 4.12\n",
      "Epoch  19/100 Batch  280/1562 - Loss:  0.593, Seconds: 3.30\n",
      "Epoch  19/100 Batch  300/1562 - Loss:  0.555, Seconds: 4.09\n",
      "Average loss for this update: 0.667-- No Improvement.\n",
      "Epoch  19/100 Batch  320/1562 - Loss:  0.557, Seconds: 3.52\n",
      "Epoch  19/100 Batch  340/1562 - Loss:  0.605, Seconds: 3.27\n",
      "Epoch  19/100 Batch  360/1562 - Loss:  0.608, Seconds: 3.92\n",
      "Epoch  19/100 Batch  380/1562 - Loss:  0.552, Seconds: 2.93\n",
      "Epoch  19/100 Batch  400/1562 - Loss:  0.599, Seconds: 4.20\n",
      "Epoch  19/100 Batch  420/1562 - Loss:  0.623, Seconds: 3.55\n",
      "Epoch  19/100 Batch  440/1562 - Loss:  0.663, Seconds: 3.43\n",
      "Epoch  19/100 Batch  460/1562 - Loss:  0.626, Seconds: 3.20\n",
      "Epoch  19/100 Batch  480/1562 - Loss:  0.548, Seconds: 3.53\n",
      "Epoch  19/100 Batch  500/1562 - Loss:  0.638, Seconds: 3.78\n",
      "Epoch  19/100 Batch  520/1562 - Loss:  0.559, Seconds: 4.13\n",
      "Epoch  19/100 Batch  540/1562 - Loss:  0.623, Seconds: 3.17\n",
      "Epoch  19/100 Batch  560/1562 - Loss:  0.594, Seconds: 3.59\n",
      "Epoch  19/100 Batch  580/1562 - Loss:  0.517, Seconds: 3.58\n",
      "Epoch  19/100 Batch  600/1562 - Loss:  0.472, Seconds: 3.37\n",
      "Epoch  19/100 Batch  620/1562 - Loss:  0.559, Seconds: 3.79\n",
      "Average loss for this update: 0.585 -- New Record!\n",
      "Epoch  19/100 Batch  640/1562 - Loss:  0.606, Seconds: 3.35\n",
      "Epoch  19/100 Batch  660/1562 - Loss:  0.581, Seconds: 3.57\n",
      "Epoch  19/100 Batch  680/1562 - Loss:  0.527, Seconds: 4.14\n",
      "Epoch  19/100 Batch  700/1562 - Loss:  0.604, Seconds: 3.17\n",
      "Epoch  19/100 Batch  720/1562 - Loss:  0.638, Seconds: 4.02\n",
      "Epoch  19/100 Batch  740/1562 - Loss:  0.671, Seconds: 3.89\n",
      "Epoch  19/100 Batch  760/1562 - Loss:  0.641, Seconds: 2.96\n",
      "Epoch  19/100 Batch  780/1562 - Loss:  0.632, Seconds: 4.24\n",
      "Epoch  19/100 Batch  800/1562 - Loss:  0.598, Seconds: 3.41\n",
      "Epoch  19/100 Batch  820/1562 - Loss:  0.590, Seconds: 3.80\n",
      "Epoch  19/100 Batch  840/1562 - Loss:  0.611, Seconds: 3.63\n",
      "Epoch  19/100 Batch  860/1562 - Loss:  0.571, Seconds: 3.60\n",
      "Epoch  19/100 Batch  880/1562 - Loss:  0.473, Seconds: 3.11\n",
      "Epoch  19/100 Batch  900/1562 - Loss:  0.582, Seconds: 3.97\n",
      "Epoch  19/100 Batch  920/1562 - Loss:  0.609, Seconds: 3.39\n",
      "Average loss for this update: 0.594-- No Improvement.\n",
      "Epoch  19/100 Batch  940/1562 - Loss:  0.515, Seconds: 3.14\n",
      "Epoch  19/100 Batch  960/1562 - Loss:  0.551, Seconds: 3.78\n",
      "Epoch  19/100 Batch  980/1562 - Loss:  0.585, Seconds: 3.88\n",
      "Epoch  19/100 Batch 1000/1562 - Loss:  0.610, Seconds: 3.61\n",
      "Epoch  19/100 Batch 1020/1562 - Loss:  0.622, Seconds: 3.29\n",
      "Epoch  19/100 Batch 1040/1562 - Loss:  0.637, Seconds: 3.68\n",
      "Epoch  19/100 Batch 1060/1562 - Loss:  0.598, Seconds: 3.53\n",
      "Epoch  19/100 Batch 1080/1562 - Loss:  0.578, Seconds: 4.29\n",
      "Epoch  19/100 Batch 1100/1562 - Loss:  0.652, Seconds: 3.25\n",
      "Epoch  19/100 Batch 1120/1562 - Loss:  0.624, Seconds: 3.63\n",
      "Epoch  19/100 Batch 1140/1562 - Loss:  0.570, Seconds: 3.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19/100 Batch 1160/1562 - Loss:  0.532, Seconds: 3.57\n",
      "Epoch  19/100 Batch 1180/1562 - Loss:  0.562, Seconds: 3.05\n",
      "Epoch  19/100 Batch 1200/1562 - Loss:  0.642, Seconds: 4.07\n",
      "Epoch  19/100 Batch 1220/1562 - Loss:  0.571, Seconds: 3.41\n",
      "Epoch  19/100 Batch 1240/1562 - Loss:  0.475, Seconds: 3.58\n",
      "Average loss for this update: 0.586-- No Improvement.\n",
      "Epoch  19/100 Batch 1260/1562 - Loss:  0.620, Seconds: 3.60\n",
      "Epoch  19/100 Batch 1280/1562 - Loss:  0.613, Seconds: 3.81\n",
      "Epoch  19/100 Batch 1300/1562 - Loss:  0.664, Seconds: 3.27\n",
      "Epoch  19/100 Batch 1320/1562 - Loss:  0.647, Seconds: 3.96\n",
      "Epoch  19/100 Batch 1340/1562 - Loss:  0.596, Seconds: 3.45\n",
      "Epoch  19/100 Batch 1360/1562 - Loss:  0.609, Seconds: 3.64\n",
      "Epoch  19/100 Batch 1380/1562 - Loss:  0.620, Seconds: 3.84\n",
      "Epoch  19/100 Batch 1400/1562 - Loss:  0.563, Seconds: 3.92\n",
      "Epoch  19/100 Batch 1420/1562 - Loss:  0.461, Seconds: 3.24\n",
      "Epoch  19/100 Batch 1440/1562 - Loss:  0.525, Seconds: 3.72\n",
      "Epoch  19/100 Batch 1460/1562 - Loss:  0.545, Seconds: 3.87\n",
      "Epoch  19/100 Batch 1480/1562 - Loss:  0.541, Seconds: 3.88\n",
      "Epoch  19/100 Batch 1500/1562 - Loss:  0.562, Seconds: 3.79\n",
      "Epoch  19/100 Batch 1520/1562 - Loss:  0.693, Seconds: 4.35\n",
      "Epoch  19/100 Batch 1540/1562 - Loss:  0.848, Seconds: 3.78\n",
      "Average loss for this update: 0.617-- No Improvement.\n",
      "Epoch  19/100 Batch 1560/1562 - Loss:  0.834, Seconds: 3.96\n",
      "Epoch  20/100 Batch   20/1562 - Loss:  0.777, Seconds: 3.87\n",
      "Epoch  20/100 Batch   40/1562 - Loss:  0.700, Seconds: 3.39\n",
      "Epoch  20/100 Batch   60/1562 - Loss:  0.818, Seconds: 3.07\n",
      "Epoch  20/100 Batch   80/1562 - Loss:  0.672, Seconds: 2.88\n",
      "Epoch  20/100 Batch  100/1562 - Loss:  0.612, Seconds: 3.48\n",
      "Epoch  20/100 Batch  120/1562 - Loss:  0.604, Seconds: 3.06\n",
      "Epoch  20/100 Batch  140/1562 - Loss:  0.628, Seconds: 3.32\n",
      "Epoch  20/100 Batch  160/1562 - Loss:  0.611, Seconds: 2.92\n",
      "Epoch  20/100 Batch  180/1562 - Loss:  0.617, Seconds: 3.77\n",
      "Epoch  20/100 Batch  200/1562 - Loss:  0.572, Seconds: 3.17\n",
      "Epoch  20/100 Batch  220/1562 - Loss:  0.605, Seconds: 3.05\n",
      "Epoch  20/100 Batch  240/1562 - Loss:  0.579, Seconds: 2.90\n",
      "Epoch  20/100 Batch  260/1562 - Loss:  0.641, Seconds: 4.11\n",
      "Epoch  20/100 Batch  280/1562 - Loss:  0.567, Seconds: 3.26\n",
      "Epoch  20/100 Batch  300/1562 - Loss:  0.518, Seconds: 4.06\n",
      "Average loss for this update: 0.63-- No Improvement.\n",
      "Epoch  20/100 Batch  320/1562 - Loss:  0.527, Seconds: 3.48\n",
      "Epoch  20/100 Batch  340/1562 - Loss:  0.567, Seconds: 3.34\n",
      "Epoch  20/100 Batch  360/1562 - Loss:  0.568, Seconds: 4.00\n",
      "Epoch  20/100 Batch  380/1562 - Loss:  0.529, Seconds: 2.92\n",
      "Epoch  20/100 Batch  400/1562 - Loss:  0.559, Seconds: 4.15\n",
      "Epoch  20/100 Batch  420/1562 - Loss:  0.586, Seconds: 3.53\n",
      "Epoch  20/100 Batch  440/1562 - Loss:  0.630, Seconds: 3.31\n",
      "Epoch  20/100 Batch  460/1562 - Loss:  0.588, Seconds: 3.26\n",
      "Epoch  20/100 Batch  480/1562 - Loss:  0.516, Seconds: 3.55\n",
      "Epoch  20/100 Batch  500/1562 - Loss:  0.607, Seconds: 3.83\n",
      "Epoch  20/100 Batch  520/1562 - Loss:  0.527, Seconds: 4.09\n",
      "Epoch  20/100 Batch  540/1562 - Loss:  0.590, Seconds: 3.22\n",
      "Epoch  20/100 Batch  560/1562 - Loss:  0.550, Seconds: 3.57\n",
      "Epoch  20/100 Batch  580/1562 - Loss:  0.487, Seconds: 3.58\n",
      "Epoch  20/100 Batch  600/1562 - Loss:  0.437, Seconds: 3.37\n",
      "Epoch  20/100 Batch  620/1562 - Loss:  0.535, Seconds: 3.82\n",
      "Average loss for this update: 0.551 -- New Record!\n",
      "Epoch  20/100 Batch  640/1562 - Loss:  0.581, Seconds: 3.35\n",
      "Epoch  20/100 Batch  660/1562 - Loss:  0.551, Seconds: 3.59\n",
      "Epoch  20/100 Batch  680/1562 - Loss:  0.510, Seconds: 4.21\n",
      "Epoch  20/100 Batch  700/1562 - Loss:  0.569, Seconds: 3.17\n",
      "Epoch  20/100 Batch  720/1562 - Loss:  0.592, Seconds: 4.08\n",
      "Epoch  20/100 Batch  740/1562 - Loss:  0.629, Seconds: 3.79\n",
      "Epoch  20/100 Batch  760/1562 - Loss:  0.613, Seconds: 2.96\n",
      "Epoch  20/100 Batch  780/1562 - Loss:  0.588, Seconds: 4.16\n",
      "Epoch  20/100 Batch  800/1562 - Loss:  0.565, Seconds: 3.41\n",
      "Epoch  20/100 Batch  820/1562 - Loss:  0.544, Seconds: 3.84\n",
      "Epoch  20/100 Batch  840/1562 - Loss:  0.573, Seconds: 3.58\n",
      "Epoch  20/100 Batch  860/1562 - Loss:  0.544, Seconds: 3.66\n",
      "Epoch  20/100 Batch  880/1562 - Loss:  0.442, Seconds: 3.21\n",
      "Epoch  20/100 Batch  900/1562 - Loss:  0.541, Seconds: 4.02\n",
      "Epoch  20/100 Batch  920/1562 - Loss:  0.572, Seconds: 3.45\n",
      "Average loss for this update: 0.559-- No Improvement.\n",
      "Epoch  20/100 Batch  940/1562 - Loss:  0.490, Seconds: 3.12\n",
      "Epoch  20/100 Batch  960/1562 - Loss:  0.521, Seconds: 3.74\n",
      "Epoch  20/100 Batch  980/1562 - Loss:  0.547, Seconds: 3.87\n",
      "Epoch  20/100 Batch 1000/1562 - Loss:  0.569, Seconds: 3.67\n",
      "Epoch  20/100 Batch 1020/1562 - Loss:  0.582, Seconds: 3.26\n",
      "Epoch  20/100 Batch 1040/1562 - Loss:  0.598, Seconds: 3.65\n",
      "Epoch  20/100 Batch 1060/1562 - Loss:  0.570, Seconds: 3.44\n",
      "Epoch  20/100 Batch 1080/1562 - Loss:  0.557, Seconds: 4.23\n",
      "Epoch  20/100 Batch 1100/1562 - Loss:  0.615, Seconds: 3.26\n",
      "Epoch  20/100 Batch 1120/1562 - Loss:  0.591, Seconds: 3.61\n",
      "Epoch  20/100 Batch 1140/1562 - Loss:  0.523, Seconds: 3.72\n",
      "Epoch  20/100 Batch 1160/1562 - Loss:  0.513, Seconds: 3.46\n",
      "Epoch  20/100 Batch 1180/1562 - Loss:  0.529, Seconds: 3.15\n",
      "Epoch  20/100 Batch 1200/1562 - Loss:  0.623, Seconds: 4.04\n",
      "Epoch  20/100 Batch 1220/1562 - Loss:  0.550, Seconds: 3.46\n",
      "Epoch  20/100 Batch 1240/1562 - Loss:  0.447, Seconds: 3.67\n",
      "Average loss for this update: 0.554-- No Improvement.\n",
      "Epoch  20/100 Batch 1260/1562 - Loss:  0.572, Seconds: 3.52\n",
      "Epoch  20/100 Batch 1280/1562 - Loss:  0.583, Seconds: 3.92\n",
      "Epoch  20/100 Batch 1300/1562 - Loss:  0.617, Seconds: 3.28\n",
      "Epoch  20/100 Batch 1320/1562 - Loss:  0.598, Seconds: 3.95\n",
      "Epoch  20/100 Batch 1340/1562 - Loss:  0.560, Seconds: 3.52\n",
      "Epoch  20/100 Batch 1360/1562 - Loss:  0.566, Seconds: 3.72\n",
      "Epoch  20/100 Batch 1380/1562 - Loss:  0.610, Seconds: 3.85\n",
      "Epoch  20/100 Batch 1400/1562 - Loss:  0.525, Seconds: 3.92\n",
      "Epoch  20/100 Batch 1420/1562 - Loss:  0.438, Seconds: 3.26\n",
      "Epoch  20/100 Batch 1440/1562 - Loss:  0.503, Seconds: 3.70\n",
      "Epoch  20/100 Batch 1460/1562 - Loss:  0.519, Seconds: 3.93\n",
      "Epoch  20/100 Batch 1480/1562 - Loss:  0.523, Seconds: 3.88\n",
      "Epoch  20/100 Batch 1500/1562 - Loss:  0.532, Seconds: 3.75\n",
      "Epoch  20/100 Batch 1520/1562 - Loss:  0.663, Seconds: 4.52\n",
      "Epoch  20/100 Batch 1540/1562 - Loss:  0.800, Seconds: 3.73\n",
      "Average loss for this update: 0.584-- No Improvement.\n",
      "Epoch  20/100 Batch 1560/1562 - Loss:  0.797, Seconds: 3.98\n",
      "Epoch  21/100 Batch   20/1562 - Loss:  0.739, Seconds: 3.91\n",
      "Epoch  21/100 Batch   40/1562 - Loss:  0.657, Seconds: 3.51\n",
      "Epoch  21/100 Batch   60/1562 - Loss:  0.748, Seconds: 3.08\n",
      "Epoch  21/100 Batch   80/1562 - Loss:  0.629, Seconds: 2.86\n",
      "Epoch  21/100 Batch  100/1562 - Loss:  0.581, Seconds: 3.49\n",
      "Epoch  21/100 Batch  120/1562 - Loss:  0.566, Seconds: 3.09\n",
      "Epoch  21/100 Batch  140/1562 - Loss:  0.592, Seconds: 3.31\n",
      "Epoch  21/100 Batch  160/1562 - Loss:  0.564, Seconds: 2.83\n",
      "Epoch  21/100 Batch  180/1562 - Loss:  0.595, Seconds: 3.68\n",
      "Epoch  21/100 Batch  200/1562 - Loss:  0.541, Seconds: 3.14\n",
      "Epoch  21/100 Batch  220/1562 - Loss:  0.570, Seconds: 3.08\n",
      "Epoch  21/100 Batch  240/1562 - Loss:  0.531, Seconds: 2.84\n",
      "Epoch  21/100 Batch  260/1562 - Loss:  0.603, Seconds: 4.12\n",
      "Epoch  21/100 Batch  280/1562 - Loss:  0.528, Seconds: 3.31\n",
      "Epoch  21/100 Batch  300/1562 - Loss:  0.490, Seconds: 4.16\n",
      "Average loss for this update: 0.591-- No Improvement.\n",
      "Epoch  21/100 Batch  320/1562 - Loss:  0.493, Seconds: 3.59\n",
      "Epoch  21/100 Batch  340/1562 - Loss:  0.542, Seconds: 3.33\n",
      "Epoch  21/100 Batch  360/1562 - Loss:  0.547, Seconds: 3.98\n",
      "Epoch  21/100 Batch  380/1562 - Loss:  0.497, Seconds: 2.88\n",
      "Epoch  21/100 Batch  400/1562 - Loss:  0.539, Seconds: 4.14\n",
      "Epoch  21/100 Batch  420/1562 - Loss:  0.542, Seconds: 3.68\n",
      "Epoch  21/100 Batch  440/1562 - Loss:  0.600, Seconds: 3.34\n",
      "Epoch  21/100 Batch  460/1562 - Loss:  0.563, Seconds: 3.13\n",
      "Epoch  21/100 Batch  480/1562 - Loss:  0.501, Seconds: 3.56\n",
      "Epoch  21/100 Batch  500/1562 - Loss:  0.573, Seconds: 3.79\n",
      "Epoch  21/100 Batch  520/1562 - Loss:  0.487, Seconds: 4.18\n",
      "Epoch  21/100 Batch  540/1562 - Loss:  0.550, Seconds: 3.15\n",
      "Epoch  21/100 Batch  560/1562 - Loss:  0.525, Seconds: 3.53\n",
      "Epoch  21/100 Batch  580/1562 - Loss:  0.476, Seconds: 3.58\n",
      "Epoch  21/100 Batch  600/1562 - Loss:  0.412, Seconds: 3.36\n",
      "Epoch  21/100 Batch  620/1562 - Loss:  0.507, Seconds: 3.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss for this update: 0.523 -- New Record!\n",
      "Epoch  21/100 Batch  640/1562 - Loss:  0.538, Seconds: 3.43\n",
      "Epoch  21/100 Batch  660/1562 - Loss:  0.520, Seconds: 3.60\n",
      "Epoch  21/100 Batch  680/1562 - Loss:  0.477, Seconds: 4.22\n",
      "Epoch  21/100 Batch  700/1562 - Loss:  0.525, Seconds: 3.16\n",
      "Epoch  21/100 Batch  720/1562 - Loss:  0.567, Seconds: 3.99\n",
      "Epoch  21/100 Batch  740/1562 - Loss:  0.610, Seconds: 3.83\n",
      "Epoch  21/100 Batch  760/1562 - Loss:  0.571, Seconds: 2.98\n",
      "Epoch  21/100 Batch  780/1562 - Loss:  0.586, Seconds: 4.19\n",
      "Epoch  21/100 Batch  800/1562 - Loss:  0.536, Seconds: 3.41\n",
      "Epoch  21/100 Batch  820/1562 - Loss:  0.527, Seconds: 3.83\n",
      "Epoch  21/100 Batch  840/1562 - Loss:  0.543, Seconds: 3.59\n",
      "Epoch  21/100 Batch  860/1562 - Loss:  0.502, Seconds: 3.57\n",
      "Epoch  21/100 Batch  880/1562 - Loss:  0.411, Seconds: 3.22\n",
      "Epoch  21/100 Batch  900/1562 - Loss:  0.517, Seconds: 4.03\n",
      "Epoch  21/100 Batch  920/1562 - Loss:  0.544, Seconds: 3.32\n",
      "Average loss for this update: 0.53-- No Improvement.\n",
      "Epoch  21/100 Batch  940/1562 - Loss:  0.476, Seconds: 3.19\n",
      "Epoch  21/100 Batch  960/1562 - Loss:  0.484, Seconds: 3.82\n",
      "Epoch  21/100 Batch  980/1562 - Loss:  0.513, Seconds: 3.85\n",
      "Epoch  21/100 Batch 1000/1562 - Loss:  0.523, Seconds: 3.68\n",
      "Epoch  21/100 Batch 1020/1562 - Loss:  0.559, Seconds: 3.28\n",
      "Epoch  21/100 Batch 1040/1562 - Loss:  0.587, Seconds: 3.74\n",
      "Epoch  21/100 Batch 1060/1562 - Loss:  0.543, Seconds: 3.54\n",
      "Epoch  21/100 Batch 1080/1562 - Loss:  0.527, Seconds: 4.40\n",
      "Epoch  21/100 Batch 1100/1562 - Loss:  0.574, Seconds: 3.25\n",
      "Epoch  21/100 Batch 1120/1562 - Loss:  0.553, Seconds: 3.63\n",
      "Epoch  21/100 Batch 1140/1562 - Loss:  0.500, Seconds: 3.66\n",
      "Epoch  21/100 Batch 1160/1562 - Loss:  0.495, Seconds: 3.53\n",
      "Epoch  21/100 Batch 1180/1562 - Loss:  0.496, Seconds: 2.97\n",
      "Epoch  21/100 Batch 1200/1562 - Loss:  0.587, Seconds: 3.98\n",
      "Epoch  21/100 Batch 1220/1562 - Loss:  0.508, Seconds: 3.43\n",
      "Epoch  21/100 Batch 1240/1562 - Loss:  0.425, Seconds: 3.68\n",
      "Average loss for this update: 0.523-- No Improvement.\n",
      "Epoch  21/100 Batch 1260/1562 - Loss:  0.555, Seconds: 3.46\n",
      "Epoch  21/100 Batch 1280/1562 - Loss:  0.543, Seconds: 3.95\n",
      "Epoch  21/100 Batch 1300/1562 - Loss:  0.574, Seconds: 3.20\n",
      "Epoch  21/100 Batch 1320/1562 - Loss:  0.576, Seconds: 3.78\n",
      "Epoch  21/100 Batch 1340/1562 - Loss:  0.517, Seconds: 3.47\n",
      "Epoch  21/100 Batch 1360/1562 - Loss:  0.540, Seconds: 3.67\n",
      "Epoch  21/100 Batch 1380/1562 - Loss:  0.562, Seconds: 3.91\n",
      "Epoch  21/100 Batch 1400/1562 - Loss:  0.500, Seconds: 3.90\n",
      "Epoch  21/100 Batch 1420/1562 - Loss:  0.415, Seconds: 3.29\n",
      "Epoch  21/100 Batch 1440/1562 - Loss:  0.477, Seconds: 3.79\n",
      "Epoch  21/100 Batch 1460/1562 - Loss:  0.487, Seconds: 3.86\n",
      "Epoch  21/100 Batch 1480/1562 - Loss:  0.490, Seconds: 3.96\n",
      "Epoch  21/100 Batch 1500/1562 - Loss:  0.524, Seconds: 3.74\n",
      "Epoch  21/100 Batch 1520/1562 - Loss:  0.635, Seconds: 4.34\n",
      "Epoch  21/100 Batch 1540/1562 - Loss:  0.746, Seconds: 3.76\n",
      "Average loss for this update: 0.554-- No Improvement.\n",
      "Epoch  21/100 Batch 1560/1562 - Loss:  0.773, Seconds: 3.88\n",
      "Epoch  22/100 Batch   20/1562 - Loss:  0.704, Seconds: 3.91\n",
      "Epoch  22/100 Batch   40/1562 - Loss:  0.640, Seconds: 3.42\n",
      "Epoch  22/100 Batch   60/1562 - Loss:  0.729, Seconds: 3.00\n",
      "Epoch  22/100 Batch   80/1562 - Loss:  0.620, Seconds: 2.87\n",
      "Epoch  22/100 Batch  100/1562 - Loss:  0.550, Seconds: 3.45\n",
      "Epoch  22/100 Batch  120/1562 - Loss:  0.557, Seconds: 3.14\n",
      "Epoch  22/100 Batch  140/1562 - Loss:  0.584, Seconds: 3.31\n",
      "Epoch  22/100 Batch  160/1562 - Loss:  0.530, Seconds: 2.95\n",
      "Epoch  22/100 Batch  180/1562 - Loss:  0.564, Seconds: 3.71\n",
      "Epoch  22/100 Batch  200/1562 - Loss:  0.499, Seconds: 3.04\n",
      "Epoch  22/100 Batch  220/1562 - Loss:  0.548, Seconds: 3.11\n",
      "Epoch  22/100 Batch  240/1562 - Loss:  0.507, Seconds: 2.96\n",
      "Epoch  22/100 Batch  260/1562 - Loss:  0.575, Seconds: 4.25\n",
      "Epoch  22/100 Batch  280/1562 - Loss:  0.496, Seconds: 3.27\n",
      "Epoch  22/100 Batch  300/1562 - Loss:  0.464, Seconds: 4.18\n",
      "Average loss for this update: 0.566-- No Improvement.\n",
      "Epoch  22/100 Batch  320/1562 - Loss:  0.458, Seconds: 3.55\n",
      "Epoch  22/100 Batch  340/1562 - Loss:  0.501, Seconds: 3.29\n",
      "Epoch  22/100 Batch  360/1562 - Loss:  0.516, Seconds: 3.89\n",
      "Epoch  22/100 Batch  380/1562 - Loss:  0.471, Seconds: 2.91\n",
      "Epoch  22/100 Batch  400/1562 - Loss:  0.500, Seconds: 4.12\n",
      "Epoch  22/100 Batch  420/1562 - Loss:  0.534, Seconds: 3.52\n",
      "Epoch  22/100 Batch  440/1562 - Loss:  0.559, Seconds: 3.33\n",
      "Epoch  22/100 Batch  460/1562 - Loss:  0.543, Seconds: 3.17\n",
      "Epoch  22/100 Batch  480/1562 - Loss:  0.479, Seconds: 3.53\n",
      "Epoch  22/100 Batch  500/1562 - Loss:  0.549, Seconds: 3.73\n",
      "Epoch  22/100 Batch  520/1562 - Loss:  0.472, Seconds: 4.14\n",
      "Epoch  22/100 Batch  540/1562 - Loss:  0.519, Seconds: 3.15\n",
      "Epoch  22/100 Batch  560/1562 - Loss:  0.496, Seconds: 3.59\n",
      "Epoch  22/100 Batch  580/1562 - Loss:  0.436, Seconds: 3.55\n",
      "Epoch  22/100 Batch  600/1562 - Loss:  0.394, Seconds: 3.36\n",
      "Epoch  22/100 Batch  620/1562 - Loss:  0.479, Seconds: 3.70\n",
      "Average loss for this update: 0.495 -- New Record!\n",
      "Epoch  22/100 Batch  640/1562 - Loss:  0.521, Seconds: 3.42\n",
      "Epoch  22/100 Batch  660/1562 - Loss:  0.498, Seconds: 3.61\n",
      "Epoch  22/100 Batch  680/1562 - Loss:  0.429, Seconds: 4.22\n",
      "Epoch  22/100 Batch  700/1562 - Loss:  0.511, Seconds: 3.14\n",
      "Epoch  22/100 Batch  720/1562 - Loss:  0.536, Seconds: 4.12\n",
      "Epoch  22/100 Batch  740/1562 - Loss:  0.572, Seconds: 3.86\n",
      "Epoch  22/100 Batch  760/1562 - Loss:  0.527, Seconds: 3.00\n",
      "Epoch  22/100 Batch  780/1562 - Loss:  0.531, Seconds: 4.19\n",
      "Epoch  22/100 Batch  800/1562 - Loss:  0.523, Seconds: 3.42\n",
      "Epoch  22/100 Batch  820/1562 - Loss:  0.505, Seconds: 3.82\n",
      "Epoch  22/100 Batch  840/1562 - Loss:  0.525, Seconds: 3.55\n",
      "Epoch  22/100 Batch  860/1562 - Loss:  0.488, Seconds: 3.55\n",
      "Epoch  22/100 Batch  880/1562 - Loss:  0.388, Seconds: 3.23\n",
      "Epoch  22/100 Batch  900/1562 - Loss:  0.498, Seconds: 4.10\n",
      "Epoch  22/100 Batch  920/1562 - Loss:  0.516, Seconds: 3.42\n",
      "Average loss for this update: 0.503-- No Improvement.\n",
      "Epoch  22/100 Batch  940/1562 - Loss:  0.447, Seconds: 3.18\n",
      "Epoch  22/100 Batch  960/1562 - Loss:  0.464, Seconds: 3.82\n",
      "Epoch  22/100 Batch  980/1562 - Loss:  0.488, Seconds: 3.81\n",
      "Epoch  22/100 Batch 1000/1562 - Loss:  0.505, Seconds: 3.60\n",
      "Epoch  22/100 Batch 1020/1562 - Loss:  0.524, Seconds: 3.25\n",
      "Epoch  22/100 Batch 1040/1562 - Loss:  0.556, Seconds: 3.60\n",
      "Epoch  22/100 Batch 1060/1562 - Loss:  0.508, Seconds: 3.52\n",
      "Epoch  22/100 Batch 1080/1562 - Loss:  0.512, Seconds: 4.33\n",
      "Epoch  22/100 Batch 1100/1562 - Loss:  0.561, Seconds: 3.21\n",
      "Epoch  22/100 Batch 1120/1562 - Loss:  0.546, Seconds: 3.70\n",
      "Epoch  22/100 Batch 1140/1562 - Loss:  0.478, Seconds: 3.68\n",
      "Epoch  22/100 Batch 1160/1562 - Loss:  0.457, Seconds: 3.41\n",
      "Epoch  22/100 Batch 1180/1562 - Loss:  0.489, Seconds: 2.98\n",
      "Epoch  22/100 Batch 1200/1562 - Loss:  0.544, Seconds: 4.05\n",
      "Epoch  22/100 Batch 1220/1562 - Loss:  0.487, Seconds: 3.46\n",
      "Epoch  22/100 Batch 1240/1562 - Loss:  0.396, Seconds: 3.69\n",
      "Average loss for this update: 0.5-- No Improvement.\n",
      "Epoch  22/100 Batch 1260/1562 - Loss:  0.523, Seconds: 3.44\n",
      "Epoch  22/100 Batch 1280/1562 - Loss:  0.504, Seconds: 4.00\n",
      "Epoch  22/100 Batch 1300/1562 - Loss:  0.559, Seconds: 3.22\n",
      "Epoch  22/100 Batch 1320/1562 - Loss:  0.544, Seconds: 3.87\n",
      "Epoch  22/100 Batch 1340/1562 - Loss:  0.513, Seconds: 3.50\n",
      "Epoch  22/100 Batch 1360/1562 - Loss:  0.516, Seconds: 3.73\n",
      "Epoch  22/100 Batch 1380/1562 - Loss:  0.529, Seconds: 3.88\n",
      "Epoch  22/100 Batch 1400/1562 - Loss:  0.481, Seconds: 3.90\n",
      "Epoch  22/100 Batch 1420/1562 - Loss:  0.403, Seconds: 3.36\n",
      "Epoch  22/100 Batch 1440/1562 - Loss:  0.472, Seconds: 3.77\n",
      "Epoch  22/100 Batch 1460/1562 - Loss:  0.449, Seconds: 3.96\n",
      "Epoch  22/100 Batch 1480/1562 - Loss:  0.456, Seconds: 3.91\n",
      "Epoch  22/100 Batch 1500/1562 - Loss:  0.480, Seconds: 3.73\n",
      "Epoch  22/100 Batch 1520/1562 - Loss:  0.592, Seconds: 4.41\n",
      "Epoch  22/100 Batch 1540/1562 - Loss:  0.716, Seconds: 3.75\n",
      "Average loss for this update: 0.525-- No Improvement.\n",
      "Epoch  22/100 Batch 1560/1562 - Loss:  0.732, Seconds: 3.92\n",
      "Epoch  23/100 Batch   20/1562 - Loss:  0.669, Seconds: 3.88\n",
      "Epoch  23/100 Batch   40/1562 - Loss:  0.595, Seconds: 3.46\n",
      "Epoch  23/100 Batch   60/1562 - Loss:  0.696, Seconds: 2.96\n",
      "Epoch  23/100 Batch   80/1562 - Loss:  0.576, Seconds: 2.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  23/100 Batch  100/1562 - Loss:  0.507, Seconds: 3.58\n",
      "Epoch  23/100 Batch  120/1562 - Loss:  0.521, Seconds: 3.10\n",
      "Epoch  23/100 Batch  140/1562 - Loss:  0.545, Seconds: 3.34\n",
      "Epoch  23/100 Batch  160/1562 - Loss:  0.503, Seconds: 2.92\n",
      "Epoch  23/100 Batch  180/1562 - Loss:  0.526, Seconds: 3.73\n",
      "Epoch  23/100 Batch  200/1562 - Loss:  0.462, Seconds: 3.11\n",
      "Epoch  23/100 Batch  220/1562 - Loss:  0.499, Seconds: 3.08\n",
      "Epoch  23/100 Batch  240/1562 - Loss:  0.472, Seconds: 2.93\n",
      "Epoch  23/100 Batch  260/1562 - Loss:  0.515, Seconds: 4.15\n",
      "Epoch  23/100 Batch  280/1562 - Loss:  0.458, Seconds: 3.31\n",
      "Epoch  23/100 Batch  300/1562 - Loss:  0.433, Seconds: 4.09\n",
      "Average loss for this update: 0.528-- No Improvement.\n",
      "Epoch  23/100 Batch  320/1562 - Loss:  0.444, Seconds: 3.62\n",
      "Epoch  23/100 Batch  340/1562 - Loss:  0.487, Seconds: 3.34\n",
      "Epoch  23/100 Batch  360/1562 - Loss:  0.491, Seconds: 3.89\n",
      "Epoch  23/100 Batch  380/1562 - Loss:  0.437, Seconds: 2.90\n",
      "Epoch  23/100 Batch  400/1562 - Loss:  0.474, Seconds: 4.26\n",
      "Epoch  23/100 Batch  420/1562 - Loss:  0.496, Seconds: 3.54\n",
      "Epoch  23/100 Batch  440/1562 - Loss:  0.528, Seconds: 3.31\n",
      "Epoch  23/100 Batch  460/1562 - Loss:  0.513, Seconds: 3.18\n",
      "Epoch  23/100 Batch  480/1562 - Loss:  0.448, Seconds: 3.53\n",
      "Epoch  23/100 Batch  500/1562 - Loss:  0.507, Seconds: 3.77\n",
      "Epoch  23/100 Batch  520/1562 - Loss:  0.455, Seconds: 4.10\n",
      "Epoch  23/100 Batch  540/1562 - Loss:  0.501, Seconds: 3.15\n",
      "Epoch  23/100 Batch  560/1562 - Loss:  0.471, Seconds: 3.57\n",
      "Epoch  23/100 Batch  580/1562 - Loss:  0.410, Seconds: 3.57\n",
      "Epoch  23/100 Batch  600/1562 - Loss:  0.363, Seconds: 3.42\n",
      "Epoch  23/100 Batch  620/1562 - Loss:  0.457, Seconds: 3.86\n",
      "Average loss for this update: 0.469 -- New Record!\n",
      "Epoch  23/100 Batch  640/1562 - Loss:  0.487, Seconds: 3.37\n",
      "Epoch  23/100 Batch  660/1562 - Loss:  0.466, Seconds: 3.58\n",
      "Epoch  23/100 Batch  680/1562 - Loss:  0.428, Seconds: 4.22\n",
      "Epoch  23/100 Batch  700/1562 - Loss:  0.482, Seconds: 3.20\n",
      "Epoch  23/100 Batch  720/1562 - Loss:  0.505, Seconds: 3.99\n",
      "Epoch  23/100 Batch  740/1562 - Loss:  0.529, Seconds: 3.84\n",
      "Epoch  23/100 Batch  760/1562 - Loss:  0.523, Seconds: 2.98\n",
      "Epoch  23/100 Batch  780/1562 - Loss:  0.501, Seconds: 4.24\n",
      "Epoch  23/100 Batch  800/1562 - Loss:  0.484, Seconds: 3.44\n",
      "Epoch  23/100 Batch  820/1562 - Loss:  0.473, Seconds: 3.83\n",
      "Epoch  23/100 Batch  840/1562 - Loss:  0.495, Seconds: 3.59\n",
      "Epoch  23/100 Batch  860/1562 - Loss:  0.462, Seconds: 3.53\n",
      "Epoch  23/100 Batch  880/1562 - Loss:  0.387, Seconds: 3.12\n",
      "Epoch  23/100 Batch  900/1562 - Loss:  0.466, Seconds: 3.98\n",
      "Epoch  23/100 Batch  920/1562 - Loss:  0.494, Seconds: 3.37\n",
      "Average loss for this update: 0.477-- No Improvement.\n",
      "Epoch  23/100 Batch  940/1562 - Loss:  0.425, Seconds: 3.19\n",
      "Epoch  23/100 Batch  960/1562 - Loss:  0.432, Seconds: 3.86\n",
      "Epoch  23/100 Batch  980/1562 - Loss:  0.461, Seconds: 3.88\n",
      "Epoch  23/100 Batch 1000/1562 - Loss:  0.483, Seconds: 3.70\n",
      "Epoch  23/100 Batch 1020/1562 - Loss:  0.491, Seconds: 3.31\n",
      "Epoch  23/100 Batch 1040/1562 - Loss:  0.527, Seconds: 3.67\n",
      "Epoch  23/100 Batch 1060/1562 - Loss:  0.480, Seconds: 3.46\n",
      "Epoch  23/100 Batch 1080/1562 - Loss:  0.482, Seconds: 4.33\n",
      "Epoch  23/100 Batch 1100/1562 - Loss:  0.526, Seconds: 3.28\n",
      "Epoch  23/100 Batch 1120/1562 - Loss:  0.512, Seconds: 3.70\n",
      "Epoch  23/100 Batch 1140/1562 - Loss:  0.454, Seconds: 3.63\n",
      "Epoch  23/100 Batch 1160/1562 - Loss:  0.446, Seconds: 3.41\n",
      "Epoch  23/100 Batch 1180/1562 - Loss:  0.457, Seconds: 3.02\n",
      "Epoch  23/100 Batch 1200/1562 - Loss:  0.520, Seconds: 4.06\n",
      "Epoch  23/100 Batch 1220/1562 - Loss:  0.464, Seconds: 3.42\n",
      "Epoch  23/100 Batch 1240/1562 - Loss:  0.381, Seconds: 3.64\n",
      "Average loss for this update: 0.474-- No Improvement.\n",
      "Epoch  23/100 Batch 1260/1562 - Loss:  0.496, Seconds: 3.51\n",
      "Epoch  23/100 Batch 1280/1562 - Loss:  0.507, Seconds: 3.83\n",
      "Epoch  23/100 Batch 1300/1562 - Loss:  0.504, Seconds: 3.25\n",
      "Epoch  23/100 Batch 1320/1562 - Loss:  0.515, Seconds: 3.89\n",
      "Epoch  23/100 Batch 1340/1562 - Loss:  0.474, Seconds: 3.51\n",
      "Epoch  23/100 Batch 1360/1562 - Loss:  0.494, Seconds: 3.80\n",
      "Epoch  23/100 Batch 1380/1562 - Loss:  0.507, Seconds: 3.99\n",
      "Epoch  23/100 Batch 1400/1562 - Loss:  0.453, Seconds: 3.88\n",
      "Epoch  23/100 Batch 1420/1562 - Loss:  0.380, Seconds: 3.22\n",
      "Epoch  23/100 Batch 1440/1562 - Loss:  0.436, Seconds: 3.66\n",
      "Epoch  23/100 Batch 1460/1562 - Loss:  0.438, Seconds: 3.92\n",
      "Epoch  23/100 Batch 1480/1562 - Loss:  0.452, Seconds: 3.90\n",
      "Epoch  23/100 Batch 1500/1562 - Loss:  0.466, Seconds: 3.71\n",
      "Epoch  23/100 Batch 1520/1562 - Loss:  0.573, Seconds: 4.42\n",
      "Epoch  23/100 Batch 1540/1562 - Loss:  0.673, Seconds: 3.75\n",
      "Average loss for this update: 0.499-- No Improvement.\n",
      "Epoch  23/100 Batch 1560/1562 - Loss:  0.687, Seconds: 4.03\n",
      "Epoch  24/100 Batch   20/1562 - Loss:  0.616, Seconds: 3.85\n",
      "Epoch  24/100 Batch   40/1562 - Loss:  0.561, Seconds: 3.49\n",
      "Epoch  24/100 Batch   60/1562 - Loss:  0.666, Seconds: 3.07\n",
      "Epoch  24/100 Batch   80/1562 - Loss:  0.554, Seconds: 2.84\n",
      "Epoch  24/100 Batch  100/1562 - Loss:  0.487, Seconds: 3.47\n",
      "Epoch  24/100 Batch  120/1562 - Loss:  0.496, Seconds: 3.05\n",
      "Epoch  24/100 Batch  140/1562 - Loss:  0.505, Seconds: 3.33\n",
      "Epoch  24/100 Batch  160/1562 - Loss:  0.501, Seconds: 2.93\n",
      "Epoch  24/100 Batch  180/1562 - Loss:  0.493, Seconds: 3.71\n",
      "Epoch  24/100 Batch  200/1562 - Loss:  0.437, Seconds: 3.11\n",
      "Epoch  24/100 Batch  220/1562 - Loss:  0.487, Seconds: 3.15\n",
      "Epoch  24/100 Batch  240/1562 - Loss:  0.457, Seconds: 2.91\n",
      "Epoch  24/100 Batch  260/1562 - Loss:  0.506, Seconds: 4.18\n",
      "Epoch  24/100 Batch  280/1562 - Loss:  0.453, Seconds: 3.32\n",
      "Epoch  24/100 Batch  300/1562 - Loss:  0.420, Seconds: 4.13\n",
      "Average loss for this update: 0.506-- No Improvement.\n",
      "Epoch  24/100 Batch  320/1562 - Loss:  0.423, Seconds: 3.53\n",
      "Epoch  24/100 Batch  340/1562 - Loss:  0.468, Seconds: 3.27\n",
      "Epoch  24/100 Batch  360/1562 - Loss:  0.467, Seconds: 3.93\n",
      "Epoch  24/100 Batch  380/1562 - Loss:  0.427, Seconds: 2.85\n",
      "Epoch  24/100 Batch  400/1562 - Loss:  0.452, Seconds: 4.12\n",
      "Epoch  24/100 Batch  420/1562 - Loss:  0.480, Seconds: 3.60\n",
      "Epoch  24/100 Batch  440/1562 - Loss:  0.515, Seconds: 3.38\n",
      "Epoch  24/100 Batch  460/1562 - Loss:  0.480, Seconds: 3.17\n",
      "Epoch  24/100 Batch  480/1562 - Loss:  0.435, Seconds: 3.52\n",
      "Epoch  24/100 Batch  500/1562 - Loss:  0.486, Seconds: 3.71\n",
      "Epoch  24/100 Batch  520/1562 - Loss:  0.428, Seconds: 4.20\n",
      "Epoch  24/100 Batch  540/1562 - Loss:  0.463, Seconds: 3.15\n",
      "Epoch  24/100 Batch  560/1562 - Loss:  0.447, Seconds: 3.64\n",
      "Epoch  24/100 Batch  580/1562 - Loss:  0.391, Seconds: 3.62\n",
      "Epoch  24/100 Batch  600/1562 - Loss:  0.357, Seconds: 3.38\n",
      "Epoch  24/100 Batch  620/1562 - Loss:  0.431, Seconds: 3.80\n",
      "Average loss for this update: 0.447 -- New Record!\n",
      "Epoch  24/100 Batch  640/1562 - Loss:  0.458, Seconds: 3.37\n",
      "Epoch  24/100 Batch  660/1562 - Loss:  0.446, Seconds: 3.58\n",
      "Epoch  24/100 Batch  680/1562 - Loss:  0.395, Seconds: 4.17\n",
      "Epoch  24/100 Batch  700/1562 - Loss:  0.447, Seconds: 3.25\n",
      "Epoch  24/100 Batch  720/1562 - Loss:  0.482, Seconds: 4.01\n",
      "Epoch  24/100 Batch  740/1562 - Loss:  0.504, Seconds: 3.81\n",
      "Epoch  24/100 Batch  760/1562 - Loss:  0.482, Seconds: 3.06\n",
      "Epoch  24/100 Batch  780/1562 - Loss:  0.462, Seconds: 4.18\n",
      "Epoch  24/100 Batch  800/1562 - Loss:  0.461, Seconds: 3.41\n",
      "Epoch  24/100 Batch  820/1562 - Loss:  0.431, Seconds: 3.78\n",
      "Epoch  24/100 Batch  840/1562 - Loss:  0.477, Seconds: 3.63\n",
      "Epoch  24/100 Batch  860/1562 - Loss:  0.439, Seconds: 3.58\n",
      "Epoch  24/100 Batch  880/1562 - Loss:  0.361, Seconds: 3.20\n",
      "Epoch  24/100 Batch  900/1562 - Loss:  0.447, Seconds: 3.98\n",
      "Epoch  24/100 Batch  920/1562 - Loss:  0.468, Seconds: 3.47\n",
      "Average loss for this update: 0.449-- No Improvement.\n",
      "Epoch  24/100 Batch  940/1562 - Loss:  0.398, Seconds: 3.26\n",
      "Epoch  24/100 Batch  960/1562 - Loss:  0.427, Seconds: 3.88\n",
      "Epoch  24/100 Batch  980/1562 - Loss:  0.433, Seconds: 3.93\n",
      "Epoch  24/100 Batch 1000/1562 - Loss:  0.472, Seconds: 3.67\n",
      "Epoch  24/100 Batch 1020/1562 - Loss:  0.461, Seconds: 3.19\n",
      "Epoch  24/100 Batch 1040/1562 - Loss:  0.499, Seconds: 3.67\n",
      "Epoch  24/100 Batch 1060/1562 - Loss:  0.467, Seconds: 3.47\n",
      "Epoch  24/100 Batch 1080/1562 - Loss:  0.451, Seconds: 4.35\n",
      "Epoch  24/100 Batch 1100/1562 - Loss:  0.510, Seconds: 3.17\n",
      "Epoch  24/100 Batch 1120/1562 - Loss:  0.483, Seconds: 3.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24/100 Batch 1140/1562 - Loss:  0.415, Seconds: 3.63\n",
      "Epoch  24/100 Batch 1160/1562 - Loss:  0.414, Seconds: 3.40\n",
      "Epoch  24/100 Batch 1180/1562 - Loss:  0.428, Seconds: 3.02\n",
      "Epoch  24/100 Batch 1200/1562 - Loss:  0.504, Seconds: 4.03\n",
      "Epoch  24/100 Batch 1220/1562 - Loss:  0.429, Seconds: 3.43\n",
      "Epoch  24/100 Batch 1240/1562 - Loss:  0.358, Seconds: 3.58\n",
      "Average loss for this update: 0.449-- No Improvement.\n",
      "Epoch  24/100 Batch 1260/1562 - Loss:  0.476, Seconds: 3.49\n",
      "Epoch  24/100 Batch 1280/1562 - Loss:  0.463, Seconds: 3.96\n",
      "Epoch  24/100 Batch 1300/1562 - Loss:  0.483, Seconds: 3.27\n",
      "Epoch  24/100 Batch 1320/1562 - Loss:  0.487, Seconds: 3.99\n",
      "Epoch  24/100 Batch 1340/1562 - Loss:  0.453, Seconds: 3.46\n",
      "Epoch  24/100 Batch 1360/1562 - Loss:  0.463, Seconds: 3.76\n",
      "Epoch  24/100 Batch 1380/1562 - Loss:  0.490, Seconds: 3.88\n",
      "Epoch  24/100 Batch 1400/1562 - Loss:  0.433, Seconds: 3.85\n",
      "Epoch  24/100 Batch 1420/1562 - Loss:  0.354, Seconds: 3.25\n",
      "Epoch  24/100 Batch 1440/1562 - Loss:  0.416, Seconds: 3.69\n",
      "Epoch  24/100 Batch 1460/1562 - Loss:  0.415, Seconds: 3.90\n",
      "Epoch  24/100 Batch 1480/1562 - Loss:  0.412, Seconds: 3.89\n",
      "Epoch  24/100 Batch 1500/1562 - Loss:  0.423, Seconds: 3.70\n",
      "Epoch  24/100 Batch 1520/1562 - Loss:  0.526, Seconds: 4.41\n",
      "Epoch  24/100 Batch 1540/1562 - Loss:  0.642, Seconds: 3.71\n",
      "Average loss for this update: 0.471-- No Improvement.\n",
      "Epoch  24/100 Batch 1560/1562 - Loss:  0.655, Seconds: 4.04\n",
      "Epoch  25/100 Batch   20/1562 - Loss:  0.587, Seconds: 3.86\n",
      "Epoch  25/100 Batch   40/1562 - Loss:  0.523, Seconds: 3.50\n",
      "Epoch  25/100 Batch   60/1562 - Loss:  0.612, Seconds: 3.08\n",
      "Epoch  25/100 Batch   80/1562 - Loss:  0.511, Seconds: 2.75\n",
      "Epoch  25/100 Batch  100/1562 - Loss:  0.458, Seconds: 3.48\n",
      "Epoch  25/100 Batch  120/1562 - Loss:  0.469, Seconds: 3.08\n",
      "Epoch  25/100 Batch  140/1562 - Loss:  0.472, Seconds: 3.41\n",
      "Epoch  25/100 Batch  160/1562 - Loss:  0.450, Seconds: 2.90\n",
      "Epoch  25/100 Batch  180/1562 - Loss:  0.477, Seconds: 3.74\n",
      "Epoch  25/100 Batch  200/1562 - Loss:  0.422, Seconds: 3.12\n",
      "Epoch  25/100 Batch  220/1562 - Loss:  0.455, Seconds: 3.11\n",
      "Epoch  25/100 Batch  240/1562 - Loss:  0.428, Seconds: 2.92\n",
      "Epoch  25/100 Batch  260/1562 - Loss:  0.472, Seconds: 4.13\n",
      "Epoch  25/100 Batch  280/1562 - Loss:  0.443, Seconds: 3.44\n",
      "Epoch  25/100 Batch  300/1562 - Loss:  0.396, Seconds: 4.13\n",
      "Average loss for this update: 0.475-- No Improvement.\n",
      "Epoch  25/100 Batch  320/1562 - Loss:  0.401, Seconds: 3.55\n",
      "Epoch  25/100 Batch  340/1562 - Loss:  0.419, Seconds: 3.29\n",
      "Epoch  25/100 Batch  360/1562 - Loss:  0.445, Seconds: 3.93\n",
      "Epoch  25/100 Batch  380/1562 - Loss:  0.409, Seconds: 2.88\n",
      "Epoch  25/100 Batch  400/1562 - Loss:  0.411, Seconds: 4.13\n",
      "Epoch  25/100 Batch  420/1562 - Loss:  0.439, Seconds: 3.50\n",
      "Epoch  25/100 Batch  440/1562 - Loss:  0.454, Seconds: 3.31\n",
      "Epoch  25/100 Batch  460/1562 - Loss:  0.460, Seconds: 3.20\n",
      "Epoch  25/100 Batch  480/1562 - Loss:  0.408, Seconds: 3.54\n",
      "Epoch  25/100 Batch  500/1562 - Loss:  0.467, Seconds: 3.77\n",
      "Epoch  25/100 Batch  520/1562 - Loss:  0.404, Seconds: 4.24\n",
      "Epoch  25/100 Batch  540/1562 - Loss:  0.439, Seconds: 3.19\n",
      "Epoch  25/100 Batch  560/1562 - Loss:  0.443, Seconds: 3.59\n",
      "Epoch  25/100 Batch  580/1562 - Loss:  0.382, Seconds: 3.59\n",
      "Epoch  25/100 Batch  600/1562 - Loss:  0.343, Seconds: 3.37\n",
      "Epoch  25/100 Batch  620/1562 - Loss:  0.424, Seconds: 3.75\n",
      "Average loss for this update: 0.422 -- New Record!\n",
      "Epoch  25/100 Batch  640/1562 - Loss:  0.442, Seconds: 3.36\n",
      "Epoch  25/100 Batch  660/1562 - Loss:  0.420, Seconds: 3.59\n",
      "Epoch  25/100 Batch  680/1562 - Loss:  0.390, Seconds: 4.16\n",
      "Epoch  25/100 Batch  700/1562 - Loss:  0.420, Seconds: 3.22\n",
      "Epoch  25/100 Batch  720/1562 - Loss:  0.445, Seconds: 4.00\n",
      "Epoch  25/100 Batch  740/1562 - Loss:  0.494, Seconds: 3.77\n",
      "Epoch  25/100 Batch  760/1562 - Loss:  0.473, Seconds: 2.94\n",
      "Epoch  25/100 Batch  780/1562 - Loss:  0.444, Seconds: 4.19\n",
      "Epoch  25/100 Batch  800/1562 - Loss:  0.449, Seconds: 3.42\n",
      "Epoch  25/100 Batch  820/1562 - Loss:  0.426, Seconds: 3.82\n",
      "Epoch  25/100 Batch  840/1562 - Loss:  0.455, Seconds: 3.56\n",
      "Epoch  25/100 Batch  860/1562 - Loss:  0.420, Seconds: 3.54\n",
      "Epoch  25/100 Batch  880/1562 - Loss:  0.341, Seconds: 3.21\n",
      "Epoch  25/100 Batch  900/1562 - Loss:  0.420, Seconds: 4.08\n",
      "Epoch  25/100 Batch  920/1562 - Loss:  0.435, Seconds: 3.33\n",
      "Average loss for this update: 0.43-- No Improvement.\n",
      "Epoch  25/100 Batch  940/1562 - Loss:  0.378, Seconds: 3.20\n",
      "Epoch  25/100 Batch  960/1562 - Loss:  0.395, Seconds: 3.86\n",
      "Epoch  25/100 Batch  980/1562 - Loss:  0.412, Seconds: 3.88\n",
      "Epoch  25/100 Batch 1000/1562 - Loss:  0.438, Seconds: 3.61\n",
      "Epoch  25/100 Batch 1020/1562 - Loss:  0.444, Seconds: 3.30\n",
      "Epoch  25/100 Batch 1040/1562 - Loss:  0.472, Seconds: 3.66\n",
      "Epoch  25/100 Batch 1060/1562 - Loss:  0.430, Seconds: 3.35\n",
      "Epoch  25/100 Batch 1080/1562 - Loss:  0.421, Seconds: 4.29\n",
      "Epoch  25/100 Batch 1100/1562 - Loss:  0.497, Seconds: 3.24\n",
      "Epoch  25/100 Batch 1120/1562 - Loss:  0.450, Seconds: 3.64\n",
      "Epoch  25/100 Batch 1140/1562 - Loss:  0.407, Seconds: 3.68\n",
      "Epoch  25/100 Batch 1160/1562 - Loss:  0.403, Seconds: 3.43\n",
      "Epoch  25/100 Batch 1180/1562 - Loss:  0.398, Seconds: 3.07\n",
      "Epoch  25/100 Batch 1200/1562 - Loss:  0.473, Seconds: 4.04\n",
      "Epoch  25/100 Batch 1220/1562 - Loss:  0.411, Seconds: 3.43\n",
      "Epoch  25/100 Batch 1240/1562 - Loss:  0.339, Seconds: 3.67\n",
      "Average loss for this update: 0.425-- No Improvement.\n",
      "Epoch  25/100 Batch 1260/1562 - Loss:  0.433, Seconds: 3.55\n",
      "Epoch  25/100 Batch 1280/1562 - Loss:  0.447, Seconds: 3.99\n",
      "Epoch  25/100 Batch 1300/1562 - Loss:  0.463, Seconds: 3.43\n",
      "Epoch  25/100 Batch 1320/1562 - Loss:  0.471, Seconds: 3.87\n",
      "Epoch  25/100 Batch 1340/1562 - Loss:  0.422, Seconds: 3.49\n",
      "Epoch  25/100 Batch 1360/1562 - Loss:  0.428, Seconds: 3.67\n",
      "Epoch  25/100 Batch 1380/1562 - Loss:  0.461, Seconds: 3.91\n",
      "Epoch  25/100 Batch 1400/1562 - Loss:  0.405, Seconds: 3.87\n",
      "Epoch  25/100 Batch 1420/1562 - Loss:  0.334, Seconds: 3.29\n",
      "Epoch  25/100 Batch 1440/1562 - Loss:  0.386, Seconds: 3.77\n",
      "Epoch  25/100 Batch 1460/1562 - Loss:  0.403, Seconds: 3.92\n",
      "Epoch  25/100 Batch 1480/1562 - Loss:  0.406, Seconds: 3.81\n",
      "Epoch  25/100 Batch 1500/1562 - Loss:  0.416, Seconds: 3.69\n",
      "Epoch  25/100 Batch 1520/1562 - Loss:  0.505, Seconds: 4.34\n",
      "Epoch  25/100 Batch 1540/1562 - Loss:  0.610, Seconds: 3.75\n",
      "Average loss for this update: 0.447-- No Improvement.\n",
      "Epoch  25/100 Batch 1560/1562 - Loss:  0.613, Seconds: 3.99\n",
      "Epoch  26/100 Batch   20/1562 - Loss:  0.567, Seconds: 3.82\n",
      "Epoch  26/100 Batch   40/1562 - Loss:  0.511, Seconds: 3.48\n",
      "Epoch  26/100 Batch   60/1562 - Loss:  0.585, Seconds: 3.11\n",
      "Epoch  26/100 Batch   80/1562 - Loss:  0.500, Seconds: 2.84\n",
      "Epoch  26/100 Batch  100/1562 - Loss:  0.445, Seconds: 3.46\n",
      "Epoch  26/100 Batch  120/1562 - Loss:  0.453, Seconds: 3.11\n",
      "Epoch  26/100 Batch  140/1562 - Loss:  0.458, Seconds: 3.31\n",
      "Epoch  26/100 Batch  160/1562 - Loss:  0.450, Seconds: 2.93\n",
      "Epoch  26/100 Batch  180/1562 - Loss:  0.468, Seconds: 3.72\n",
      "Epoch  26/100 Batch  200/1562 - Loss:  0.406, Seconds: 3.07\n",
      "Epoch  26/100 Batch  220/1562 - Loss:  0.447, Seconds: 3.12\n",
      "Epoch  26/100 Batch  240/1562 - Loss:  0.413, Seconds: 2.93\n",
      "Epoch  26/100 Batch  260/1562 - Loss:  0.459, Seconds: 4.12\n",
      "Epoch  26/100 Batch  280/1562 - Loss:  0.406, Seconds: 3.30\n",
      "Epoch  26/100 Batch  300/1562 - Loss:  0.378, Seconds: 4.09\n",
      "Average loss for this update: 0.458-- No Improvement.\n",
      "Epoch  26/100 Batch  320/1562 - Loss:  0.369, Seconds: 3.51\n",
      "Epoch  26/100 Batch  340/1562 - Loss:  0.416, Seconds: 3.37\n",
      "Epoch  26/100 Batch  360/1562 - Loss:  0.436, Seconds: 3.99\n",
      "Epoch  26/100 Batch  380/1562 - Loss:  0.371, Seconds: 2.90\n",
      "Epoch  26/100 Batch  400/1562 - Loss:  0.385, Seconds: 4.08\n",
      "Epoch  26/100 Batch  420/1562 - Loss:  0.419, Seconds: 3.56\n",
      "Epoch  26/100 Batch  440/1562 - Loss:  0.461, Seconds: 3.35\n",
      "Epoch  26/100 Batch  460/1562 - Loss:  0.426, Seconds: 3.21\n",
      "Epoch  26/100 Batch  480/1562 - Loss:  0.377, Seconds: 3.58\n",
      "Epoch  26/100 Batch  500/1562 - Loss:  0.450, Seconds: 3.82\n",
      "Epoch  26/100 Batch  520/1562 - Loss:  0.372, Seconds: 4.16\n",
      "Epoch  26/100 Batch  540/1562 - Loss:  0.427, Seconds: 3.20\n",
      "Epoch  26/100 Batch  560/1562 - Loss:  0.395, Seconds: 3.60\n",
      "Epoch  26/100 Batch  580/1562 - Loss:  0.360, Seconds: 3.60\n",
      "Epoch  26/100 Batch  600/1562 - Loss:  0.325, Seconds: 3.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  26/100 Batch  620/1562 - Loss:  0.389, Seconds: 3.76\n",
      "Average loss for this update: 0.4 -- New Record!\n",
      "Epoch  26/100 Batch  640/1562 - Loss:  0.428, Seconds: 3.37\n",
      "Epoch  26/100 Batch  660/1562 - Loss:  0.393, Seconds: 3.50\n",
      "Epoch  26/100 Batch  680/1562 - Loss:  0.361, Seconds: 4.17\n",
      "Epoch  26/100 Batch  700/1562 - Loss:  0.398, Seconds: 3.17\n",
      "Epoch  26/100 Batch  720/1562 - Loss:  0.428, Seconds: 4.00\n",
      "Epoch  26/100 Batch  740/1562 - Loss:  0.461, Seconds: 3.84\n",
      "Epoch  26/100 Batch  760/1562 - Loss:  0.434, Seconds: 2.96\n",
      "Epoch  26/100 Batch  780/1562 - Loss:  0.425, Seconds: 4.35\n",
      "Epoch  26/100 Batch  800/1562 - Loss:  0.419, Seconds: 3.35\n",
      "Epoch  26/100 Batch  820/1562 - Loss:  0.412, Seconds: 3.82\n",
      "Epoch  26/100 Batch  840/1562 - Loss:  0.424, Seconds: 3.68\n",
      "Epoch  26/100 Batch  860/1562 - Loss:  0.395, Seconds: 3.61\n",
      "Epoch  26/100 Batch  880/1562 - Loss:  0.325, Seconds: 3.17\n",
      "Epoch  26/100 Batch  900/1562 - Loss:  0.400, Seconds: 4.08\n",
      "Epoch  26/100 Batch  920/1562 - Loss:  0.430, Seconds: 3.44\n",
      "Average loss for this update: 0.407-- No Improvement.\n",
      "Epoch  26/100 Batch  940/1562 - Loss:  0.354, Seconds: 3.19\n",
      "Epoch  26/100 Batch  960/1562 - Loss:  0.369, Seconds: 3.83\n",
      "Epoch  26/100 Batch  980/1562 - Loss:  0.382, Seconds: 3.85\n",
      "Epoch  26/100 Batch 1000/1562 - Loss:  0.420, Seconds: 3.73\n",
      "Epoch  26/100 Batch 1020/1562 - Loss:  0.408, Seconds: 3.26\n",
      "Epoch  26/100 Batch 1040/1562 - Loss:  0.428, Seconds: 3.66\n",
      "Epoch  26/100 Batch 1060/1562 - Loss:  0.413, Seconds: 3.45\n",
      "Epoch  26/100 Batch 1080/1562 - Loss:  0.409, Seconds: 4.28\n",
      "Epoch  26/100 Batch 1100/1562 - Loss:  0.457, Seconds: 3.24\n",
      "Epoch  26/100 Batch 1120/1562 - Loss:  0.432, Seconds: 3.68\n",
      "Epoch  26/100 Batch 1140/1562 - Loss:  0.392, Seconds: 3.71\n",
      "Epoch  26/100 Batch 1160/1562 - Loss:  0.391, Seconds: 3.51\n",
      "Epoch  26/100 Batch 1180/1562 - Loss:  0.386, Seconds: 2.99\n",
      "Epoch  26/100 Batch 1200/1562 - Loss:  0.447, Seconds: 4.09\n",
      "Epoch  26/100 Batch 1220/1562 - Loss:  0.392, Seconds: 3.73\n",
      "Epoch  26/100 Batch 1240/1562 - Loss:  0.333, Seconds: 3.75\n",
      "Average loss for this update: 0.403-- No Improvement.\n",
      "Epoch  26/100 Batch 1260/1562 - Loss:  0.426, Seconds: 3.47\n",
      "Epoch  26/100 Batch 1280/1562 - Loss:  0.423, Seconds: 3.85\n",
      "Epoch  26/100 Batch 1300/1562 - Loss:  0.433, Seconds: 3.31\n",
      "Epoch  26/100 Batch 1320/1562 - Loss:  0.442, Seconds: 3.83\n",
      "Epoch  26/100 Batch 1340/1562 - Loss:  0.407, Seconds: 3.45\n",
      "Epoch  26/100 Batch 1360/1562 - Loss:  0.423, Seconds: 3.70\n",
      "Epoch  26/100 Batch 1380/1562 - Loss:  0.430, Seconds: 3.93\n",
      "Epoch  26/100 Batch 1400/1562 - Loss:  0.396, Seconds: 3.93\n",
      "Epoch  26/100 Batch 1420/1562 - Loss:  0.312, Seconds: 3.40\n",
      "Epoch  26/100 Batch 1440/1562 - Loss:  0.382, Seconds: 3.71\n",
      "Epoch  26/100 Batch 1460/1562 - Loss:  0.379, Seconds: 3.87\n",
      "Epoch  26/100 Batch 1480/1562 - Loss:  0.388, Seconds: 3.95\n",
      "Epoch  26/100 Batch 1500/1562 - Loss:  0.390, Seconds: 3.73\n",
      "Epoch  26/100 Batch 1520/1562 - Loss:  0.492, Seconds: 4.44\n",
      "Epoch  26/100 Batch 1540/1562 - Loss:  0.608, Seconds: 3.73\n",
      "Average loss for this update: 0.43-- No Improvement.\n",
      "Epoch  26/100 Batch 1560/1562 - Loss:  0.588, Seconds: 3.98\n",
      "Epoch  27/100 Batch   20/1562 - Loss:  0.540, Seconds: 3.97\n",
      "Epoch  27/100 Batch   40/1562 - Loss:  0.488, Seconds: 3.52\n",
      "Epoch  27/100 Batch   60/1562 - Loss:  0.567, Seconds: 3.17\n",
      "Epoch  27/100 Batch   80/1562 - Loss:  0.472, Seconds: 2.88\n",
      "Epoch  27/100 Batch  100/1562 - Loss:  0.409, Seconds: 3.46\n",
      "Epoch  27/100 Batch  120/1562 - Loss:  0.417, Seconds: 3.17\n",
      "Epoch  27/100 Batch  140/1562 - Loss:  0.431, Seconds: 3.31\n",
      "Epoch  27/100 Batch  160/1562 - Loss:  0.408, Seconds: 2.90\n",
      "Epoch  27/100 Batch  180/1562 - Loss:  0.429, Seconds: 3.70\n",
      "Epoch  27/100 Batch  200/1562 - Loss:  0.376, Seconds: 3.07\n",
      "Epoch  27/100 Batch  220/1562 - Loss:  0.402, Seconds: 3.09\n",
      "Epoch  27/100 Batch  240/1562 - Loss:  0.395, Seconds: 3.03\n",
      "Epoch  27/100 Batch  260/1562 - Loss:  0.439, Seconds: 4.14\n",
      "Epoch  27/100 Batch  280/1562 - Loss:  0.380, Seconds: 3.34\n",
      "Epoch  27/100 Batch  300/1562 - Loss:  0.347, Seconds: 4.08\n",
      "Average loss for this update: 0.429-- No Improvement.\n",
      "Epoch  27/100 Batch  320/1562 - Loss:  0.347, Seconds: 3.53\n",
      "Epoch  27/100 Batch  340/1562 - Loss:  0.389, Seconds: 3.32\n",
      "Epoch  27/100 Batch  360/1562 - Loss:  0.392, Seconds: 3.91\n",
      "Epoch  27/100 Batch  380/1562 - Loss:  0.363, Seconds: 2.87\n",
      "Epoch  27/100 Batch  400/1562 - Loss:  0.387, Seconds: 4.12\n",
      "Epoch  27/100 Batch  420/1562 - Loss:  0.412, Seconds: 3.58\n",
      "Epoch  27/100 Batch  440/1562 - Loss:  0.416, Seconds: 3.34\n",
      "Epoch  27/100 Batch  460/1562 - Loss:  0.424, Seconds: 3.19\n",
      "Epoch  27/100 Batch  480/1562 - Loss:  0.365, Seconds: 3.58\n",
      "Epoch  27/100 Batch  500/1562 - Loss:  0.415, Seconds: 3.80\n",
      "Epoch  27/100 Batch  520/1562 - Loss:  0.360, Seconds: 4.17\n",
      "Epoch  27/100 Batch  540/1562 - Loss:  0.410, Seconds: 3.11\n",
      "Epoch  27/100 Batch  560/1562 - Loss:  0.380, Seconds: 3.53\n",
      "Epoch  27/100 Batch  580/1562 - Loss:  0.343, Seconds: 3.49\n",
      "Epoch  27/100 Batch  600/1562 - Loss:  0.289, Seconds: 3.37\n",
      "Epoch  27/100 Batch  620/1562 - Loss:  0.388, Seconds: 3.74\n",
      "Average loss for this update: 0.381 -- New Record!\n",
      "Epoch  27/100 Batch  640/1562 - Loss:  0.407, Seconds: 3.38\n",
      "Epoch  27/100 Batch  660/1562 - Loss:  0.380, Seconds: 3.55\n",
      "Epoch  27/100 Batch  680/1562 - Loss:  0.344, Seconds: 4.08\n",
      "Epoch  27/100 Batch  700/1562 - Loss:  0.379, Seconds: 3.21\n",
      "Epoch  27/100 Batch  720/1562 - Loss:  0.392, Seconds: 4.02\n",
      "Epoch  27/100 Batch  740/1562 - Loss:  0.433, Seconds: 3.95\n",
      "Epoch  27/100 Batch  760/1562 - Loss:  0.417, Seconds: 3.00\n",
      "Epoch  27/100 Batch  780/1562 - Loss:  0.401, Seconds: 4.27\n",
      "Epoch  27/100 Batch  800/1562 - Loss:  0.399, Seconds: 3.36\n",
      "Epoch  27/100 Batch  820/1562 - Loss:  0.376, Seconds: 3.88\n",
      "Epoch  27/100 Batch  840/1562 - Loss:  0.417, Seconds: 3.58\n",
      "Epoch  27/100 Batch  860/1562 - Loss:  0.374, Seconds: 3.55\n",
      "Epoch  27/100 Batch  880/1562 - Loss:  0.314, Seconds: 3.18\n",
      "Epoch  27/100 Batch  900/1562 - Loss:  0.371, Seconds: 3.98\n",
      "Epoch  27/100 Batch  920/1562 - Loss:  0.406, Seconds: 3.42\n",
      "Average loss for this update: 0.385-- No Improvement.\n",
      "Epoch  27/100 Batch  940/1562 - Loss:  0.327, Seconds: 3.20\n",
      "Epoch  27/100 Batch  960/1562 - Loss:  0.362, Seconds: 3.76\n",
      "Epoch  27/100 Batch  980/1562 - Loss:  0.374, Seconds: 3.91\n",
      "Epoch  27/100 Batch 1000/1562 - Loss:  0.395, Seconds: 3.60\n",
      "Epoch  27/100 Batch 1020/1562 - Loss:  0.395, Seconds: 3.26\n",
      "Epoch  27/100 Batch 1040/1562 - Loss:  0.410, Seconds: 3.63\n",
      "Epoch  27/100 Batch 1060/1562 - Loss:  0.395, Seconds: 3.46\n",
      "Epoch  27/100 Batch 1080/1562 - Loss:  0.393, Seconds: 4.31\n",
      "Epoch  27/100 Batch 1100/1562 - Loss:  0.443, Seconds: 3.23\n",
      "Epoch  27/100 Batch 1120/1562 - Loss:  0.417, Seconds: 3.69\n",
      "Epoch  27/100 Batch 1140/1562 - Loss:  0.385, Seconds: 3.73\n",
      "Epoch  27/100 Batch 1160/1562 - Loss:  0.349, Seconds: 3.46\n",
      "Epoch  27/100 Batch 1180/1562 - Loss:  0.373, Seconds: 2.97\n",
      "Epoch  27/100 Batch 1200/1562 - Loss:  0.435, Seconds: 4.12\n",
      "Epoch  27/100 Batch 1220/1562 - Loss:  0.378, Seconds: 3.40\n",
      "Epoch  27/100 Batch 1240/1562 - Loss:  0.299, Seconds: 3.66\n",
      "Average loss for this update: 0.386-- No Improvement.\n",
      "Epoch  27/100 Batch 1260/1562 - Loss:  0.404, Seconds: 3.46\n",
      "Epoch  27/100 Batch 1280/1562 - Loss:  0.409, Seconds: 3.88\n",
      "Epoch  27/100 Batch 1300/1562 - Loss:  0.430, Seconds: 3.37\n",
      "Epoch  27/100 Batch 1320/1562 - Loss:  0.433, Seconds: 3.88\n",
      "Epoch  27/100 Batch 1340/1562 - Loss:  0.380, Seconds: 3.52\n",
      "Epoch  27/100 Batch 1360/1562 - Loss:  0.399, Seconds: 3.77\n",
      "Epoch  27/100 Batch 1380/1562 - Loss:  0.410, Seconds: 3.99\n",
      "Epoch  27/100 Batch 1400/1562 - Loss:  0.370, Seconds: 3.98\n",
      "Epoch  27/100 Batch 1420/1562 - Loss:  0.307, Seconds: 3.21\n",
      "Epoch  27/100 Batch 1440/1562 - Loss:  0.354, Seconds: 3.84\n",
      "Epoch  27/100 Batch 1460/1562 - Loss:  0.361, Seconds: 3.86\n",
      "Epoch  27/100 Batch 1480/1562 - Loss:  0.372, Seconds: 3.83\n",
      "Epoch  27/100 Batch 1500/1562 - Loss:  0.373, Seconds: 3.58\n",
      "Epoch  27/100 Batch 1520/1562 - Loss:  0.450, Seconds: 4.34\n",
      "Epoch  27/100 Batch 1540/1562 - Loss:  0.549, Seconds: 3.78\n",
      "Average loss for this update: 0.406-- No Improvement.\n",
      "Epoch  27/100 Batch 1560/1562 - Loss:  0.550, Seconds: 3.95\n",
      "Epoch  28/100 Batch   20/1562 - Loss:  0.515, Seconds: 3.89\n",
      "Epoch  28/100 Batch   40/1562 - Loss:  0.466, Seconds: 3.40\n",
      "Epoch  28/100 Batch   60/1562 - Loss:  0.540, Seconds: 3.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  28/100 Batch   80/1562 - Loss:  0.432, Seconds: 2.82\n",
      "Epoch  28/100 Batch  100/1562 - Loss:  0.396, Seconds: 3.45\n",
      "Epoch  28/100 Batch  120/1562 - Loss:  0.405, Seconds: 3.10\n",
      "Epoch  28/100 Batch  140/1562 - Loss:  0.413, Seconds: 3.30\n",
      "Epoch  28/100 Batch  160/1562 - Loss:  0.390, Seconds: 2.90\n",
      "Epoch  28/100 Batch  180/1562 - Loss:  0.427, Seconds: 3.69\n",
      "Epoch  28/100 Batch  200/1562 - Loss:  0.364, Seconds: 3.10\n",
      "Epoch  28/100 Batch  220/1562 - Loss:  0.388, Seconds: 3.08\n",
      "Epoch  28/100 Batch  240/1562 - Loss:  0.367, Seconds: 2.87\n",
      "Epoch  28/100 Batch  260/1562 - Loss:  0.415, Seconds: 4.16\n",
      "Epoch  28/100 Batch  280/1562 - Loss:  0.366, Seconds: 3.33\n",
      "Epoch  28/100 Batch  300/1562 - Loss:  0.346, Seconds: 4.11\n",
      "Average loss for this update: 0.412-- No Improvement.\n",
      "Epoch  28/100 Batch  320/1562 - Loss:  0.343, Seconds: 3.59\n",
      "Epoch  28/100 Batch  340/1562 - Loss:  0.378, Seconds: 3.37\n",
      "Epoch  28/100 Batch  360/1562 - Loss:  0.380, Seconds: 3.91\n",
      "Epoch  28/100 Batch  380/1562 - Loss:  0.351, Seconds: 2.91\n",
      "Epoch  28/100 Batch  400/1562 - Loss:  0.359, Seconds: 4.16\n",
      "Epoch  28/100 Batch  420/1562 - Loss:  0.383, Seconds: 3.52\n",
      "Epoch  28/100 Batch  440/1562 - Loss:  0.398, Seconds: 3.34\n",
      "Epoch  28/100 Batch  460/1562 - Loss:  0.387, Seconds: 3.12\n",
      "Epoch  28/100 Batch  480/1562 - Loss:  0.349, Seconds: 3.61\n",
      "Epoch  28/100 Batch  500/1562 - Loss:  0.413, Seconds: 3.77\n",
      "Epoch  28/100 Batch  520/1562 - Loss:  0.334, Seconds: 4.23\n",
      "Epoch  28/100 Batch  540/1562 - Loss:  0.388, Seconds: 3.13\n",
      "Epoch  28/100 Batch  560/1562 - Loss:  0.366, Seconds: 3.55\n",
      "Epoch  28/100 Batch  580/1562 - Loss:  0.329, Seconds: 3.53\n",
      "Epoch  28/100 Batch  600/1562 - Loss:  0.281, Seconds: 3.38\n",
      "Epoch  28/100 Batch  620/1562 - Loss:  0.357, Seconds: 3.70\n",
      "Average loss for this update: 0.363 -- New Record!\n",
      "Epoch  28/100 Batch  640/1562 - Loss:  0.396, Seconds: 3.43\n",
      "Epoch  28/100 Batch  660/1562 - Loss:  0.356, Seconds: 3.57\n",
      "Epoch  28/100 Batch  680/1562 - Loss:  0.316, Seconds: 4.09\n",
      "Epoch  28/100 Batch  700/1562 - Loss:  0.374, Seconds: 3.19\n",
      "Epoch  28/100 Batch  720/1562 - Loss:  0.392, Seconds: 3.98\n",
      "Epoch  28/100 Batch  740/1562 - Loss:  0.417, Seconds: 3.76\n",
      "Epoch  28/100 Batch  760/1562 - Loss:  0.395, Seconds: 2.99\n",
      "Epoch  28/100 Batch  780/1562 - Loss:  0.402, Seconds: 4.26\n",
      "Epoch  28/100 Batch  800/1562 - Loss:  0.381, Seconds: 3.33\n",
      "Epoch  28/100 Batch  820/1562 - Loss:  0.355, Seconds: 3.80\n",
      "Epoch  28/100 Batch  840/1562 - Loss:  0.382, Seconds: 3.61\n",
      "Epoch  28/100 Batch  860/1562 - Loss:  0.353, Seconds: 3.61\n",
      "Epoch  28/100 Batch  880/1562 - Loss:  0.294, Seconds: 3.27\n",
      "Epoch  28/100 Batch  900/1562 - Loss:  0.358, Seconds: 4.04\n",
      "Epoch  28/100 Batch  920/1562 - Loss:  0.378, Seconds: 3.43\n",
      "Average loss for this update: 0.368-- No Improvement.\n",
      "Epoch  28/100 Batch  940/1562 - Loss:  0.312, Seconds: 3.24\n",
      "Epoch  28/100 Batch  960/1562 - Loss:  0.343, Seconds: 3.88\n",
      "Epoch  28/100 Batch  980/1562 - Loss:  0.348, Seconds: 3.87\n",
      "Epoch  28/100 Batch 1000/1562 - Loss:  0.383, Seconds: 3.68\n",
      "Epoch  28/100 Batch 1020/1562 - Loss:  0.386, Seconds: 3.29\n",
      "Epoch  28/100 Batch 1040/1562 - Loss:  0.412, Seconds: 3.66\n",
      "Epoch  28/100 Batch 1060/1562 - Loss:  0.365, Seconds: 3.41\n",
      "Epoch  28/100 Batch 1080/1562 - Loss:  0.372, Seconds: 4.29\n",
      "Epoch  28/100 Batch 1100/1562 - Loss:  0.419, Seconds: 3.29\n",
      "Epoch  28/100 Batch 1120/1562 - Loss:  0.387, Seconds: 3.64\n",
      "Epoch  28/100 Batch 1140/1562 - Loss:  0.354, Seconds: 3.69\n",
      "Epoch  28/100 Batch 1160/1562 - Loss:  0.346, Seconds: 3.52\n",
      "Epoch  28/100 Batch 1180/1562 - Loss:  0.357, Seconds: 3.06\n",
      "Epoch  28/100 Batch 1200/1562 - Loss:  0.409, Seconds: 4.04\n",
      "Epoch  28/100 Batch 1220/1562 - Loss:  0.344, Seconds: 3.44\n",
      "Epoch  28/100 Batch 1240/1562 - Loss:  0.295, Seconds: 3.62\n",
      "Average loss for this update: 0.367-- No Improvement.\n",
      "Epoch  28/100 Batch 1260/1562 - Loss:  0.390, Seconds: 3.49\n",
      "Epoch  28/100 Batch 1280/1562 - Loss:  0.399, Seconds: 3.82\n",
      "Epoch  28/100 Batch 1300/1562 - Loss:  0.397, Seconds: 3.34\n",
      "Epoch  28/100 Batch 1320/1562 - Loss:  0.403, Seconds: 3.94\n",
      "Epoch  28/100 Batch 1340/1562 - Loss:  0.354, Seconds: 3.46\n",
      "Epoch  28/100 Batch 1360/1562 - Loss:  0.380, Seconds: 3.68\n",
      "Epoch  28/100 Batch 1380/1562 - Loss:  0.390, Seconds: 3.95\n",
      "Epoch  28/100 Batch 1400/1562 - Loss:  0.354, Seconds: 3.94\n",
      "Epoch  28/100 Batch 1420/1562 - Loss:  0.287, Seconds: 3.32\n",
      "Epoch  28/100 Batch 1440/1562 - Loss:  0.324, Seconds: 3.76\n",
      "Epoch  28/100 Batch 1460/1562 - Loss:  0.342, Seconds: 3.88\n",
      "Epoch  28/100 Batch 1480/1562 - Loss:  0.349, Seconds: 3.86\n",
      "Epoch  28/100 Batch 1500/1562 - Loss:  0.346, Seconds: 3.76\n",
      "Epoch  28/100 Batch 1520/1562 - Loss:  0.411, Seconds: 4.46\n",
      "Epoch  28/100 Batch 1540/1562 - Loss:  0.532, Seconds: 3.77\n",
      "Average loss for this update: 0.383-- No Improvement.\n",
      "Epoch  28/100 Batch 1560/1562 - Loss:  0.532, Seconds: 4.00\n",
      "Epoch  29/100 Batch   20/1562 - Loss:  0.499, Seconds: 3.88\n",
      "Epoch  29/100 Batch   40/1562 - Loss:  0.447, Seconds: 3.51\n",
      "Epoch  29/100 Batch   60/1562 - Loss:  0.524, Seconds: 3.04\n",
      "Epoch  29/100 Batch   80/1562 - Loss:  0.424, Seconds: 2.94\n",
      "Epoch  29/100 Batch  100/1562 - Loss:  0.377, Seconds: 3.56\n",
      "Epoch  29/100 Batch  120/1562 - Loss:  0.384, Seconds: 3.13\n",
      "Epoch  29/100 Batch  140/1562 - Loss:  0.397, Seconds: 3.33\n",
      "Epoch  29/100 Batch  160/1562 - Loss:  0.376, Seconds: 2.91\n",
      "Epoch  29/100 Batch  180/1562 - Loss:  0.391, Seconds: 3.77\n",
      "Epoch  29/100 Batch  200/1562 - Loss:  0.343, Seconds: 3.09\n",
      "Epoch  29/100 Batch  220/1562 - Loss:  0.380, Seconds: 3.10\n",
      "Epoch  29/100 Batch  240/1562 - Loss:  0.352, Seconds: 2.93\n",
      "Epoch  29/100 Batch  260/1562 - Loss:  0.381, Seconds: 4.12\n",
      "Epoch  29/100 Batch  280/1562 - Loss:  0.336, Seconds: 3.30\n",
      "Epoch  29/100 Batch  300/1562 - Loss:  0.317, Seconds: 4.17\n",
      "Average loss for this update: 0.392-- No Improvement.\n",
      "Epoch  29/100 Batch  320/1562 - Loss:  0.330, Seconds: 3.55\n",
      "Epoch  29/100 Batch  340/1562 - Loss:  0.352, Seconds: 3.32\n",
      "Epoch  29/100 Batch  360/1562 - Loss:  0.358, Seconds: 4.00\n",
      "Epoch  29/100 Batch  380/1562 - Loss:  0.335, Seconds: 2.96\n",
      "Epoch  29/100 Batch  400/1562 - Loss:  0.346, Seconds: 4.10\n",
      "Epoch  29/100 Batch  420/1562 - Loss:  0.369, Seconds: 3.58\n",
      "Epoch  29/100 Batch  440/1562 - Loss:  0.390, Seconds: 3.49\n",
      "Epoch  29/100 Batch  460/1562 - Loss:  0.369, Seconds: 3.14\n",
      "Epoch  29/100 Batch  480/1562 - Loss:  0.336, Seconds: 3.53\n",
      "Epoch  29/100 Batch  500/1562 - Loss:  0.392, Seconds: 3.81\n",
      "Epoch  29/100 Batch  520/1562 - Loss:  0.334, Seconds: 4.13\n",
      "Epoch  29/100 Batch  540/1562 - Loss:  0.369, Seconds: 3.18\n",
      "Epoch  29/100 Batch  560/1562 - Loss:  0.352, Seconds: 3.55\n",
      "Epoch  29/100 Batch  580/1562 - Loss:  0.311, Seconds: 3.58\n",
      "Epoch  29/100 Batch  600/1562 - Loss:  0.282, Seconds: 3.36\n",
      "Epoch  29/100 Batch  620/1562 - Loss:  0.331, Seconds: 3.79\n",
      "Average loss for this update: 0.348 -- New Record!\n",
      "Epoch  29/100 Batch  640/1562 - Loss:  0.371, Seconds: 3.35\n",
      "Epoch  29/100 Batch  660/1562 - Loss:  0.348, Seconds: 3.51\n",
      "Epoch  29/100 Batch  680/1562 - Loss:  0.296, Seconds: 4.26\n",
      "Epoch  29/100 Batch  700/1562 - Loss:  0.351, Seconds: 3.70\n",
      "Epoch  29/100 Batch  720/1562 - Loss:  0.362, Seconds: 4.11\n",
      "Epoch  29/100 Batch  740/1562 - Loss:  0.392, Seconds: 3.83\n",
      "Epoch  29/100 Batch  760/1562 - Loss:  0.368, Seconds: 3.01\n",
      "Epoch  29/100 Batch  780/1562 - Loss:  0.376, Seconds: 4.34\n",
      "Epoch  29/100 Batch  800/1562 - Loss:  0.361, Seconds: 3.42\n",
      "Epoch  29/100 Batch  820/1562 - Loss:  0.338, Seconds: 3.78\n",
      "Epoch  29/100 Batch  840/1562 - Loss:  0.379, Seconds: 3.55\n",
      "Epoch  29/100 Batch  860/1562 - Loss:  0.358, Seconds: 3.60\n",
      "Epoch  29/100 Batch  880/1562 - Loss:  0.280, Seconds: 3.22\n",
      "Epoch  29/100 Batch  900/1562 - Loss:  0.334, Seconds: 4.10\n",
      "Epoch  29/100 Batch  920/1562 - Loss:  0.355, Seconds: 3.43\n",
      "Average loss for this update: 0.35-- No Improvement.\n",
      "Epoch  29/100 Batch  940/1562 - Loss:  0.306, Seconds: 3.20\n",
      "Epoch  29/100 Batch  960/1562 - Loss:  0.321, Seconds: 3.81\n",
      "Epoch  29/100 Batch  980/1562 - Loss:  0.330, Seconds: 3.86\n",
      "Epoch  29/100 Batch 1000/1562 - Loss:  0.353, Seconds: 3.66\n",
      "Epoch  29/100 Batch 1020/1562 - Loss:  0.364, Seconds: 3.33\n",
      "Epoch  29/100 Batch 1040/1562 - Loss:  0.387, Seconds: 3.79\n",
      "Epoch  29/100 Batch 1060/1562 - Loss:  0.358, Seconds: 3.56\n",
      "Epoch  29/100 Batch 1080/1562 - Loss:  0.350, Seconds: 4.29\n",
      "Epoch  29/100 Batch 1100/1562 - Loss:  0.411, Seconds: 3.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  29/100 Batch 1120/1562 - Loss:  0.372, Seconds: 3.70\n",
      "Epoch  29/100 Batch 1140/1562 - Loss:  0.350, Seconds: 3.60\n",
      "Epoch  29/100 Batch 1160/1562 - Loss:  0.339, Seconds: 3.39\n",
      "Epoch  29/100 Batch 1180/1562 - Loss:  0.335, Seconds: 3.15\n",
      "Epoch  29/100 Batch 1200/1562 - Loss:  0.379, Seconds: 4.00\n",
      "Epoch  29/100 Batch 1220/1562 - Loss:  0.344, Seconds: 3.47\n",
      "Epoch  29/100 Batch 1240/1562 - Loss:  0.280, Seconds: 3.61\n",
      "Average loss for this update: 0.351-- No Improvement.\n",
      "Epoch  29/100 Batch 1260/1562 - Loss:  0.375, Seconds: 3.53\n",
      "Epoch  29/100 Batch 1280/1562 - Loss:  0.368, Seconds: 3.86\n",
      "Epoch  29/100 Batch 1300/1562 - Loss:  0.384, Seconds: 3.22\n",
      "Epoch  29/100 Batch 1320/1562 - Loss:  0.377, Seconds: 3.85\n",
      "Epoch  29/100 Batch 1340/1562 - Loss:  0.345, Seconds: 3.44\n",
      "Epoch  29/100 Batch 1360/1562 - Loss:  0.362, Seconds: 3.66\n",
      "Epoch  29/100 Batch 1380/1562 - Loss:  0.393, Seconds: 3.93\n",
      "Epoch  29/100 Batch 1400/1562 - Loss:  0.346, Seconds: 3.90\n",
      "Epoch  29/100 Batch 1420/1562 - Loss:  0.284, Seconds: 3.29\n",
      "Epoch  29/100 Batch 1440/1562 - Loss:  0.327, Seconds: 3.65\n",
      "Epoch  29/100 Batch 1460/1562 - Loss:  0.330, Seconds: 3.97\n",
      "Epoch  29/100 Batch 1480/1562 - Loss:  0.340, Seconds: 3.93\n",
      "Epoch  29/100 Batch 1500/1562 - Loss:  0.337, Seconds: 3.77\n",
      "Epoch  29/100 Batch 1520/1562 - Loss:  0.433, Seconds: 4.34\n",
      "Epoch  29/100 Batch 1540/1562 - Loss:  0.499, Seconds: 3.72\n",
      "Average loss for this update: 0.372-- No Improvement.\n",
      "Epoch  29/100 Batch 1560/1562 - Loss:  0.497, Seconds: 3.89\n",
      "Epoch  30/100 Batch   20/1562 - Loss:  0.477, Seconds: 3.86\n",
      "Epoch  30/100 Batch   40/1562 - Loss:  0.428, Seconds: 3.45\n",
      "Epoch  30/100 Batch   60/1562 - Loss:  0.479, Seconds: 3.08\n",
      "Epoch  30/100 Batch   80/1562 - Loss:  0.407, Seconds: 2.78\n",
      "Epoch  30/100 Batch  100/1562 - Loss:  0.362, Seconds: 3.43\n",
      "Epoch  30/100 Batch  120/1562 - Loss:  0.377, Seconds: 3.15\n",
      "Epoch  30/100 Batch  140/1562 - Loss:  0.388, Seconds: 3.32\n",
      "Epoch  30/100 Batch  160/1562 - Loss:  0.345, Seconds: 2.94\n",
      "Epoch  30/100 Batch  180/1562 - Loss:  0.364, Seconds: 3.74\n",
      "Epoch  30/100 Batch  200/1562 - Loss:  0.325, Seconds: 3.12\n",
      "Epoch  30/100 Batch  220/1562 - Loss:  0.340, Seconds: 3.09\n",
      "Epoch  30/100 Batch  240/1562 - Loss:  0.334, Seconds: 2.90\n",
      "Epoch  30/100 Batch  260/1562 - Loss:  0.378, Seconds: 4.20\n",
      "Epoch  30/100 Batch  280/1562 - Loss:  0.319, Seconds: 3.40\n",
      "Epoch  30/100 Batch  300/1562 - Loss:  0.306, Seconds: 4.15\n",
      "Average loss for this update: 0.373-- No Improvement.\n",
      "Epoch  30/100 Batch  320/1562 - Loss:  0.318, Seconds: 3.48\n",
      "Epoch  30/100 Batch  340/1562 - Loss:  0.329, Seconds: 3.30\n",
      "Epoch  30/100 Batch  360/1562 - Loss:  0.358, Seconds: 3.90\n",
      "Epoch  30/100 Batch  380/1562 - Loss:  0.305, Seconds: 2.93\n",
      "Epoch  30/100 Batch  400/1562 - Loss:  0.331, Seconds: 4.11\n",
      "Epoch  30/100 Batch  420/1562 - Loss:  0.341, Seconds: 3.64\n",
      "Epoch  30/100 Batch  440/1562 - Loss:  0.362, Seconds: 3.28\n",
      "Epoch  30/100 Batch  460/1562 - Loss:  0.349, Seconds: 3.19\n",
      "Epoch  30/100 Batch  480/1562 - Loss:  0.324, Seconds: 3.59\n",
      "Epoch  30/100 Batch  500/1562 - Loss:  0.371, Seconds: 3.77\n",
      "Epoch  30/100 Batch  520/1562 - Loss:  0.310, Seconds: 4.16\n",
      "Epoch  30/100 Batch  540/1562 - Loss:  0.352, Seconds: 3.15\n",
      "Epoch  30/100 Batch  560/1562 - Loss:  0.328, Seconds: 3.56\n",
      "Epoch  30/100 Batch  580/1562 - Loss:  0.290, Seconds: 3.50\n",
      "Epoch  30/100 Batch  600/1562 - Loss:  0.259, Seconds: 3.37\n",
      "Epoch  30/100 Batch  620/1562 - Loss:  0.316, Seconds: 3.74\n",
      "Average loss for this update: 0.328 -- New Record!\n",
      "Epoch  30/100 Batch  640/1562 - Loss:  0.352, Seconds: 3.36\n",
      "Epoch  30/100 Batch  660/1562 - Loss:  0.329, Seconds: 3.51\n",
      "Epoch  30/100 Batch  680/1562 - Loss:  0.287, Seconds: 4.10\n",
      "Epoch  30/100 Batch  700/1562 - Loss:  0.333, Seconds: 3.23\n",
      "Epoch  30/100 Batch  720/1562 - Loss:  0.357, Seconds: 3.94\n",
      "Epoch  30/100 Batch  740/1562 - Loss:  0.374, Seconds: 3.76\n",
      "Epoch  30/100 Batch  760/1562 - Loss:  0.357, Seconds: 2.96\n",
      "Epoch  30/100 Batch  780/1562 - Loss:  0.346, Seconds: 4.17\n",
      "Epoch  30/100 Batch  800/1562 - Loss:  0.351, Seconds: 3.37\n",
      "Epoch  30/100 Batch  820/1562 - Loss:  0.323, Seconds: 3.83\n",
      "Epoch  30/100 Batch  840/1562 - Loss:  0.360, Seconds: 3.57\n",
      "Epoch  30/100 Batch  860/1562 - Loss:  0.334, Seconds: 3.61\n",
      "Epoch  30/100 Batch  880/1562 - Loss:  0.274, Seconds: 3.24\n",
      "Epoch  30/100 Batch  900/1562 - Loss:  0.338, Seconds: 4.03\n",
      "Epoch  30/100 Batch  920/1562 - Loss:  0.354, Seconds: 3.36\n",
      "Average loss for this update: 0.336-- No Improvement.\n",
      "Epoch  30/100 Batch  940/1562 - Loss:  0.285, Seconds: 3.20\n",
      "Epoch  30/100 Batch  960/1562 - Loss:  0.302, Seconds: 3.85\n",
      "Epoch  30/100 Batch  980/1562 - Loss:  0.324, Seconds: 3.85\n",
      "Epoch  30/100 Batch 1000/1562 - Loss:  0.343, Seconds: 3.66\n",
      "Epoch  30/100 Batch 1020/1562 - Loss:  0.357, Seconds: 3.18\n",
      "Epoch  30/100 Batch 1040/1562 - Loss:  0.363, Seconds: 3.70\n",
      "Epoch  30/100 Batch 1060/1562 - Loss:  0.341, Seconds: 3.45\n",
      "Epoch  30/100 Batch 1080/1562 - Loss:  0.346, Seconds: 4.32\n",
      "Epoch  30/100 Batch 1100/1562 - Loss:  0.385, Seconds: 3.20\n",
      "Epoch  30/100 Batch 1120/1562 - Loss:  0.347, Seconds: 3.68\n",
      "Epoch  30/100 Batch 1140/1562 - Loss:  0.321, Seconds: 3.62\n",
      "Epoch  30/100 Batch 1160/1562 - Loss:  0.308, Seconds: 3.44\n",
      "Epoch  30/100 Batch 1180/1562 - Loss:  0.302, Seconds: 3.06\n",
      "Epoch  30/100 Batch 1200/1562 - Loss:  0.363, Seconds: 4.07\n",
      "Epoch  30/100 Batch 1220/1562 - Loss:  0.321, Seconds: 3.48\n",
      "Epoch  30/100 Batch 1240/1562 - Loss:  0.264, Seconds: 3.70\n",
      "Average loss for this update: 0.332-- No Improvement.\n",
      "Epoch  30/100 Batch 1260/1562 - Loss:  0.361, Seconds: 3.50\n",
      "Epoch  30/100 Batch 1280/1562 - Loss:  0.351, Seconds: 3.92\n",
      "Epoch  30/100 Batch 1300/1562 - Loss:  0.366, Seconds: 3.32\n",
      "Epoch  30/100 Batch 1320/1562 - Loss:  0.375, Seconds: 3.92\n",
      "Epoch  30/100 Batch 1340/1562 - Loss:  0.331, Seconds: 3.46\n",
      "Epoch  30/100 Batch 1360/1562 - Loss:  0.344, Seconds: 3.64\n",
      "Epoch  30/100 Batch 1380/1562 - Loss:  0.355, Seconds: 3.88\n",
      "Epoch  30/100 Batch 1400/1562 - Loss:  0.334, Seconds: 4.00\n",
      "Epoch  30/100 Batch 1420/1562 - Loss:  0.262, Seconds: 3.36\n",
      "Epoch  30/100 Batch 1440/1562 - Loss:  0.315, Seconds: 3.69\n",
      "Epoch  30/100 Batch 1460/1562 - Loss:  0.320, Seconds: 3.94\n",
      "Epoch  30/100 Batch 1480/1562 - Loss:  0.315, Seconds: 3.97\n",
      "Epoch  30/100 Batch 1500/1562 - Loss:  0.328, Seconds: 3.75\n",
      "Epoch  30/100 Batch 1520/1562 - Loss:  0.422, Seconds: 4.43\n",
      "Epoch  30/100 Batch 1540/1562 - Loss:  0.480, Seconds: 3.75\n",
      "Average loss for this update: 0.356-- No Improvement.\n",
      "Epoch  30/100 Batch 1560/1562 - Loss:  0.463, Seconds: 3.96\n",
      "Epoch  31/100 Batch   20/1562 - Loss:  0.447, Seconds: 3.87\n",
      "Epoch  31/100 Batch   40/1562 - Loss:  0.395, Seconds: 3.49\n",
      "Epoch  31/100 Batch   60/1562 - Loss:  0.469, Seconds: 3.05\n",
      "Epoch  31/100 Batch   80/1562 - Loss:  0.377, Seconds: 2.81\n",
      "Epoch  31/100 Batch  100/1562 - Loss:  0.337, Seconds: 3.48\n",
      "Epoch  31/100 Batch  120/1562 - Loss:  0.340, Seconds: 3.11\n",
      "Epoch  31/100 Batch  140/1562 - Loss:  0.360, Seconds: 3.36\n",
      "Epoch  31/100 Batch  160/1562 - Loss:  0.339, Seconds: 2.89\n",
      "Epoch  31/100 Batch  180/1562 - Loss:  0.365, Seconds: 3.68\n",
      "Epoch  31/100 Batch  200/1562 - Loss:  0.322, Seconds: 3.09\n",
      "Epoch  31/100 Batch  220/1562 - Loss:  0.342, Seconds: 3.08\n",
      "Epoch  31/100 Batch  240/1562 - Loss:  0.313, Seconds: 2.86\n",
      "Epoch  31/100 Batch  260/1562 - Loss:  0.363, Seconds: 4.15\n",
      "Epoch  31/100 Batch  280/1562 - Loss:  0.320, Seconds: 3.27\n",
      "Epoch  31/100 Batch  300/1562 - Loss:  0.281, Seconds: 4.09\n",
      "Average loss for this update: 0.355-- No Improvement.\n",
      "Epoch  31/100 Batch  320/1562 - Loss:  0.304, Seconds: 3.51\n",
      "Epoch  31/100 Batch  340/1562 - Loss:  0.319, Seconds: 3.34\n",
      "Epoch  31/100 Batch  360/1562 - Loss:  0.338, Seconds: 3.95\n",
      "Epoch  31/100 Batch  380/1562 - Loss:  0.287, Seconds: 2.97\n",
      "Epoch  31/100 Batch  400/1562 - Loss:  0.311, Seconds: 4.08\n",
      "Epoch  31/100 Batch  420/1562 - Loss:  0.338, Seconds: 3.58\n",
      "Epoch  31/100 Batch  440/1562 - Loss:  0.352, Seconds: 3.37\n",
      "Epoch  31/100 Batch  460/1562 - Loss:  0.337, Seconds: 3.11\n",
      "Epoch  31/100 Batch  480/1562 - Loss:  0.298, Seconds: 3.52\n",
      "Epoch  31/100 Batch  500/1562 - Loss:  0.354, Seconds: 3.78\n",
      "Epoch  31/100 Batch  520/1562 - Loss:  0.299, Seconds: 4.16\n",
      "Epoch  31/100 Batch  540/1562 - Loss:  0.335, Seconds: 3.18\n",
      "Epoch  31/100 Batch  560/1562 - Loss:  0.322, Seconds: 3.54\n",
      "Epoch  31/100 Batch  580/1562 - Loss:  0.272, Seconds: 3.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  31/100 Batch  600/1562 - Loss:  0.254, Seconds: 3.38\n",
      "Epoch  31/100 Batch  620/1562 - Loss:  0.286, Seconds: 3.75\n",
      "Average loss for this update: 0.313 -- New Record!\n",
      "Epoch  31/100 Batch  640/1562 - Loss:  0.337, Seconds: 3.42\n",
      "Epoch  31/100 Batch  660/1562 - Loss:  0.319, Seconds: 3.50\n",
      "Epoch  31/100 Batch  680/1562 - Loss:  0.269, Seconds: 4.20\n",
      "Epoch  31/100 Batch  700/1562 - Loss:  0.314, Seconds: 3.18\n",
      "Epoch  31/100 Batch  720/1562 - Loss:  0.347, Seconds: 4.02\n",
      "Epoch  31/100 Batch  740/1562 - Loss:  0.348, Seconds: 3.86\n",
      "Epoch  31/100 Batch  760/1562 - Loss:  0.338, Seconds: 2.99\n",
      "Epoch  31/100 Batch  780/1562 - Loss:  0.334, Seconds: 4.21\n",
      "Epoch  31/100 Batch  800/1562 - Loss:  0.338, Seconds: 3.46\n",
      "Epoch  31/100 Batch  820/1562 - Loss:  0.315, Seconds: 3.76\n",
      "Epoch  31/100 Batch  840/1562 - Loss:  0.331, Seconds: 3.55\n",
      "Epoch  31/100 Batch  860/1562 - Loss:  0.314, Seconds: 3.57\n",
      "Epoch  31/100 Batch  880/1562 - Loss:  0.268, Seconds: 3.25\n",
      "Epoch  31/100 Batch  900/1562 - Loss:  0.311, Seconds: 4.01\n",
      "Epoch  31/100 Batch  920/1562 - Loss:  0.323, Seconds: 3.37\n",
      "Average loss for this update: 0.319-- No Improvement.\n",
      "Epoch  31/100 Batch  940/1562 - Loss:  0.278, Seconds: 3.17\n",
      "Epoch  31/100 Batch  960/1562 - Loss:  0.301, Seconds: 3.83\n",
      "Epoch  31/100 Batch  980/1562 - Loss:  0.307, Seconds: 3.82\n",
      "Epoch  31/100 Batch 1000/1562 - Loss:  0.337, Seconds: 3.67\n",
      "Epoch  31/100 Batch 1020/1562 - Loss:  0.323, Seconds: 3.20\n",
      "Epoch  31/100 Batch 1040/1562 - Loss:  0.347, Seconds: 3.58\n",
      "Epoch  31/100 Batch 1060/1562 - Loss:  0.330, Seconds: 3.38\n",
      "Epoch  31/100 Batch 1080/1562 - Loss:  0.318, Seconds: 4.22\n",
      "Epoch  31/100 Batch 1100/1562 - Loss:  0.366, Seconds: 3.19\n",
      "Epoch  31/100 Batch 1120/1562 - Loss:  0.349, Seconds: 3.54\n",
      "Epoch  31/100 Batch 1140/1562 - Loss:  0.317, Seconds: 3.59\n",
      "Epoch  31/100 Batch 1160/1562 - Loss:  0.306, Seconds: 3.37\n",
      "Epoch  31/100 Batch 1180/1562 - Loss:  0.299, Seconds: 3.09\n",
      "Epoch  31/100 Batch 1200/1562 - Loss:  0.362, Seconds: 4.01\n",
      "Epoch  31/100 Batch 1220/1562 - Loss:  0.327, Seconds: 3.44\n",
      "Epoch  31/100 Batch 1240/1562 - Loss:  0.255, Seconds: 3.61\n",
      "Average loss for this update: 0.323-- No Improvement.\n",
      "Epoch  31/100 Batch 1260/1562 - Loss:  0.356, Seconds: 3.45\n",
      "Epoch  31/100 Batch 1280/1562 - Loss:  0.341, Seconds: 4.05\n",
      "Epoch  31/100 Batch 1300/1562 - Loss:  0.331, Seconds: 3.25\n",
      "Epoch  31/100 Batch 1320/1562 - Loss:  0.359, Seconds: 3.88\n",
      "Epoch  31/100 Batch 1340/1562 - Loss:  0.316, Seconds: 3.51\n",
      "Epoch  31/100 Batch 1360/1562 - Loss:  0.342, Seconds: 3.70\n",
      "Epoch  31/100 Batch 1380/1562 - Loss:  0.355, Seconds: 3.89\n",
      "Epoch  31/100 Batch 1400/1562 - Loss:  0.301, Seconds: 3.90\n",
      "Epoch  31/100 Batch 1420/1562 - Loss:  0.249, Seconds: 3.19\n",
      "Epoch  31/100 Batch 1440/1562 - Loss:  0.290, Seconds: 3.71\n",
      "Epoch  31/100 Batch 1460/1562 - Loss:  0.307, Seconds: 3.95\n",
      "Epoch  31/100 Batch 1480/1562 - Loss:  0.307, Seconds: 3.91\n",
      "Epoch  31/100 Batch 1500/1562 - Loss:  0.327, Seconds: 3.70\n",
      "Epoch  31/100 Batch 1520/1562 - Loss:  0.387, Seconds: 4.43\n",
      "Epoch  31/100 Batch 1540/1562 - Loss:  0.466, Seconds: 3.70\n",
      "Average loss for this update: 0.34-- No Improvement.\n",
      "Epoch  31/100 Batch 1560/1562 - Loss:  0.452, Seconds: 3.94\n",
      "Epoch  32/100 Batch   20/1562 - Loss:  0.421, Seconds: 3.84\n",
      "Epoch  32/100 Batch   40/1562 - Loss:  0.364, Seconds: 3.48\n",
      "Epoch  32/100 Batch   60/1562 - Loss:  0.435, Seconds: 3.04\n",
      "Epoch  32/100 Batch   80/1562 - Loss:  0.346, Seconds: 2.83\n",
      "Epoch  32/100 Batch  100/1562 - Loss:  0.327, Seconds: 3.45\n",
      "Epoch  32/100 Batch  120/1562 - Loss:  0.325, Seconds: 3.07\n",
      "Epoch  32/100 Batch  140/1562 - Loss:  0.337, Seconds: 3.27\n",
      "Epoch  32/100 Batch  160/1562 - Loss:  0.333, Seconds: 2.87\n",
      "Epoch  32/100 Batch  180/1562 - Loss:  0.339, Seconds: 3.74\n",
      "Epoch  32/100 Batch  200/1562 - Loss:  0.280, Seconds: 3.09\n",
      "Epoch  32/100 Batch  220/1562 - Loss:  0.312, Seconds: 3.08\n",
      "Epoch  32/100 Batch  240/1562 - Loss:  0.298, Seconds: 2.91\n",
      "Epoch  32/100 Batch  260/1562 - Loss:  0.324, Seconds: 4.10\n",
      "Epoch  32/100 Batch  280/1562 - Loss:  0.298, Seconds: 3.33\n",
      "Epoch  32/100 Batch  300/1562 - Loss:  0.284, Seconds: 4.13\n",
      "Average loss for this update: 0.332-- No Improvement.\n",
      "Epoch  32/100 Batch  320/1562 - Loss:  0.286, Seconds: 3.48\n",
      "Epoch  32/100 Batch  340/1562 - Loss:  0.308, Seconds: 3.27\n",
      "Epoch  32/100 Batch  360/1562 - Loss:  0.313, Seconds: 3.85\n",
      "Epoch  32/100 Batch  380/1562 - Loss:  0.275, Seconds: 2.88\n",
      "Epoch  32/100 Batch  400/1562 - Loss:  0.300, Seconds: 4.13\n",
      "Epoch  32/100 Batch  420/1562 - Loss:  0.325, Seconds: 3.54\n",
      "Epoch  32/100 Batch  440/1562 - Loss:  0.328, Seconds: 3.36\n",
      "Epoch  32/100 Batch  460/1562 - Loss:  0.336, Seconds: 3.20\n",
      "Epoch  32/100 Batch  480/1562 - Loss:  0.272, Seconds: 3.54\n",
      "Epoch  32/100 Batch  500/1562 - Loss:  0.328, Seconds: 3.78\n",
      "Epoch  32/100 Batch  520/1562 - Loss:  0.275, Seconds: 4.15\n",
      "Epoch  32/100 Batch  540/1562 - Loss:  0.313, Seconds: 3.19\n",
      "Epoch  32/100 Batch  560/1562 - Loss:  0.290, Seconds: 3.53\n",
      "Epoch  32/100 Batch  580/1562 - Loss:  0.270, Seconds: 3.69\n",
      "Epoch  32/100 Batch  600/1562 - Loss:  0.248, Seconds: 3.35\n",
      "Epoch  32/100 Batch  620/1562 - Loss:  0.290, Seconds: 3.79\n",
      "Average loss for this update: 0.298 -- New Record!\n",
      "Epoch  32/100 Batch  640/1562 - Loss:  0.321, Seconds: 3.34\n",
      "Epoch  32/100 Batch  660/1562 - Loss:  0.300, Seconds: 3.59\n",
      "Epoch  32/100 Batch  680/1562 - Loss:  0.274, Seconds: 4.16\n",
      "Epoch  32/100 Batch  700/1562 - Loss:  0.298, Seconds: 3.19\n",
      "Epoch  32/100 Batch  720/1562 - Loss:  0.326, Seconds: 4.01\n",
      "Epoch  32/100 Batch  740/1562 - Loss:  0.334, Seconds: 3.89\n",
      "Epoch  32/100 Batch  760/1562 - Loss:  0.335, Seconds: 2.99\n",
      "Epoch  32/100 Batch  780/1562 - Loss:  0.318, Seconds: 4.23\n",
      "Epoch  32/100 Batch  800/1562 - Loss:  0.316, Seconds: 3.41\n",
      "Epoch  32/100 Batch  820/1562 - Loss:  0.300, Seconds: 3.79\n",
      "Epoch  32/100 Batch  840/1562 - Loss:  0.338, Seconds: 3.60\n",
      "Epoch  32/100 Batch  860/1562 - Loss:  0.289, Seconds: 3.60\n",
      "Epoch  32/100 Batch  880/1562 - Loss:  0.256, Seconds: 3.16\n",
      "Epoch  32/100 Batch  900/1562 - Loss:  0.299, Seconds: 3.94\n",
      "Epoch  32/100 Batch  920/1562 - Loss:  0.302, Seconds: 3.44\n",
      "Average loss for this update: 0.306-- No Improvement.\n",
      "Epoch  32/100 Batch  940/1562 - Loss:  0.264, Seconds: 3.39\n",
      "Epoch  32/100 Batch  960/1562 - Loss:  0.293, Seconds: 3.84\n",
      "Epoch  32/100 Batch  980/1562 - Loss:  0.302, Seconds: 3.86\n",
      "Epoch  32/100 Batch 1000/1562 - Loss:  0.323, Seconds: 3.66\n",
      "Epoch  32/100 Batch 1020/1562 - Loss:  0.324, Seconds: 3.25\n",
      "Epoch  32/100 Batch 1040/1562 - Loss:  0.318, Seconds: 3.61\n",
      "Epoch  32/100 Batch 1060/1562 - Loss:  0.315, Seconds: 3.45\n",
      "Epoch  32/100 Batch 1080/1562 - Loss:  0.310, Seconds: 4.29\n",
      "Epoch  32/100 Batch 1100/1562 - Loss:  0.335, Seconds: 3.25\n",
      "Epoch  32/100 Batch 1120/1562 - Loss:  0.328, Seconds: 3.65\n",
      "Epoch  32/100 Batch 1140/1562 - Loss:  0.293, Seconds: 3.70\n",
      "Epoch  32/100 Batch 1160/1562 - Loss:  0.271, Seconds: 3.45\n",
      "Epoch  32/100 Batch 1180/1562 - Loss:  0.292, Seconds: 3.00\n",
      "Epoch  32/100 Batch 1200/1562 - Loss:  0.345, Seconds: 4.10\n",
      "Epoch  32/100 Batch 1220/1562 - Loss:  0.283, Seconds: 3.44\n",
      "Epoch  32/100 Batch 1240/1562 - Loss:  0.242, Seconds: 3.65\n",
      "Average loss for this update: 0.304-- No Improvement.\n",
      "Epoch  32/100 Batch 1260/1562 - Loss:  0.319, Seconds: 3.44\n",
      "Epoch  32/100 Batch 1280/1562 - Loss:  0.317, Seconds: 3.93\n",
      "Epoch  32/100 Batch 1300/1562 - Loss:  0.329, Seconds: 3.25\n",
      "Epoch  32/100 Batch 1320/1562 - Loss:  0.333, Seconds: 4.32\n",
      "Epoch  32/100 Batch 1340/1562 - Loss:  0.311, Seconds: 3.51\n",
      "Epoch  32/100 Batch 1360/1562 - Loss:  0.316, Seconds: 3.71\n",
      "Epoch  32/100 Batch 1380/1562 - Loss:  0.331, Seconds: 3.91\n",
      "Epoch  32/100 Batch 1400/1562 - Loss:  0.297, Seconds: 3.88\n",
      "Epoch  32/100 Batch 1420/1562 - Loss:  0.249, Seconds: 3.27\n",
      "Epoch  32/100 Batch 1440/1562 - Loss:  0.277, Seconds: 3.62\n",
      "Epoch  32/100 Batch 1460/1562 - Loss:  0.293, Seconds: 3.95\n",
      "Epoch  32/100 Batch 1480/1562 - Loss:  0.307, Seconds: 3.84\n",
      "Epoch  32/100 Batch 1500/1562 - Loss:  0.299, Seconds: 3.65\n",
      "Epoch  32/100 Batch 1520/1562 - Loss:  0.360, Seconds: 4.37\n",
      "Epoch  32/100 Batch 1540/1562 - Loss:  0.445, Seconds: 3.71\n",
      "Average loss for this update: 0.323-- No Improvement.\n",
      "Epoch  32/100 Batch 1560/1562 - Loss:  0.415, Seconds: 3.96\n",
      "Epoch  33/100 Batch   20/1562 - Loss:  0.417, Seconds: 3.84\n",
      "Epoch  33/100 Batch   40/1562 - Loss:  0.363, Seconds: 3.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  33/100 Batch   60/1562 - Loss:  0.417, Seconds: 3.01\n",
      "Epoch  33/100 Batch   80/1562 - Loss:  0.353, Seconds: 2.81\n",
      "Epoch  33/100 Batch  100/1562 - Loss:  0.318, Seconds: 3.52\n",
      "Epoch  33/100 Batch  120/1562 - Loss:  0.314, Seconds: 3.14\n",
      "Epoch  33/100 Batch  140/1562 - Loss:  0.331, Seconds: 3.35\n",
      "Epoch  33/100 Batch  160/1562 - Loss:  0.299, Seconds: 2.88\n",
      "Epoch  33/100 Batch  180/1562 - Loss:  0.327, Seconds: 3.68\n",
      "Epoch  33/100 Batch  200/1562 - Loss:  0.278, Seconds: 3.06\n",
      "Epoch  33/100 Batch  220/1562 - Loss:  0.296, Seconds: 3.10\n",
      "Epoch  33/100 Batch  240/1562 - Loss:  0.284, Seconds: 2.90\n",
      "Epoch  33/100 Batch  260/1562 - Loss:  0.323, Seconds: 4.10\n",
      "Epoch  33/100 Batch  280/1562 - Loss:  0.287, Seconds: 3.36\n",
      "Epoch  33/100 Batch  300/1562 - Loss:  0.286, Seconds: 4.15\n",
      "Average loss for this update: 0.324-- No Improvement.\n",
      "Epoch  33/100 Batch  320/1562 - Loss:  0.273, Seconds: 3.58\n",
      "Epoch  33/100 Batch  340/1562 - Loss:  0.296, Seconds: 3.31\n",
      "Epoch  33/100 Batch  360/1562 - Loss:  0.303, Seconds: 3.92\n",
      "Epoch  33/100 Batch  380/1562 - Loss:  0.274, Seconds: 2.86\n",
      "Epoch  33/100 Batch  400/1562 - Loss:  0.279, Seconds: 4.14\n",
      "Epoch  33/100 Batch  420/1562 - Loss:  0.313, Seconds: 3.63\n",
      "Epoch  33/100 Batch  440/1562 - Loss:  0.325, Seconds: 3.33\n",
      "Epoch  33/100 Batch  460/1562 - Loss:  0.321, Seconds: 3.17\n",
      "Epoch  33/100 Batch  480/1562 - Loss:  0.275, Seconds: 3.55\n",
      "Epoch  33/100 Batch  500/1562 - Loss:  0.324, Seconds: 3.82\n",
      "Epoch  33/100 Batch  520/1562 - Loss:  0.278, Seconds: 4.21\n",
      "Epoch  33/100 Batch  540/1562 - Loss:  0.318, Seconds: 3.19\n",
      "Epoch  33/100 Batch  560/1562 - Loss:  0.290, Seconds: 3.55\n",
      "Epoch  33/100 Batch  580/1562 - Loss:  0.255, Seconds: 3.56\n",
      "Epoch  33/100 Batch  600/1562 - Loss:  0.230, Seconds: 3.29\n",
      "Epoch  33/100 Batch  620/1562 - Loss:  0.283, Seconds: 3.79\n",
      "Average loss for this update: 0.291 -- New Record!\n",
      "Epoch  33/100 Batch  640/1562 - Loss:  0.307, Seconds: 3.31\n",
      "Epoch  33/100 Batch  660/1562 - Loss:  0.297, Seconds: 3.57\n",
      "Epoch  33/100 Batch  680/1562 - Loss:  0.245, Seconds: 4.16\n",
      "Epoch  33/100 Batch  700/1562 - Loss:  0.288, Seconds: 3.16\n",
      "Epoch  33/100 Batch  720/1562 - Loss:  0.319, Seconds: 4.00\n",
      "Epoch  33/100 Batch  740/1562 - Loss:  0.322, Seconds: 3.83\n",
      "Epoch  33/100 Batch  760/1562 - Loss:  0.310, Seconds: 2.96\n",
      "Epoch  33/100 Batch  780/1562 - Loss:  0.321, Seconds: 4.21\n",
      "Epoch  33/100 Batch  800/1562 - Loss:  0.309, Seconds: 3.40\n",
      "Epoch  33/100 Batch  820/1562 - Loss:  0.279, Seconds: 3.86\n",
      "Epoch  33/100 Batch  840/1562 - Loss:  0.313, Seconds: 3.58\n",
      "Epoch  33/100 Batch  860/1562 - Loss:  0.289, Seconds: 3.62\n",
      "Epoch  33/100 Batch  880/1562 - Loss:  0.247, Seconds: 3.20\n",
      "Epoch  33/100 Batch  900/1562 - Loss:  0.288, Seconds: 4.08\n",
      "Epoch  33/100 Batch  920/1562 - Loss:  0.304, Seconds: 3.39\n",
      "Average loss for this update: 0.294-- No Improvement.\n",
      "Epoch  33/100 Batch  940/1562 - Loss:  0.242, Seconds: 3.23\n",
      "Epoch  33/100 Batch  960/1562 - Loss:  0.277, Seconds: 3.82\n",
      "Epoch  33/100 Batch  980/1562 - Loss:  0.288, Seconds: 3.87\n",
      "Epoch  33/100 Batch 1000/1562 - Loss:  0.315, Seconds: 3.64\n",
      "Epoch  33/100 Batch 1020/1562 - Loss:  0.310, Seconds: 3.25\n",
      "Epoch  33/100 Batch 1040/1562 - Loss:  0.323, Seconds: 3.72\n",
      "Epoch  33/100 Batch 1060/1562 - Loss:  0.294, Seconds: 3.48\n",
      "Epoch  33/100 Batch 1080/1562 - Loss:  0.305, Seconds: 4.42\n",
      "Epoch  33/100 Batch 1100/1562 - Loss:  0.355, Seconds: 3.29\n",
      "Epoch  33/100 Batch 1120/1562 - Loss:  0.316, Seconds: 3.67\n",
      "Epoch  33/100 Batch 1140/1562 - Loss:  0.285, Seconds: 3.71\n",
      "Epoch  33/100 Batch 1160/1562 - Loss:  0.269, Seconds: 3.46\n",
      "Epoch  33/100 Batch 1180/1562 - Loss:  0.283, Seconds: 3.17\n",
      "Epoch  33/100 Batch 1200/1562 - Loss:  0.326, Seconds: 4.04\n",
      "Epoch  33/100 Batch 1220/1562 - Loss:  0.269, Seconds: 3.48\n",
      "Epoch  33/100 Batch 1240/1562 - Loss:  0.245, Seconds: 3.60\n",
      "Average loss for this update: 0.296-- No Improvement.\n",
      "Epoch  33/100 Batch 1260/1562 - Loss:  0.311, Seconds: 3.56\n",
      "Epoch  33/100 Batch 1280/1562 - Loss:  0.312, Seconds: 3.98\n",
      "Epoch  33/100 Batch 1300/1562 - Loss:  0.312, Seconds: 3.29\n",
      "Epoch  33/100 Batch 1320/1562 - Loss:  0.308, Seconds: 3.85\n",
      "Epoch  33/100 Batch 1340/1562 - Loss:  0.300, Seconds: 3.46\n",
      "Epoch  33/100 Batch 1360/1562 - Loss:  0.299, Seconds: 3.73\n",
      "Epoch  33/100 Batch 1380/1562 - Loss:  0.318, Seconds: 3.91\n",
      "Epoch  33/100 Batch 1400/1562 - Loss:  0.292, Seconds: 3.95\n",
      "Epoch  33/100 Batch 1420/1562 - Loss:  0.249, Seconds: 3.25\n",
      "Epoch  33/100 Batch 1440/1562 - Loss:  0.265, Seconds: 3.66\n",
      "Epoch  33/100 Batch 1460/1562 - Loss:  0.271, Seconds: 3.91\n",
      "Epoch  33/100 Batch 1480/1562 - Loss:  0.275, Seconds: 3.82\n",
      "Epoch  33/100 Batch 1500/1562 - Loss:  0.288, Seconds: 3.71\n",
      "Epoch  33/100 Batch 1520/1562 - Loss:  0.352, Seconds: 4.40\n",
      "Epoch  33/100 Batch 1540/1562 - Loss:  0.423, Seconds: 3.67\n",
      "Average loss for this update: 0.309-- No Improvement.\n",
      "Epoch  33/100 Batch 1560/1562 - Loss:  0.407, Seconds: 3.92\n",
      "Epoch  34/100 Batch   20/1562 - Loss:  0.390, Seconds: 3.85\n",
      "Epoch  34/100 Batch   40/1562 - Loss:  0.344, Seconds: 3.48\n",
      "Epoch  34/100 Batch   60/1562 - Loss:  0.383, Seconds: 3.11\n",
      "Epoch  34/100 Batch   80/1562 - Loss:  0.336, Seconds: 2.91\n",
      "Epoch  34/100 Batch  100/1562 - Loss:  0.298, Seconds: 3.58\n",
      "Epoch  34/100 Batch  120/1562 - Loss:  0.289, Seconds: 3.06\n",
      "Epoch  34/100 Batch  140/1562 - Loss:  0.314, Seconds: 3.33\n",
      "Epoch  34/100 Batch  160/1562 - Loss:  0.296, Seconds: 2.93\n",
      "Epoch  34/100 Batch  180/1562 - Loss:  0.314, Seconds: 3.71\n",
      "Epoch  34/100 Batch  200/1562 - Loss:  0.276, Seconds: 3.13\n",
      "Epoch  34/100 Batch  220/1562 - Loss:  0.291, Seconds: 3.15\n",
      "Epoch  34/100 Batch  240/1562 - Loss:  0.280, Seconds: 2.89\n",
      "Epoch  34/100 Batch  260/1562 - Loss:  0.323, Seconds: 4.24\n",
      "Epoch  34/100 Batch  280/1562 - Loss:  0.266, Seconds: 3.31\n",
      "Epoch  34/100 Batch  300/1562 - Loss:  0.267, Seconds: 4.10\n",
      "Average loss for this update: 0.309-- No Improvement.\n",
      "Epoch  34/100 Batch  320/1562 - Loss:  0.277, Seconds: 3.56\n",
      "Epoch  34/100 Batch  340/1562 - Loss:  0.293, Seconds: 3.31\n",
      "Epoch  34/100 Batch  360/1562 - Loss:  0.285, Seconds: 3.95\n",
      "Epoch  34/100 Batch  380/1562 - Loss:  0.261, Seconds: 2.90\n",
      "Epoch  34/100 Batch  400/1562 - Loss:  0.273, Seconds: 4.16\n",
      "Epoch  34/100 Batch  420/1562 - Loss:  0.307, Seconds: 3.58\n",
      "Epoch  34/100 Batch  440/1562 - Loss:  0.300, Seconds: 3.40\n",
      "Epoch  34/100 Batch  460/1562 - Loss:  0.302, Seconds: 3.14\n",
      "Epoch  34/100 Batch  480/1562 - Loss:  0.253, Seconds: 3.59\n",
      "Epoch  34/100 Batch  500/1562 - Loss:  0.304, Seconds: 3.77\n",
      "Epoch  34/100 Batch  520/1562 - Loss:  0.266, Seconds: 4.23\n",
      "Epoch  34/100 Batch  540/1562 - Loss:  0.293, Seconds: 3.20\n",
      "Epoch  34/100 Batch  560/1562 - Loss:  0.266, Seconds: 3.57\n",
      "Epoch  34/100 Batch  580/1562 - Loss:  0.254, Seconds: 3.53\n",
      "Epoch  34/100 Batch  600/1562 - Loss:  0.215, Seconds: 3.36\n",
      "Epoch  34/100 Batch  620/1562 - Loss:  0.265, Seconds: 3.78\n",
      "Average loss for this update: 0.276 -- New Record!\n",
      "Epoch  34/100 Batch  640/1562 - Loss:  0.305, Seconds: 3.37\n",
      "Epoch  34/100 Batch  660/1562 - Loss:  0.282, Seconds: 3.55\n",
      "Epoch  34/100 Batch  680/1562 - Loss:  0.236, Seconds: 4.15\n",
      "Epoch  34/100 Batch  700/1562 - Loss:  0.271, Seconds: 3.21\n",
      "Epoch  34/100 Batch  720/1562 - Loss:  0.305, Seconds: 3.98\n",
      "Epoch  34/100 Batch  740/1562 - Loss:  0.332, Seconds: 3.82\n",
      "Epoch  34/100 Batch  760/1562 - Loss:  0.300, Seconds: 2.99\n",
      "Epoch  34/100 Batch  780/1562 - Loss:  0.281, Seconds: 4.20\n",
      "Epoch  34/100 Batch  800/1562 - Loss:  0.290, Seconds: 3.34\n",
      "Epoch  34/100 Batch  820/1562 - Loss:  0.261, Seconds: 3.87\n",
      "Epoch  34/100 Batch  840/1562 - Loss:  0.300, Seconds: 3.61\n",
      "Epoch  34/100 Batch  860/1562 - Loss:  0.288, Seconds: 3.66\n",
      "Epoch  34/100 Batch  880/1562 - Loss:  0.221, Seconds: 3.26\n",
      "Epoch  34/100 Batch  900/1562 - Loss:  0.266, Seconds: 4.11\n",
      "Epoch  34/100 Batch  920/1562 - Loss:  0.289, Seconds: 3.41\n",
      "Average loss for this update: 0.28-- No Improvement.\n",
      "Epoch  34/100 Batch  940/1562 - Loss:  0.248, Seconds: 3.21\n",
      "Epoch  34/100 Batch  960/1562 - Loss:  0.267, Seconds: 3.74\n",
      "Epoch  34/100 Batch  980/1562 - Loss:  0.277, Seconds: 3.79\n",
      "Epoch  34/100 Batch 1000/1562 - Loss:  0.299, Seconds: 3.62\n",
      "Epoch  34/100 Batch 1020/1562 - Loss:  0.291, Seconds: 3.24\n",
      "Epoch  34/100 Batch 1040/1562 - Loss:  0.306, Seconds: 3.59\n",
      "Epoch  34/100 Batch 1060/1562 - Loss:  0.284, Seconds: 3.43\n",
      "Epoch  34/100 Batch 1080/1562 - Loss:  0.292, Seconds: 4.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  34/100 Batch 1100/1562 - Loss:  0.314, Seconds: 3.32\n",
      "Epoch  34/100 Batch 1120/1562 - Loss:  0.297, Seconds: 3.60\n",
      "Epoch  34/100 Batch 1140/1562 - Loss:  0.268, Seconds: 3.68\n",
      "Epoch  34/100 Batch 1160/1562 - Loss:  0.262, Seconds: 3.39\n",
      "Epoch  34/100 Batch 1180/1562 - Loss:  0.261, Seconds: 3.02\n",
      "Epoch  34/100 Batch 1200/1562 - Loss:  0.316, Seconds: 4.07\n",
      "Epoch  34/100 Batch 1220/1562 - Loss:  0.279, Seconds: 3.54\n",
      "Epoch  34/100 Batch 1240/1562 - Loss:  0.228, Seconds: 3.58\n",
      "Average loss for this update: 0.282-- No Improvement.\n",
      "Epoch  34/100 Batch 1260/1562 - Loss:  0.295, Seconds: 3.49\n",
      "Epoch  34/100 Batch 1280/1562 - Loss:  0.305, Seconds: 3.94\n",
      "Epoch  34/100 Batch 1300/1562 - Loss:  0.300, Seconds: 3.36\n",
      "Epoch  34/100 Batch 1320/1562 - Loss:  0.302, Seconds: 3.84\n",
      "Epoch  34/100 Batch 1340/1562 - Loss:  0.276, Seconds: 3.44\n",
      "Epoch  34/100 Batch 1360/1562 - Loss:  0.299, Seconds: 3.67\n",
      "Epoch  34/100 Batch 1380/1562 - Loss:  0.306, Seconds: 3.84\n",
      "Epoch  34/100 Batch 1400/1562 - Loss:  0.287, Seconds: 3.92\n",
      "Epoch  34/100 Batch 1420/1562 - Loss:  0.238, Seconds: 3.29\n",
      "Epoch  34/100 Batch 1440/1562 - Loss:  0.262, Seconds: 3.74\n",
      "Epoch  34/100 Batch 1460/1562 - Loss:  0.267, Seconds: 3.95\n",
      "Epoch  34/100 Batch 1480/1562 - Loss:  0.264, Seconds: 3.98\n",
      "Epoch  34/100 Batch 1500/1562 - Loss:  0.272, Seconds: 3.73\n",
      "Epoch  34/100 Batch 1520/1562 - Loss:  0.324, Seconds: 4.36\n",
      "Epoch  34/100 Batch 1540/1562 - Loss:  0.395, Seconds: 3.70\n",
      "Average loss for this update: 0.297-- No Improvement.\n",
      "Epoch  34/100 Batch 1560/1562 - Loss:  0.394, Seconds: 3.98\n",
      "Epoch  35/100 Batch   20/1562 - Loss:  0.359, Seconds: 3.94\n",
      "Epoch  35/100 Batch   40/1562 - Loss:  0.327, Seconds: 3.52\n",
      "Epoch  35/100 Batch   60/1562 - Loss:  0.396, Seconds: 2.99\n",
      "Epoch  35/100 Batch   80/1562 - Loss:  0.312, Seconds: 2.89\n",
      "Epoch  35/100 Batch  100/1562 - Loss:  0.284, Seconds: 3.47\n",
      "Epoch  35/100 Batch  120/1562 - Loss:  0.292, Seconds: 3.09\n",
      "Epoch  35/100 Batch  140/1562 - Loss:  0.292, Seconds: 3.31\n",
      "Epoch  35/100 Batch  160/1562 - Loss:  0.272, Seconds: 2.95\n",
      "Epoch  35/100 Batch  180/1562 - Loss:  0.293, Seconds: 3.67\n",
      "Epoch  35/100 Batch  200/1562 - Loss:  0.251, Seconds: 3.13\n",
      "Epoch  35/100 Batch  220/1562 - Loss:  0.284, Seconds: 3.08\n",
      "Epoch  35/100 Batch  240/1562 - Loss:  0.256, Seconds: 2.93\n",
      "Epoch  35/100 Batch  260/1562 - Loss:  0.303, Seconds: 4.08\n",
      "Epoch  35/100 Batch  280/1562 - Loss:  0.266, Seconds: 3.32\n",
      "Epoch  35/100 Batch  300/1562 - Loss:  0.241, Seconds: 4.15\n",
      "Average loss for this update: 0.293-- No Improvement.\n",
      "Epoch  35/100 Batch  320/1562 - Loss:  0.255, Seconds: 3.60\n",
      "Epoch  35/100 Batch  340/1562 - Loss:  0.267, Seconds: 3.27\n",
      "Epoch  35/100 Batch  360/1562 - Loss:  0.279, Seconds: 3.94\n",
      "Epoch  35/100 Batch  380/1562 - Loss:  0.247, Seconds: 2.96\n",
      "Epoch  35/100 Batch  400/1562 - Loss:  0.264, Seconds: 4.14\n",
      "Epoch  35/100 Batch  420/1562 - Loss:  0.287, Seconds: 3.59\n",
      "Epoch  35/100 Batch  440/1562 - Loss:  0.296, Seconds: 3.38\n",
      "Epoch  35/100 Batch  460/1562 - Loss:  0.283, Seconds: 3.17\n",
      "Epoch  35/100 Batch  480/1562 - Loss:  0.250, Seconds: 3.59\n",
      "Epoch  35/100 Batch  500/1562 - Loss:  0.297, Seconds: 3.81\n",
      "Epoch  35/100 Batch  520/1562 - Loss:  0.255, Seconds: 4.16\n",
      "Epoch  35/100 Batch  540/1562 - Loss:  0.274, Seconds: 3.18\n",
      "Epoch  35/100 Batch  560/1562 - Loss:  0.266, Seconds: 3.60\n",
      "Epoch  35/100 Batch  580/1562 - Loss:  0.241, Seconds: 3.54\n",
      "Epoch  35/100 Batch  600/1562 - Loss:  0.223, Seconds: 3.35\n",
      "Epoch  35/100 Batch  620/1562 - Loss:  0.257, Seconds: 3.69\n",
      "Average loss for this update: 0.266 -- New Record!\n",
      "Epoch  35/100 Batch  640/1562 - Loss:  0.282, Seconds: 3.35\n",
      "Epoch  35/100 Batch  660/1562 - Loss:  0.253, Seconds: 3.77\n",
      "Epoch  35/100 Batch  680/1562 - Loss:  0.225, Seconds: 4.21\n",
      "Epoch  35/100 Batch  700/1562 - Loss:  0.264, Seconds: 3.17\n",
      "Epoch  35/100 Batch  720/1562 - Loss:  0.277, Seconds: 4.01\n",
      "Epoch  35/100 Batch  740/1562 - Loss:  0.287, Seconds: 3.84\n",
      "Epoch  35/100 Batch  760/1562 - Loss:  0.299, Seconds: 3.10\n",
      "Epoch  35/100 Batch  780/1562 - Loss:  0.285, Seconds: 4.26\n",
      "Epoch  35/100 Batch  800/1562 - Loss:  0.277, Seconds: 3.48\n",
      "Epoch  35/100 Batch  820/1562 - Loss:  0.257, Seconds: 3.82\n",
      "Epoch  35/100 Batch  840/1562 - Loss:  0.286, Seconds: 3.59\n",
      "Epoch  35/100 Batch  860/1562 - Loss:  0.262, Seconds: 3.53\n",
      "Epoch  35/100 Batch  880/1562 - Loss:  0.231, Seconds: 3.27\n",
      "Epoch  35/100 Batch  900/1562 - Loss:  0.269, Seconds: 4.03\n",
      "Epoch  35/100 Batch  920/1562 - Loss:  0.278, Seconds: 3.44\n",
      "Average loss for this update: 0.268-- No Improvement.\n",
      "Epoch  35/100 Batch  940/1562 - Loss:  0.239, Seconds: 3.17\n",
      "Epoch  35/100 Batch  960/1562 - Loss:  0.269, Seconds: 3.80\n",
      "Epoch  35/100 Batch  980/1562 - Loss:  0.267, Seconds: 3.89\n",
      "Epoch  35/100 Batch 1000/1562 - Loss:  0.277, Seconds: 3.66\n",
      "Epoch  35/100 Batch 1020/1562 - Loss:  0.281, Seconds: 3.24\n",
      "Epoch  35/100 Batch 1040/1562 - Loss:  0.286, Seconds: 3.63\n",
      "Epoch  35/100 Batch 1060/1562 - Loss:  0.269, Seconds: 3.45\n",
      "Epoch  35/100 Batch 1080/1562 - Loss:  0.290, Seconds: 4.34\n",
      "Epoch  35/100 Batch 1100/1562 - Loss:  0.315, Seconds: 3.25\n",
      "Epoch  35/100 Batch 1120/1562 - Loss:  0.297, Seconds: 3.65\n",
      "Epoch  35/100 Batch 1140/1562 - Loss:  0.263, Seconds: 3.65\n",
      "Epoch  35/100 Batch 1160/1562 - Loss:  0.250, Seconds: 3.55\n",
      "Epoch  35/100 Batch 1180/1562 - Loss:  0.256, Seconds: 3.06\n",
      "Epoch  35/100 Batch 1200/1562 - Loss:  0.298, Seconds: 4.11\n",
      "Epoch  35/100 Batch 1220/1562 - Loss:  0.255, Seconds: 3.45\n",
      "Epoch  35/100 Batch 1240/1562 - Loss:  0.212, Seconds: 3.70\n",
      "Average loss for this update: 0.272-- No Improvement.\n",
      "Epoch  35/100 Batch 1260/1562 - Loss:  0.294, Seconds: 3.51\n",
      "Epoch  35/100 Batch 1280/1562 - Loss:  0.281, Seconds: 3.93\n",
      "Epoch  35/100 Batch 1300/1562 - Loss:  0.286, Seconds: 3.28\n",
      "Epoch  35/100 Batch 1320/1562 - Loss:  0.297, Seconds: 3.94\n",
      "Epoch  35/100 Batch 1340/1562 - Loss:  0.263, Seconds: 3.47\n",
      "Epoch  35/100 Batch 1360/1562 - Loss:  0.286, Seconds: 3.74\n",
      "Epoch  35/100 Batch 1380/1562 - Loss:  0.300, Seconds: 3.91\n",
      "Epoch  35/100 Batch 1400/1562 - Loss:  0.260, Seconds: 3.93\n",
      "Epoch  35/100 Batch 1420/1562 - Loss:  0.222, Seconds: 3.34\n",
      "Epoch  35/100 Batch 1440/1562 - Loss:  0.245, Seconds: 3.66\n",
      "Epoch  35/100 Batch 1460/1562 - Loss:  0.258, Seconds: 3.95\n",
      "Epoch  35/100 Batch 1480/1562 - Loss:  0.272, Seconds: 3.87\n",
      "Epoch  35/100 Batch 1500/1562 - Loss:  0.262, Seconds: 3.69\n",
      "Epoch  35/100 Batch 1520/1562 - Loss:  0.318, Seconds: 4.44\n",
      "Epoch  35/100 Batch 1540/1562 - Loss:  0.390, Seconds: 3.74\n",
      "Average loss for this update: 0.286-- No Improvement.\n",
      "Epoch  35/100 Batch 1560/1562 - Loss:  0.380, Seconds: 3.93\n",
      "Epoch  36/100 Batch   20/1562 - Loss:  0.347, Seconds: 3.88\n",
      "Epoch  36/100 Batch   40/1562 - Loss:  0.320, Seconds: 3.51\n",
      "Epoch  36/100 Batch   60/1562 - Loss:  0.373, Seconds: 3.06\n",
      "Epoch  36/100 Batch   80/1562 - Loss:  0.293, Seconds: 2.83\n",
      "Epoch  36/100 Batch  100/1562 - Loss:  0.282, Seconds: 3.49\n",
      "Epoch  36/100 Batch  120/1562 - Loss:  0.269, Seconds: 3.12\n",
      "Epoch  36/100 Batch  140/1562 - Loss:  0.278, Seconds: 3.31\n",
      "Epoch  36/100 Batch  160/1562 - Loss:  0.276, Seconds: 2.94\n",
      "Epoch  36/100 Batch  180/1562 - Loss:  0.276, Seconds: 3.71\n",
      "Epoch  36/100 Batch  200/1562 - Loss:  0.251, Seconds: 3.17\n",
      "Epoch  36/100 Batch  220/1562 - Loss:  0.260, Seconds: 3.13\n",
      "Epoch  36/100 Batch  240/1562 - Loss:  0.249, Seconds: 2.92\n",
      "Epoch  36/100 Batch  260/1562 - Loss:  0.281, Seconds: 4.08\n",
      "Epoch  36/100 Batch  280/1562 - Loss:  0.256, Seconds: 3.33\n",
      "Epoch  36/100 Batch  300/1562 - Loss:  0.230, Seconds: 4.14\n",
      "Average loss for this update: 0.281-- No Improvement.\n",
      "Epoch  36/100 Batch  320/1562 - Loss:  0.246, Seconds: 3.51\n",
      "Epoch  36/100 Batch  340/1562 - Loss:  0.254, Seconds: 3.35\n",
      "Epoch  36/100 Batch  360/1562 - Loss:  0.266, Seconds: 3.96\n",
      "Epoch  36/100 Batch  380/1562 - Loss:  0.247, Seconds: 2.97\n",
      "Epoch  36/100 Batch  400/1562 - Loss:  0.253, Seconds: 4.16\n",
      "Epoch  36/100 Batch  420/1562 - Loss:  0.258, Seconds: 3.59\n",
      "Epoch  36/100 Batch  440/1562 - Loss:  0.281, Seconds: 3.29\n",
      "Epoch  36/100 Batch  460/1562 - Loss:  0.276, Seconds: 3.18\n",
      "Epoch  36/100 Batch  480/1562 - Loss:  0.256, Seconds: 3.61\n",
      "Epoch  36/100 Batch  500/1562 - Loss:  0.279, Seconds: 3.81\n",
      "Epoch  36/100 Batch  520/1562 - Loss:  0.241, Seconds: 4.23\n",
      "Epoch  36/100 Batch  540/1562 - Loss:  0.262, Seconds: 3.20\n",
      "Epoch  36/100 Batch  560/1562 - Loss:  0.254, Seconds: 3.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  36/100 Batch  580/1562 - Loss:  0.219, Seconds: 3.53\n",
      "Epoch  36/100 Batch  600/1562 - Loss:  0.204, Seconds: 3.38\n",
      "Epoch  36/100 Batch  620/1562 - Loss:  0.252, Seconds: 3.83\n",
      "Average loss for this update: 0.254 -- New Record!\n",
      "Epoch  36/100 Batch  640/1562 - Loss:  0.273, Seconds: 3.35\n",
      "Epoch  36/100 Batch  660/1562 - Loss:  0.257, Seconds: 3.74\n",
      "Epoch  36/100 Batch  680/1562 - Loss:  0.220, Seconds: 4.19\n",
      "Epoch  36/100 Batch  700/1562 - Loss:  0.247, Seconds: 3.22\n",
      "Epoch  36/100 Batch  720/1562 - Loss:  0.264, Seconds: 4.10\n",
      "Epoch  36/100 Batch  740/1562 - Loss:  0.294, Seconds: 3.85\n",
      "Epoch  36/100 Batch  760/1562 - Loss:  0.271, Seconds: 2.95\n",
      "Epoch  36/100 Batch  780/1562 - Loss:  0.279, Seconds: 4.22\n",
      "Epoch  36/100 Batch  800/1562 - Loss:  0.262, Seconds: 3.40\n",
      "Epoch  36/100 Batch  820/1562 - Loss:  0.253, Seconds: 3.79\n",
      "Epoch  36/100 Batch  840/1562 - Loss:  0.277, Seconds: 3.69\n",
      "Epoch  36/100 Batch  860/1562 - Loss:  0.263, Seconds: 3.63\n",
      "Epoch  36/100 Batch  880/1562 - Loss:  0.206, Seconds: 3.22\n",
      "Epoch  36/100 Batch  900/1562 - Loss:  0.249, Seconds: 4.17\n",
      "Epoch  36/100 Batch  920/1562 - Loss:  0.280, Seconds: 3.54\n",
      "Average loss for this update: 0.258-- No Improvement.\n",
      "Epoch  36/100 Batch  940/1562 - Loss:  0.225, Seconds: 3.22\n",
      "Epoch  36/100 Batch  960/1562 - Loss:  0.242, Seconds: 3.79\n",
      "Epoch  36/100 Batch  980/1562 - Loss:  0.256, Seconds: 3.80\n",
      "Epoch  36/100 Batch 1000/1562 - Loss:  0.263, Seconds: 3.64\n",
      "Epoch  36/100 Batch 1020/1562 - Loss:  0.280, Seconds: 3.19\n",
      "Epoch  36/100 Batch 1040/1562 - Loss:  0.284, Seconds: 3.70\n",
      "Epoch  36/100 Batch 1060/1562 - Loss:  0.261, Seconds: 3.42\n",
      "Epoch  36/100 Batch 1080/1562 - Loss:  0.274, Seconds: 4.25\n",
      "Epoch  36/100 Batch 1100/1562 - Loss:  0.299, Seconds: 3.26\n",
      "Epoch  36/100 Batch 1120/1562 - Loss:  0.288, Seconds: 3.68\n",
      "Epoch  36/100 Batch 1140/1562 - Loss:  0.240, Seconds: 3.56\n",
      "Epoch  36/100 Batch 1160/1562 - Loss:  0.250, Seconds: 3.51\n",
      "Epoch  36/100 Batch 1180/1562 - Loss:  0.240, Seconds: 3.11\n",
      "Epoch  36/100 Batch 1200/1562 - Loss:  0.285, Seconds: 4.08\n",
      "Epoch  36/100 Batch 1220/1562 - Loss:  0.242, Seconds: 3.51\n",
      "Epoch  36/100 Batch 1240/1562 - Loss:  0.216, Seconds: 3.65\n",
      "Average loss for this update: 0.261-- No Improvement.\n",
      "Epoch  36/100 Batch 1260/1562 - Loss:  0.272, Seconds: 3.50\n",
      "Epoch  36/100 Batch 1280/1562 - Loss:  0.279, Seconds: 3.92\n",
      "Epoch  36/100 Batch 1300/1562 - Loss:  0.277, Seconds: 3.30\n",
      "Epoch  36/100 Batch 1320/1562 - Loss:  0.286, Seconds: 3.86\n",
      "Epoch  36/100 Batch 1340/1562 - Loss:  0.258, Seconds: 3.63\n",
      "Epoch  36/100 Batch 1360/1562 - Loss:  0.274, Seconds: 3.67\n",
      "Epoch  36/100 Batch 1380/1562 - Loss:  0.291, Seconds: 3.92\n",
      "Epoch  36/100 Batch 1400/1562 - Loss:  0.252, Seconds: 4.01\n",
      "Epoch  36/100 Batch 1420/1562 - Loss:  0.217, Seconds: 3.27\n",
      "Epoch  36/100 Batch 1440/1562 - Loss:  0.237, Seconds: 3.73\n",
      "Epoch  36/100 Batch 1460/1562 - Loss:  0.239, Seconds: 3.99\n",
      "Epoch  36/100 Batch 1480/1562 - Loss:  0.273, Seconds: 3.98\n",
      "Epoch  36/100 Batch 1500/1562 - Loss:  0.245, Seconds: 3.77\n",
      "Epoch  36/100 Batch 1520/1562 - Loss:  0.313, Seconds: 4.40\n",
      "Epoch  36/100 Batch 1540/1562 - Loss:  0.373, Seconds: 3.78\n",
      "Average loss for this update: 0.277-- No Improvement.\n",
      "Epoch  36/100 Batch 1560/1562 - Loss:  0.364, Seconds: 3.95\n",
      "Epoch  37/100 Batch   20/1562 - Loss:  0.336, Seconds: 3.90\n",
      "Epoch  37/100 Batch   40/1562 - Loss:  0.303, Seconds: 3.44\n",
      "Epoch  37/100 Batch   60/1562 - Loss:  0.337, Seconds: 3.12\n",
      "Epoch  37/100 Batch   80/1562 - Loss:  0.277, Seconds: 2.89\n",
      "Epoch  37/100 Batch  100/1562 - Loss:  0.270, Seconds: 3.43\n",
      "Epoch  37/100 Batch  120/1562 - Loss:  0.260, Seconds: 3.05\n",
      "Epoch  37/100 Batch  140/1562 - Loss:  0.269, Seconds: 3.25\n",
      "Epoch  37/100 Batch  160/1562 - Loss:  0.266, Seconds: 2.89\n",
      "Epoch  37/100 Batch  180/1562 - Loss:  0.277, Seconds: 3.70\n",
      "Epoch  37/100 Batch  200/1562 - Loss:  0.234, Seconds: 3.06\n",
      "Epoch  37/100 Batch  220/1562 - Loss:  0.262, Seconds: 3.13\n",
      "Epoch  37/100 Batch  240/1562 - Loss:  0.250, Seconds: 2.85\n",
      "Epoch  37/100 Batch  260/1562 - Loss:  0.289, Seconds: 4.07\n",
      "Epoch  37/100 Batch  280/1562 - Loss:  0.236, Seconds: 3.33\n",
      "Epoch  37/100 Batch  300/1562 - Loss:  0.235, Seconds: 4.16\n",
      "Average loss for this update: 0.271-- No Improvement.\n",
      "Epoch  37/100 Batch  320/1562 - Loss:  0.236, Seconds: 3.56\n",
      "Epoch  37/100 Batch  340/1562 - Loss:  0.243, Seconds: 3.37\n",
      "Epoch  37/100 Batch  360/1562 - Loss:  0.269, Seconds: 3.94\n",
      "Epoch  37/100 Batch  380/1562 - Loss:  0.241, Seconds: 2.87\n",
      "Epoch  37/100 Batch  400/1562 - Loss:  0.250, Seconds: 4.18\n",
      "Epoch  37/100 Batch  420/1562 - Loss:  0.260, Seconds: 3.51\n",
      "Epoch  37/100 Batch  440/1562 - Loss:  0.262, Seconds: 3.35\n",
      "Epoch  37/100 Batch  460/1562 - Loss:  0.252, Seconds: 3.09\n",
      "Epoch  37/100 Batch  480/1562 - Loss:  0.234, Seconds: 3.53\n",
      "Epoch  37/100 Batch  500/1562 - Loss:  0.285, Seconds: 3.75\n",
      "Epoch  37/100 Batch  520/1562 - Loss:  0.235, Seconds: 4.18\n",
      "Epoch  37/100 Batch  540/1562 - Loss:  0.252, Seconds: 3.20\n",
      "Epoch  37/100 Batch  560/1562 - Loss:  0.239, Seconds: 3.52\n",
      "Epoch  37/100 Batch  580/1562 - Loss:  0.216, Seconds: 3.57\n",
      "Epoch  37/100 Batch  600/1562 - Loss:  0.190, Seconds: 3.37\n",
      "Epoch  37/100 Batch  620/1562 - Loss:  0.233, Seconds: 3.73\n",
      "Average loss for this update: 0.244 -- New Record!\n",
      "Epoch  37/100 Batch  640/1562 - Loss:  0.265, Seconds: 3.36\n",
      "Epoch  37/100 Batch  660/1562 - Loss:  0.240, Seconds: 3.74\n",
      "Epoch  37/100 Batch  680/1562 - Loss:  0.211, Seconds: 4.36\n",
      "Epoch  37/100 Batch  700/1562 - Loss:  0.235, Seconds: 3.26\n",
      "Epoch  37/100 Batch  720/1562 - Loss:  0.256, Seconds: 4.03\n",
      "Epoch  37/100 Batch  740/1562 - Loss:  0.284, Seconds: 3.85\n",
      "Epoch  37/100 Batch  760/1562 - Loss:  0.260, Seconds: 2.96\n",
      "Epoch  37/100 Batch  780/1562 - Loss:  0.265, Seconds: 4.29\n",
      "Epoch  37/100 Batch  800/1562 - Loss:  0.251, Seconds: 3.48\n",
      "Epoch  37/100 Batch  820/1562 - Loss:  0.234, Seconds: 3.78\n",
      "Epoch  37/100 Batch  840/1562 - Loss:  0.250, Seconds: 3.57\n",
      "Epoch  37/100 Batch  860/1562 - Loss:  0.244, Seconds: 3.65\n",
      "Epoch  37/100 Batch  880/1562 - Loss:  0.206, Seconds: 3.35\n",
      "Epoch  37/100 Batch  900/1562 - Loss:  0.234, Seconds: 4.02\n",
      "Epoch  37/100 Batch  920/1562 - Loss:  0.266, Seconds: 3.40\n",
      "Average loss for this update: 0.246-- No Improvement.\n",
      "Epoch  37/100 Batch  940/1562 - Loss:  0.228, Seconds: 3.23\n",
      "Epoch  37/100 Batch  960/1562 - Loss:  0.228, Seconds: 3.88\n",
      "Epoch  37/100 Batch  980/1562 - Loss:  0.254, Seconds: 3.92\n",
      "Epoch  37/100 Batch 1000/1562 - Loss:  0.264, Seconds: 3.63\n",
      "Epoch  37/100 Batch 1020/1562 - Loss:  0.273, Seconds: 3.26\n",
      "Epoch  37/100 Batch 1040/1562 - Loss:  0.273, Seconds: 3.70\n",
      "Epoch  37/100 Batch 1060/1562 - Loss:  0.258, Seconds: 3.47\n",
      "Epoch  37/100 Batch 1080/1562 - Loss:  0.253, Seconds: 4.30\n",
      "Epoch  37/100 Batch 1100/1562 - Loss:  0.283, Seconds: 3.32\n",
      "Epoch  37/100 Batch 1120/1562 - Loss:  0.264, Seconds: 3.68\n",
      "Epoch  37/100 Batch 1140/1562 - Loss:  0.241, Seconds: 3.64\n",
      "Epoch  37/100 Batch 1160/1562 - Loss:  0.234, Seconds: 3.48\n",
      "Epoch  37/100 Batch 1180/1562 - Loss:  0.221, Seconds: 3.09\n",
      "Epoch  37/100 Batch 1200/1562 - Loss:  0.263, Seconds: 4.01\n",
      "Epoch  37/100 Batch 1220/1562 - Loss:  0.230, Seconds: 3.44\n",
      "Epoch  37/100 Batch 1240/1562 - Loss:  0.202, Seconds: 3.65\n",
      "Average loss for this update: 0.249-- No Improvement.\n",
      "Epoch  37/100 Batch 1260/1562 - Loss:  0.250, Seconds: 3.46\n",
      "Epoch  37/100 Batch 1280/1562 - Loss:  0.254, Seconds: 3.96\n",
      "Epoch  37/100 Batch 1300/1562 - Loss:  0.271, Seconds: 3.25\n",
      "Epoch  37/100 Batch 1320/1562 - Loss:  0.270, Seconds: 3.94\n",
      "Epoch  37/100 Batch 1340/1562 - Loss:  0.246, Seconds: 3.49\n",
      "Epoch  37/100 Batch 1360/1562 - Loss:  0.256, Seconds: 3.76\n",
      "Epoch  37/100 Batch 1380/1562 - Loss:  0.271, Seconds: 3.87\n",
      "Epoch  37/100 Batch 1400/1562 - Loss:  0.244, Seconds: 3.90\n",
      "Epoch  37/100 Batch 1420/1562 - Loss:  0.193, Seconds: 3.32\n",
      "Epoch  37/100 Batch 1440/1562 - Loss:  0.226, Seconds: 3.73\n",
      "Epoch  37/100 Batch 1460/1562 - Loss:  0.233, Seconds: 3.94\n",
      "Epoch  37/100 Batch 1480/1562 - Loss:  0.233, Seconds: 3.86\n",
      "Epoch  37/100 Batch 1500/1562 - Loss:  0.261, Seconds: 3.66\n",
      "Epoch  37/100 Batch 1520/1562 - Loss:  0.300, Seconds: 4.35\n",
      "Epoch  37/100 Batch 1540/1562 - Loss:  0.368, Seconds: 3.80\n",
      "Average loss for this update: 0.263-- No Improvement.\n",
      "Epoch  37/100 Batch 1560/1562 - Loss:  0.362, Seconds: 3.91\n",
      "Epoch  38/100 Batch   20/1562 - Loss:  0.320, Seconds: 3.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  38/100 Batch   40/1562 - Loss:  0.294, Seconds: 3.48\n",
      "Epoch  38/100 Batch   60/1562 - Loss:  0.325, Seconds: 3.08\n",
      "Epoch  38/100 Batch   80/1562 - Loss:  0.265, Seconds: 2.85\n",
      "Epoch  38/100 Batch  100/1562 - Loss:  0.248, Seconds: 3.47\n",
      "Epoch  38/100 Batch  120/1562 - Loss:  0.247, Seconds: 3.10\n",
      "Epoch  38/100 Batch  140/1562 - Loss:  0.257, Seconds: 3.26\n",
      "Epoch  38/100 Batch  160/1562 - Loss:  0.248, Seconds: 2.93\n",
      "Epoch  38/100 Batch  180/1562 - Loss:  0.267, Seconds: 3.70\n",
      "Epoch  38/100 Batch  200/1562 - Loss:  0.224, Seconds: 3.07\n",
      "Epoch  38/100 Batch  220/1562 - Loss:  0.251, Seconds: 3.10\n",
      "Epoch  38/100 Batch  240/1562 - Loss:  0.254, Seconds: 2.96\n",
      "Epoch  38/100 Batch  260/1562 - Loss:  0.264, Seconds: 4.17\n",
      "Epoch  38/100 Batch  280/1562 - Loss:  0.227, Seconds: 3.32\n",
      "Epoch  38/100 Batch  300/1562 - Loss:  0.221, Seconds: 4.11\n",
      "Average loss for this update: 0.259-- No Improvement.\n",
      "Epoch  38/100 Batch  320/1562 - Loss:  0.226, Seconds: 3.50\n",
      "Epoch  38/100 Batch  340/1562 - Loss:  0.237, Seconds: 3.33\n",
      "Epoch  38/100 Batch  360/1562 - Loss:  0.247, Seconds: 3.84\n",
      "Epoch  38/100 Batch  380/1562 - Loss:  0.228, Seconds: 2.90\n",
      "Epoch  38/100 Batch  400/1562 - Loss:  0.228, Seconds: 4.12\n",
      "Epoch  38/100 Batch  420/1562 - Loss:  0.229, Seconds: 3.55\n",
      "Epoch  38/100 Batch  440/1562 - Loss:  0.243, Seconds: 3.38\n",
      "Epoch  38/100 Batch  460/1562 - Loss:  0.247, Seconds: 3.07\n",
      "Epoch  38/100 Batch  480/1562 - Loss:  0.230, Seconds: 3.52\n",
      "Epoch  38/100 Batch  500/1562 - Loss:  0.257, Seconds: 3.74\n",
      "Epoch  38/100 Batch  520/1562 - Loss:  0.213, Seconds: 4.16\n",
      "Epoch  38/100 Batch  540/1562 - Loss:  0.239, Seconds: 3.14\n",
      "Epoch  38/100 Batch  560/1562 - Loss:  0.243, Seconds: 3.50\n",
      "Epoch  38/100 Batch  580/1562 - Loss:  0.203, Seconds: 3.57\n",
      "Epoch  38/100 Batch  600/1562 - Loss:  0.193, Seconds: 3.30\n",
      "Epoch  38/100 Batch  620/1562 - Loss:  0.218, Seconds: 3.78\n",
      "Average loss for this update: 0.231 -- New Record!\n",
      "Epoch  38/100 Batch  640/1562 - Loss:  0.263, Seconds: 3.32\n",
      "Epoch  38/100 Batch  660/1562 - Loss:  0.235, Seconds: 3.45\n",
      "Epoch  38/100 Batch  680/1562 - Loss:  0.200, Seconds: 4.14\n",
      "Epoch  38/100 Batch  700/1562 - Loss:  0.242, Seconds: 3.21\n",
      "Epoch  38/100 Batch  720/1562 - Loss:  0.247, Seconds: 3.92\n",
      "Epoch  38/100 Batch  740/1562 - Loss:  0.256, Seconds: 3.97\n",
      "Epoch  38/100 Batch  760/1562 - Loss:  0.253, Seconds: 3.03\n",
      "Epoch  38/100 Batch  780/1562 - Loss:  0.263, Seconds: 4.36\n",
      "Epoch  38/100 Batch  800/1562 - Loss:  0.235, Seconds: 3.38\n",
      "Epoch  38/100 Batch  820/1562 - Loss:  0.238, Seconds: 3.87\n",
      "Epoch  38/100 Batch  840/1562 - Loss:  0.263, Seconds: 3.62\n",
      "Epoch  38/100 Batch  860/1562 - Loss:  0.236, Seconds: 3.65\n",
      "Epoch  38/100 Batch  880/1562 - Loss:  0.208, Seconds: 3.20\n",
      "Epoch  38/100 Batch  900/1562 - Loss:  0.243, Seconds: 3.97\n",
      "Epoch  38/100 Batch  920/1562 - Loss:  0.253, Seconds: 3.46\n",
      "Average loss for this update: 0.241-- No Improvement.\n",
      "Epoch  38/100 Batch  940/1562 - Loss:  0.209, Seconds: 3.23\n",
      "Epoch  38/100 Batch  960/1562 - Loss:  0.226, Seconds: 3.82\n",
      "Epoch  38/100 Batch  980/1562 - Loss:  0.243, Seconds: 3.95\n",
      "Epoch  38/100 Batch 1000/1562 - Loss:  0.265, Seconds: 3.77\n",
      "Epoch  38/100 Batch 1020/1562 - Loss:  0.252, Seconds: 3.23\n",
      "Epoch  38/100 Batch 1040/1562 - Loss:  0.264, Seconds: 3.67\n",
      "Epoch  38/100 Batch 1060/1562 - Loss:  0.249, Seconds: 3.42\n",
      "Epoch  38/100 Batch 1080/1562 - Loss:  0.240, Seconds: 4.28\n",
      "Epoch  38/100 Batch 1100/1562 - Loss:  0.277, Seconds: 3.29\n",
      "Epoch  38/100 Batch 1120/1562 - Loss:  0.261, Seconds: 3.65\n",
      "Epoch  38/100 Batch 1140/1562 - Loss:  0.229, Seconds: 3.75\n",
      "Epoch  38/100 Batch 1160/1562 - Loss:  0.227, Seconds: 3.38\n",
      "Epoch  38/100 Batch 1180/1562 - Loss:  0.232, Seconds: 2.98\n",
      "Epoch  38/100 Batch 1200/1562 - Loss:  0.265, Seconds: 4.03\n",
      "Epoch  38/100 Batch 1220/1562 - Loss:  0.234, Seconds: 3.52\n",
      "Epoch  38/100 Batch 1240/1562 - Loss:  0.189, Seconds: 3.67\n",
      "Average loss for this update: 0.242-- No Improvement.\n",
      "Epoch  38/100 Batch 1260/1562 - Loss:  0.247, Seconds: 3.48\n",
      "Epoch  38/100 Batch 1280/1562 - Loss:  0.256, Seconds: 3.96\n",
      "Epoch  38/100 Batch 1300/1562 - Loss:  0.259, Seconds: 3.35\n",
      "Epoch  38/100 Batch 1320/1562 - Loss:  0.273, Seconds: 3.97\n",
      "Epoch  38/100 Batch 1340/1562 - Loss:  0.233, Seconds: 3.47\n",
      "Epoch  38/100 Batch 1360/1562 - Loss:  0.247, Seconds: 3.75\n",
      "Epoch  38/100 Batch 1380/1562 - Loss:  0.268, Seconds: 3.91\n",
      "Epoch  38/100 Batch 1400/1562 - Loss:  0.239, Seconds: 4.02\n",
      "Epoch  38/100 Batch 1420/1562 - Loss:  0.198, Seconds: 3.19\n",
      "Epoch  38/100 Batch 1440/1562 - Loss:  0.220, Seconds: 3.79\n",
      "Epoch  38/100 Batch 1460/1562 - Loss:  0.226, Seconds: 3.93\n",
      "Epoch  38/100 Batch 1480/1562 - Loss:  0.240, Seconds: 3.90\n",
      "Epoch  38/100 Batch 1500/1562 - Loss:  0.241, Seconds: 3.73\n",
      "Epoch  38/100 Batch 1520/1562 - Loss:  0.294, Seconds: 4.46\n",
      "Epoch  38/100 Batch 1540/1562 - Loss:  0.352, Seconds: 3.74\n",
      "Average loss for this update: 0.256-- No Improvement.\n",
      "Epoch  38/100 Batch 1560/1562 - Loss:  0.324, Seconds: 3.96\n",
      "Epoch  39/100 Batch   20/1562 - Loss:  0.300, Seconds: 3.87\n",
      "Epoch  39/100 Batch   40/1562 - Loss:  0.279, Seconds: 3.45\n",
      "Epoch  39/100 Batch   60/1562 - Loss:  0.322, Seconds: 3.07\n",
      "Epoch  39/100 Batch   80/1562 - Loss:  0.261, Seconds: 2.98\n",
      "Epoch  39/100 Batch  100/1562 - Loss:  0.239, Seconds: 3.47\n",
      "Epoch  39/100 Batch  120/1562 - Loss:  0.236, Seconds: 3.11\n",
      "Epoch  39/100 Batch  140/1562 - Loss:  0.259, Seconds: 3.26\n",
      "Epoch  39/100 Batch  160/1562 - Loss:  0.247, Seconds: 2.92\n",
      "Epoch  39/100 Batch  180/1562 - Loss:  0.250, Seconds: 3.73\n",
      "Epoch  39/100 Batch  200/1562 - Loss:  0.214, Seconds: 3.11\n",
      "Epoch  39/100 Batch  220/1562 - Loss:  0.239, Seconds: 3.07\n",
      "Epoch  39/100 Batch  240/1562 - Loss:  0.219, Seconds: 2.95\n",
      "Epoch  39/100 Batch  260/1562 - Loss:  0.253, Seconds: 4.10\n",
      "Epoch  39/100 Batch  280/1562 - Loss:  0.221, Seconds: 3.42\n",
      "Epoch  39/100 Batch  300/1562 - Loss:  0.206, Seconds: 4.10\n",
      "Average loss for this update: 0.248-- No Improvement.\n",
      "Epoch  39/100 Batch  320/1562 - Loss:  0.201, Seconds: 3.48\n",
      "Epoch  39/100 Batch  340/1562 - Loss:  0.230, Seconds: 3.28\n",
      "Epoch  39/100 Batch  360/1562 - Loss:  0.238, Seconds: 3.85\n",
      "Epoch  39/100 Batch  380/1562 - Loss:  0.211, Seconds: 2.89\n",
      "Epoch  39/100 Batch  400/1562 - Loss:  0.229, Seconds: 4.09\n",
      "Epoch  39/100 Batch  420/1562 - Loss:  0.245, Seconds: 3.73\n",
      "Epoch  39/100 Batch  440/1562 - Loss:  0.249, Seconds: 3.32\n",
      "Epoch  39/100 Batch  460/1562 - Loss:  0.251, Seconds: 3.16\n",
      "Epoch  39/100 Batch  480/1562 - Loss:  0.212, Seconds: 3.55\n",
      "Epoch  39/100 Batch  500/1562 - Loss:  0.236, Seconds: 3.79\n",
      "Epoch  39/100 Batch  520/1562 - Loss:  0.208, Seconds: 4.17\n",
      "Epoch  39/100 Batch  540/1562 - Loss:  0.237, Seconds: 3.15\n",
      "Epoch  39/100 Batch  560/1562 - Loss:  0.230, Seconds: 3.58\n",
      "Epoch  39/100 Batch  580/1562 - Loss:  0.204, Seconds: 3.61\n",
      "Epoch  39/100 Batch  600/1562 - Loss:  0.182, Seconds: 3.37\n",
      "Epoch  39/100 Batch  620/1562 - Loss:  0.217, Seconds: 3.88\n",
      "Average loss for this update: 0.225 -- New Record!\n",
      "Epoch  39/100 Batch  640/1562 - Loss:  0.262, Seconds: 3.31\n",
      "Epoch  39/100 Batch  660/1562 - Loss:  0.222, Seconds: 3.60\n",
      "Epoch  39/100 Batch  680/1562 - Loss:  0.197, Seconds: 4.18\n",
      "Epoch  39/100 Batch  700/1562 - Loss:  0.216, Seconds: 3.14\n",
      "Epoch  39/100 Batch  720/1562 - Loss:  0.251, Seconds: 3.98\n",
      "Epoch  39/100 Batch  740/1562 - Loss:  0.249, Seconds: 3.73\n",
      "Epoch  39/100 Batch  760/1562 - Loss:  0.262, Seconds: 3.02\n",
      "Epoch  39/100 Batch  780/1562 - Loss:  0.244, Seconds: 4.30\n",
      "Epoch  39/100 Batch  800/1562 - Loss:  0.231, Seconds: 3.43\n",
      "Epoch  39/100 Batch  820/1562 - Loss:  0.224, Seconds: 3.93\n",
      "Epoch  39/100 Batch  840/1562 - Loss:  0.235, Seconds: 3.61\n",
      "Epoch  39/100 Batch  860/1562 - Loss:  0.217, Seconds: 3.63\n",
      "Epoch  39/100 Batch  880/1562 - Loss:  0.190, Seconds: 3.14\n",
      "Epoch  39/100 Batch  900/1562 - Loss:  0.216, Seconds: 4.06\n",
      "Epoch  39/100 Batch  920/1562 - Loss:  0.242, Seconds: 3.41\n",
      "Average loss for this update: 0.23-- No Improvement.\n",
      "Epoch  39/100 Batch  940/1562 - Loss:  0.199, Seconds: 3.28\n",
      "Epoch  39/100 Batch  960/1562 - Loss:  0.218, Seconds: 3.85\n",
      "Epoch  39/100 Batch  980/1562 - Loss:  0.230, Seconds: 3.98\n",
      "Epoch  39/100 Batch 1000/1562 - Loss:  0.248, Seconds: 3.62\n",
      "Epoch  39/100 Batch 1020/1562 - Loss:  0.233, Seconds: 3.19\n",
      "Epoch  39/100 Batch 1040/1562 - Loss:  0.246, Seconds: 3.64\n",
      "Epoch  39/100 Batch 1060/1562 - Loss:  0.235, Seconds: 3.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  39/100 Batch 1080/1562 - Loss:  0.245, Seconds: 4.21\n",
      "Epoch  39/100 Batch 1100/1562 - Loss:  0.257, Seconds: 3.27\n",
      "Epoch  39/100 Batch 1120/1562 - Loss:  0.245, Seconds: 3.64\n",
      "Epoch  39/100 Batch 1140/1562 - Loss:  0.228, Seconds: 3.67\n",
      "Epoch  39/100 Batch 1160/1562 - Loss:  0.204, Seconds: 3.58\n",
      "Epoch  39/100 Batch 1180/1562 - Loss:  0.217, Seconds: 3.06\n",
      "Epoch  39/100 Batch 1200/1562 - Loss:  0.251, Seconds: 4.04\n",
      "Epoch  39/100 Batch 1220/1562 - Loss:  0.215, Seconds: 3.43\n",
      "Epoch  39/100 Batch 1240/1562 - Loss:  0.197, Seconds: 3.65\n",
      "Average loss for this update: 0.23-- No Improvement.\n",
      "Epoch  39/100 Batch 1260/1562 - Loss:  0.257, Seconds: 3.43\n",
      "Epoch  39/100 Batch 1280/1562 - Loss:  0.258, Seconds: 3.88\n",
      "Epoch  39/100 Batch 1300/1562 - Loss:  0.245, Seconds: 3.49\n",
      "Epoch  39/100 Batch 1320/1562 - Loss:  0.246, Seconds: 3.99\n",
      "Epoch  39/100 Batch 1340/1562 - Loss:  0.223, Seconds: 3.58\n",
      "Epoch  39/100 Batch 1360/1562 - Loss:  0.233, Seconds: 3.66\n",
      "Epoch  39/100 Batch 1380/1562 - Loss:  0.257, Seconds: 3.90\n",
      "Epoch  39/100 Batch 1400/1562 - Loss:  0.238, Seconds: 3.98\n",
      "Epoch  39/100 Batch 1420/1562 - Loss:  0.183, Seconds: 3.25\n",
      "Epoch  39/100 Batch 1440/1562 - Loss:  0.214, Seconds: 3.69\n",
      "Epoch  39/100 Batch 1460/1562 - Loss:  0.221, Seconds: 3.98\n",
      "Epoch  39/100 Batch 1480/1562 - Loss:  0.223, Seconds: 3.92\n",
      "Epoch  39/100 Batch 1500/1562 - Loss:  0.226, Seconds: 3.71\n",
      "Epoch  39/100 Batch 1520/1562 - Loss:  0.287, Seconds: 4.40\n",
      "Epoch  39/100 Batch 1540/1562 - Loss:  0.337, Seconds: 3.81\n",
      "Average loss for this update: 0.246-- No Improvement.\n",
      "Epoch  39/100 Batch 1560/1562 - Loss:  0.323, Seconds: 3.99\n",
      "Epoch  40/100 Batch   20/1562 - Loss:  0.305, Seconds: 3.86\n",
      "Epoch  40/100 Batch   40/1562 - Loss:  0.258, Seconds: 3.49\n",
      "Epoch  40/100 Batch   60/1562 - Loss:  0.301, Seconds: 3.03\n",
      "Epoch  40/100 Batch   80/1562 - Loss:  0.250, Seconds: 2.89\n",
      "Epoch  40/100 Batch  100/1562 - Loss:  0.238, Seconds: 3.49\n",
      "Epoch  40/100 Batch  120/1562 - Loss:  0.244, Seconds: 3.20\n",
      "Epoch  40/100 Batch  140/1562 - Loss:  0.248, Seconds: 3.29\n",
      "Epoch  40/100 Batch  160/1562 - Loss:  0.224, Seconds: 2.97\n",
      "Epoch  40/100 Batch  180/1562 - Loss:  0.254, Seconds: 3.76\n",
      "Epoch  40/100 Batch  200/1562 - Loss:  0.213, Seconds: 3.27\n",
      "Epoch  40/100 Batch  220/1562 - Loss:  0.244, Seconds: 3.18\n",
      "Epoch  40/100 Batch  240/1562 - Loss:  0.218, Seconds: 2.89\n",
      "Epoch  40/100 Batch  260/1562 - Loss:  0.251, Seconds: 4.18\n",
      "Epoch  40/100 Batch  280/1562 - Loss:  0.213, Seconds: 3.30\n",
      "Epoch  40/100 Batch  300/1562 - Loss:  0.187, Seconds: 4.10\n",
      "Average loss for this update: 0.242-- No Improvement.\n",
      "Epoch  40/100 Batch  320/1562 - Loss:  0.210, Seconds: 3.50\n",
      "Epoch  40/100 Batch  340/1562 - Loss:  0.233, Seconds: 3.32\n",
      "Epoch  40/100 Batch  360/1562 - Loss:  0.229, Seconds: 3.94\n",
      "Epoch  40/100 Batch  380/1562 - Loss:  0.208, Seconds: 2.95\n",
      "Epoch  40/100 Batch  400/1562 - Loss:  0.208, Seconds: 4.18\n",
      "Epoch  40/100 Batch  420/1562 - Loss:  0.234, Seconds: 3.56\n",
      "Epoch  40/100 Batch  440/1562 - Loss:  0.252, Seconds: 3.37\n",
      "Epoch  40/100 Batch  460/1562 - Loss:  0.247, Seconds: 3.17\n",
      "Epoch  40/100 Batch  480/1562 - Loss:  0.201, Seconds: 3.59\n",
      "Epoch  40/100 Batch  500/1562 - Loss:  0.229, Seconds: 3.78\n",
      "Epoch  40/100 Batch  520/1562 - Loss:  0.211, Seconds: 4.19\n",
      "Epoch  40/100 Batch  540/1562 - Loss:  0.231, Seconds: 3.19\n",
      "Epoch  40/100 Batch  560/1562 - Loss:  0.217, Seconds: 3.63\n",
      "Epoch  40/100 Batch  580/1562 - Loss:  0.203, Seconds: 3.63\n",
      "Epoch  40/100 Batch  600/1562 - Loss:  0.178, Seconds: 3.40\n",
      "Epoch  40/100 Batch  620/1562 - Loss:  0.219, Seconds: 3.68\n",
      "Average loss for this update: 0.22 -- New Record!\n",
      "Epoch  40/100 Batch  640/1562 - Loss:  0.248, Seconds: 3.45\n",
      "Epoch  40/100 Batch  660/1562 - Loss:  0.216, Seconds: 3.55\n",
      "Epoch  40/100 Batch  680/1562 - Loss:  0.196, Seconds: 4.19\n",
      "Epoch  40/100 Batch  700/1562 - Loss:  0.213, Seconds: 3.27\n",
      "Epoch  40/100 Batch  720/1562 - Loss:  0.227, Seconds: 4.08\n",
      "Epoch  40/100 Batch  740/1562 - Loss:  0.230, Seconds: 3.85\n",
      "Epoch  40/100 Batch  760/1562 - Loss:  0.256, Seconds: 3.04\n",
      "Epoch  40/100 Batch  780/1562 - Loss:  0.239, Seconds: 4.21\n",
      "Epoch  40/100 Batch  800/1562 - Loss:  0.223, Seconds: 3.38\n",
      "Epoch  40/100 Batch  820/1562 - Loss:  0.211, Seconds: 3.83\n",
      "Epoch  40/100 Batch  840/1562 - Loss:  0.252, Seconds: 3.69\n",
      "Epoch  40/100 Batch  860/1562 - Loss:  0.218, Seconds: 3.57\n",
      "Epoch  40/100 Batch  880/1562 - Loss:  0.179, Seconds: 3.21\n",
      "Epoch  40/100 Batch  900/1562 - Loss:  0.212, Seconds: 4.07\n",
      "Epoch  40/100 Batch  920/1562 - Loss:  0.230, Seconds: 3.43\n",
      "Average loss for this update: 0.221-- No Improvement.\n",
      "Epoch  40/100 Batch  940/1562 - Loss:  0.188, Seconds: 3.20\n",
      "Epoch  40/100 Batch  960/1562 - Loss:  0.207, Seconds: 3.89\n",
      "Epoch  40/100 Batch  980/1562 - Loss:  0.209, Seconds: 3.87\n",
      "Epoch  40/100 Batch 1000/1562 - Loss:  0.243, Seconds: 3.73\n",
      "Epoch  40/100 Batch 1020/1562 - Loss:  0.225, Seconds: 3.27\n",
      "Epoch  40/100 Batch 1040/1562 - Loss:  0.256, Seconds: 3.68\n",
      "Epoch  40/100 Batch 1060/1562 - Loss:  0.228, Seconds: 3.37\n",
      "Epoch  40/100 Batch 1080/1562 - Loss:  0.235, Seconds: 4.29\n",
      "Epoch  40/100 Batch 1100/1562 - Loss:  0.269, Seconds: 3.28\n",
      "Epoch  40/100 Batch 1120/1562 - Loss:  0.244, Seconds: 3.63\n",
      "Epoch  40/100 Batch 1140/1562 - Loss:  0.219, Seconds: 3.63\n",
      "Epoch  40/100 Batch 1160/1562 - Loss:  0.208, Seconds: 3.42\n",
      "Epoch  40/100 Batch 1180/1562 - Loss:  0.214, Seconds: 2.97\n",
      "Epoch  40/100 Batch 1200/1562 - Loss:  0.260, Seconds: 4.05\n",
      "Epoch  40/100 Batch 1220/1562 - Loss:  0.223, Seconds: 3.47\n",
      "Epoch  40/100 Batch 1240/1562 - Loss:  0.173, Seconds: 3.73\n",
      "Average loss for this update: 0.227-- No Improvement.\n",
      "Epoch  40/100 Batch 1260/1562 - Loss:  0.243, Seconds: 3.75\n",
      "Epoch  40/100 Batch 1280/1562 - Loss:  0.239, Seconds: 3.91\n",
      "Epoch  40/100 Batch 1300/1562 - Loss:  0.233, Seconds: 3.26\n",
      "Epoch  40/100 Batch 1320/1562 - Loss:  0.247, Seconds: 3.87\n",
      "Epoch  40/100 Batch 1340/1562 - Loss:  0.213, Seconds: 3.44\n",
      "Epoch  40/100 Batch 1360/1562 - Loss:  0.228, Seconds: 3.75\n",
      "Epoch  40/100 Batch 1380/1562 - Loss:  0.244, Seconds: 3.85\n",
      "Epoch  40/100 Batch 1400/1562 - Loss:  0.212, Seconds: 4.03\n",
      "Epoch  40/100 Batch 1420/1562 - Loss:  0.172, Seconds: 3.27\n",
      "Epoch  40/100 Batch 1440/1562 - Loss:  0.201, Seconds: 3.64\n",
      "Epoch  40/100 Batch 1460/1562 - Loss:  0.202, Seconds: 3.98\n",
      "Epoch  40/100 Batch 1480/1562 - Loss:  0.214, Seconds: 3.95\n",
      "Epoch  40/100 Batch 1500/1562 - Loss:  0.218, Seconds: 3.73\n",
      "Epoch  40/100 Batch 1520/1562 - Loss:  0.272, Seconds: 4.33\n",
      "Epoch  40/100 Batch 1540/1562 - Loss:  0.319, Seconds: 3.78\n",
      "Average loss for this update: 0.233-- No Improvement.\n",
      "Epoch  40/100 Batch 1560/1562 - Loss:  0.306, Seconds: 3.95\n",
      "Epoch  41/100 Batch   20/1562 - Loss:  0.287, Seconds: 3.91\n",
      "Epoch  41/100 Batch   40/1562 - Loss:  0.257, Seconds: 3.46\n",
      "Epoch  41/100 Batch   60/1562 - Loss:  0.296, Seconds: 3.09\n",
      "Epoch  41/100 Batch   80/1562 - Loss:  0.244, Seconds: 2.90\n",
      "Epoch  41/100 Batch  100/1562 - Loss:  0.229, Seconds: 3.47\n",
      "Epoch  41/100 Batch  120/1562 - Loss:  0.228, Seconds: 3.11\n",
      "Epoch  41/100 Batch  140/1562 - Loss:  0.236, Seconds: 3.37\n",
      "Epoch  41/100 Batch  160/1562 - Loss:  0.213, Seconds: 2.90\n",
      "Epoch  41/100 Batch  180/1562 - Loss:  0.246, Seconds: 3.72\n",
      "Epoch  41/100 Batch  200/1562 - Loss:  0.195, Seconds: 3.13\n",
      "Epoch  41/100 Batch  220/1562 - Loss:  0.226, Seconds: 3.15\n",
      "Epoch  41/100 Batch  240/1562 - Loss:  0.213, Seconds: 2.95\n",
      "Epoch  41/100 Batch  260/1562 - Loss:  0.235, Seconds: 4.14\n",
      "Epoch  41/100 Batch  280/1562 - Loss:  0.210, Seconds: 3.33\n",
      "Epoch  41/100 Batch  300/1562 - Loss:  0.190, Seconds: 4.13\n",
      "Average loss for this update: 0.231-- No Improvement.\n",
      "Epoch  41/100 Batch  320/1562 - Loss:  0.185, Seconds: 3.45\n",
      "Epoch  41/100 Batch  340/1562 - Loss:  0.212, Seconds: 3.28\n",
      "Epoch  41/100 Batch  360/1562 - Loss:  0.240, Seconds: 3.94\n",
      "Epoch  41/100 Batch  380/1562 - Loss:  0.204, Seconds: 2.98\n",
      "Epoch  41/100 Batch  400/1562 - Loss:  0.211, Seconds: 4.11\n",
      "Epoch  41/100 Batch  420/1562 - Loss:  0.232, Seconds: 3.52\n",
      "Epoch  41/100 Batch  440/1562 - Loss:  0.246, Seconds: 3.34\n",
      "Epoch  41/100 Batch  460/1562 - Loss:  0.226, Seconds: 3.18\n",
      "Epoch  41/100 Batch  480/1562 - Loss:  0.210, Seconds: 3.59\n",
      "Epoch  41/100 Batch  500/1562 - Loss:  0.234, Seconds: 3.88\n",
      "Epoch  41/100 Batch  520/1562 - Loss:  0.198, Seconds: 4.20\n",
      "Epoch  41/100 Batch  540/1562 - Loss:  0.220, Seconds: 3.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  41/100 Batch  560/1562 - Loss:  0.209, Seconds: 3.68\n",
      "Epoch  41/100 Batch  580/1562 - Loss:  0.199, Seconds: 3.49\n",
      "Epoch  41/100 Batch  600/1562 - Loss:  0.178, Seconds: 3.46\n",
      "Epoch  41/100 Batch  620/1562 - Loss:  0.206, Seconds: 3.77\n",
      "Average loss for this update: 0.214 -- New Record!\n",
      "Epoch  41/100 Batch  640/1562 - Loss:  0.223, Seconds: 3.27\n",
      "Epoch  41/100 Batch  660/1562 - Loss:  0.212, Seconds: 3.57\n",
      "Epoch  41/100 Batch  680/1562 - Loss:  0.190, Seconds: 4.21\n",
      "Epoch  41/100 Batch  700/1562 - Loss:  0.210, Seconds: 3.19\n",
      "Epoch  41/100 Batch  720/1562 - Loss:  0.236, Seconds: 4.03\n",
      "Epoch  41/100 Batch  740/1562 - Loss:  0.224, Seconds: 3.79\n",
      "Epoch  41/100 Batch  760/1562 - Loss:  0.242, Seconds: 3.00\n",
      "Epoch  41/100 Batch  780/1562 - Loss:  0.225, Seconds: 4.19\n",
      "Epoch  41/100 Batch  800/1562 - Loss:  0.213, Seconds: 3.47\n",
      "Epoch  41/100 Batch  820/1562 - Loss:  0.200, Seconds: 4.28\n",
      "Epoch  41/100 Batch  840/1562 - Loss:  0.220, Seconds: 3.63\n",
      "Epoch  41/100 Batch  860/1562 - Loss:  0.206, Seconds: 3.60\n",
      "Epoch  41/100 Batch  880/1562 - Loss:  0.183, Seconds: 3.21\n",
      "Epoch  41/100 Batch  900/1562 - Loss:  0.201, Seconds: 4.06\n",
      "Epoch  41/100 Batch  920/1562 - Loss:  0.228, Seconds: 3.45\n",
      "Average loss for this update: 0.213 -- New Record!\n",
      "Epoch  41/100 Batch  940/1562 - Loss:  0.188, Seconds: 3.17\n",
      "Epoch  41/100 Batch  960/1562 - Loss:  0.208, Seconds: 3.80\n",
      "Epoch  41/100 Batch  980/1562 - Loss:  0.215, Seconds: 3.81\n",
      "Epoch  41/100 Batch 1000/1562 - Loss:  0.231, Seconds: 3.58\n",
      "Epoch  41/100 Batch 1020/1562 - Loss:  0.230, Seconds: 3.17\n",
      "Epoch  41/100 Batch 1040/1562 - Loss:  0.241, Seconds: 3.60\n",
      "Epoch  41/100 Batch 1060/1562 - Loss:  0.216, Seconds: 3.42\n",
      "Epoch  41/100 Batch 1080/1562 - Loss:  0.230, Seconds: 4.24\n",
      "Epoch  41/100 Batch 1100/1562 - Loss:  0.260, Seconds: 3.22\n",
      "Epoch  41/100 Batch 1120/1562 - Loss:  0.231, Seconds: 3.57\n",
      "Epoch  41/100 Batch 1140/1562 - Loss:  0.213, Seconds: 3.64\n",
      "Epoch  41/100 Batch 1160/1562 - Loss:  0.197, Seconds: 3.40\n",
      "Epoch  41/100 Batch 1180/1562 - Loss:  0.195, Seconds: 3.08\n",
      "Epoch  41/100 Batch 1200/1562 - Loss:  0.244, Seconds: 4.15\n",
      "Epoch  41/100 Batch 1220/1562 - Loss:  0.210, Seconds: 3.45\n",
      "Epoch  41/100 Batch 1240/1562 - Loss:  0.177, Seconds: 3.58\n",
      "Average loss for this update: 0.219-- No Improvement.\n",
      "Epoch  41/100 Batch 1260/1562 - Loss:  0.237, Seconds: 3.50\n",
      "Epoch  41/100 Batch 1280/1562 - Loss:  0.241, Seconds: 3.93\n",
      "Epoch  41/100 Batch 1300/1562 - Loss:  0.243, Seconds: 3.31\n",
      "Epoch  41/100 Batch 1320/1562 - Loss:  0.245, Seconds: 3.95\n",
      "Epoch  41/100 Batch 1340/1562 - Loss:  0.200, Seconds: 3.51\n",
      "Epoch  41/100 Batch 1360/1562 - Loss:  0.226, Seconds: 3.74\n",
      "Epoch  41/100 Batch 1380/1562 - Loss:  0.243, Seconds: 3.93\n",
      "Epoch  41/100 Batch 1400/1562 - Loss:  0.209, Seconds: 3.87\n",
      "Epoch  41/100 Batch 1420/1562 - Loss:  0.174, Seconds: 3.27\n",
      "Epoch  41/100 Batch 1440/1562 - Loss:  0.207, Seconds: 3.76\n",
      "Epoch  41/100 Batch 1460/1562 - Loss:  0.214, Seconds: 3.89\n",
      "Epoch  41/100 Batch 1480/1562 - Loss:  0.208, Seconds: 3.86\n",
      "Epoch  41/100 Batch 1500/1562 - Loss:  0.220, Seconds: 3.73\n",
      "Epoch  41/100 Batch 1520/1562 - Loss:  0.267, Seconds: 4.44\n",
      "Epoch  41/100 Batch 1540/1562 - Loss:  0.326, Seconds: 3.81\n",
      "Average loss for this update: 0.234-- No Improvement.\n",
      "Epoch  41/100 Batch 1560/1562 - Loss:  0.312, Seconds: 3.94\n",
      "Epoch  42/100 Batch   20/1562 - Loss:  0.276, Seconds: 4.04\n",
      "Epoch  42/100 Batch   40/1562 - Loss:  0.236, Seconds: 3.50\n",
      "Epoch  42/100 Batch   60/1562 - Loss:  0.276, Seconds: 3.11\n",
      "Epoch  42/100 Batch   80/1562 - Loss:  0.242, Seconds: 2.90\n",
      "Epoch  42/100 Batch  100/1562 - Loss:  0.218, Seconds: 3.55\n",
      "Epoch  42/100 Batch  120/1562 - Loss:  0.214, Seconds: 3.15\n",
      "Epoch  42/100 Batch  140/1562 - Loss:  0.234, Seconds: 3.31\n",
      "Epoch  42/100 Batch  160/1562 - Loss:  0.219, Seconds: 2.89\n",
      "Epoch  42/100 Batch  180/1562 - Loss:  0.229, Seconds: 3.67\n",
      "Epoch  42/100 Batch  200/1562 - Loss:  0.192, Seconds: 3.17\n",
      "Epoch  42/100 Batch  220/1562 - Loss:  0.204, Seconds: 3.08\n",
      "Epoch  42/100 Batch  240/1562 - Loss:  0.199, Seconds: 2.89\n",
      "Epoch  42/100 Batch  260/1562 - Loss:  0.227, Seconds: 4.15\n",
      "Epoch  42/100 Batch  280/1562 - Loss:  0.198, Seconds: 3.27\n",
      "Epoch  42/100 Batch  300/1562 - Loss:  0.192, Seconds: 4.10\n",
      "Average loss for this update: 0.222-- No Improvement.\n",
      "Epoch  42/100 Batch  320/1562 - Loss:  0.188, Seconds: 3.52\n",
      "Epoch  42/100 Batch  340/1562 - Loss:  0.210, Seconds: 3.33\n",
      "Epoch  42/100 Batch  360/1562 - Loss:  0.208, Seconds: 3.87\n",
      "Epoch  42/100 Batch  380/1562 - Loss:  0.201, Seconds: 2.90\n",
      "Epoch  42/100 Batch  400/1562 - Loss:  0.190, Seconds: 4.15\n",
      "Epoch  42/100 Batch  420/1562 - Loss:  0.203, Seconds: 3.63\n",
      "Epoch  42/100 Batch  440/1562 - Loss:  0.228, Seconds: 3.38\n",
      "Epoch  42/100 Batch  460/1562 - Loss:  0.218, Seconds: 3.24\n",
      "Epoch  42/100 Batch  480/1562 - Loss:  0.195, Seconds: 3.56\n",
      "Epoch  42/100 Batch  500/1562 - Loss:  0.215, Seconds: 3.77\n",
      "Epoch  42/100 Batch  520/1562 - Loss:  0.185, Seconds: 4.17\n",
      "Epoch  42/100 Batch  540/1562 - Loss:  0.223, Seconds: 3.17\n",
      "Epoch  42/100 Batch  560/1562 - Loss:  0.207, Seconds: 3.54\n",
      "Epoch  42/100 Batch  580/1562 - Loss:  0.187, Seconds: 3.70\n",
      "Epoch  42/100 Batch  600/1562 - Loss:  0.167, Seconds: 3.36\n",
      "Epoch  42/100 Batch  620/1562 - Loss:  0.201, Seconds: 3.73\n",
      "Average loss for this update: 0.202 -- New Record!\n",
      "Epoch  42/100 Batch  640/1562 - Loss:  0.209, Seconds: 3.36\n",
      "Epoch  42/100 Batch  660/1562 - Loss:  0.204, Seconds: 3.55\n",
      "Epoch  42/100 Batch  680/1562 - Loss:  0.184, Seconds: 4.07\n",
      "Epoch  42/100 Batch  700/1562 - Loss:  0.205, Seconds: 3.16\n",
      "Epoch  42/100 Batch  720/1562 - Loss:  0.213, Seconds: 4.02\n",
      "Epoch  42/100 Batch  740/1562 - Loss:  0.234, Seconds: 3.82\n",
      "Epoch  42/100 Batch  760/1562 - Loss:  0.232, Seconds: 3.02\n",
      "Epoch  42/100 Batch  780/1562 - Loss:  0.224, Seconds: 4.32\n",
      "Epoch  42/100 Batch  800/1562 - Loss:  0.217, Seconds: 3.43\n",
      "Epoch  42/100 Batch  820/1562 - Loss:  0.192, Seconds: 3.80\n",
      "Epoch  42/100 Batch  840/1562 - Loss:  0.213, Seconds: 3.61\n",
      "Epoch  42/100 Batch  860/1562 - Loss:  0.201, Seconds: 3.66\n",
      "Epoch  42/100 Batch  880/1562 - Loss:  0.169, Seconds: 3.21\n",
      "Epoch  42/100 Batch  900/1562 - Loss:  0.203, Seconds: 4.02\n",
      "Epoch  42/100 Batch  920/1562 - Loss:  0.216, Seconds: 3.36\n",
      "Average loss for this update: 0.206-- No Improvement.\n",
      "Epoch  42/100 Batch  940/1562 - Loss:  0.173, Seconds: 3.16\n",
      "Epoch  42/100 Batch  960/1562 - Loss:  0.193, Seconds: 3.81\n",
      "Epoch  42/100 Batch  980/1562 - Loss:  0.204, Seconds: 3.78\n",
      "Epoch  42/100 Batch 1000/1562 - Loss:  0.214, Seconds: 3.70\n",
      "Epoch  42/100 Batch 1020/1562 - Loss:  0.219, Seconds: 3.25\n",
      "Epoch  42/100 Batch 1040/1562 - Loss:  0.214, Seconds: 3.68\n",
      "Epoch  42/100 Batch 1060/1562 - Loss:  0.217, Seconds: 3.45\n",
      "Epoch  42/100 Batch 1080/1562 - Loss:  0.216, Seconds: 4.24\n",
      "Epoch  42/100 Batch 1100/1562 - Loss:  0.258, Seconds: 3.24\n",
      "Epoch  42/100 Batch 1120/1562 - Loss:  0.223, Seconds: 3.61\n",
      "Epoch  42/100 Batch 1140/1562 - Loss:  0.199, Seconds: 3.71\n",
      "Epoch  42/100 Batch 1160/1562 - Loss:  0.195, Seconds: 3.45\n",
      "Epoch  42/100 Batch 1180/1562 - Loss:  0.193, Seconds: 3.14\n",
      "Epoch  42/100 Batch 1200/1562 - Loss:  0.232, Seconds: 4.21\n",
      "Epoch  42/100 Batch 1220/1562 - Loss:  0.202, Seconds: 3.41\n",
      "Epoch  42/100 Batch 1240/1562 - Loss:  0.164, Seconds: 3.68\n",
      "Average loss for this update: 0.209-- No Improvement.\n",
      "Epoch  42/100 Batch 1260/1562 - Loss:  0.211, Seconds: 3.46\n",
      "Epoch  42/100 Batch 1280/1562 - Loss:  0.221, Seconds: 3.89\n",
      "Epoch  42/100 Batch 1300/1562 - Loss:  0.226, Seconds: 3.33\n",
      "Epoch  42/100 Batch 1320/1562 - Loss:  0.241, Seconds: 3.91\n",
      "Epoch  42/100 Batch 1340/1562 - Loss:  0.217, Seconds: 3.46\n",
      "Epoch  42/100 Batch 1360/1562 - Loss:  0.224, Seconds: 3.72\n",
      "Epoch  42/100 Batch 1380/1562 - Loss:  0.230, Seconds: 3.93\n",
      "Epoch  42/100 Batch 1400/1562 - Loss:  0.198, Seconds: 3.93\n",
      "Epoch  42/100 Batch 1420/1562 - Loss:  0.176, Seconds: 3.28\n",
      "Epoch  42/100 Batch 1440/1562 - Loss:  0.194, Seconds: 3.79\n",
      "Epoch  42/100 Batch 1460/1562 - Loss:  0.192, Seconds: 3.89\n",
      "Epoch  42/100 Batch 1480/1562 - Loss:  0.192, Seconds: 4.03\n",
      "Epoch  42/100 Batch 1500/1562 - Loss:  0.203, Seconds: 3.71\n",
      "Epoch  42/100 Batch 1520/1562 - Loss:  0.238, Seconds: 4.39\n",
      "Epoch  42/100 Batch 1540/1562 - Loss:  0.285, Seconds: 3.77\n",
      "Average loss for this update: 0.22-- No Improvement.\n",
      "Epoch  42/100 Batch 1560/1562 - Loss:  0.284, Seconds: 3.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  43/100 Batch   20/1562 - Loss:  0.243, Seconds: 3.80\n",
      "Epoch  43/100 Batch   40/1562 - Loss:  0.247, Seconds: 3.49\n",
      "Epoch  43/100 Batch   60/1562 - Loss:  0.274, Seconds: 3.08\n",
      "Epoch  43/100 Batch   80/1562 - Loss:  0.229, Seconds: 2.84\n",
      "Epoch  43/100 Batch  100/1562 - Loss:  0.212, Seconds: 3.52\n",
      "Epoch  43/100 Batch  120/1562 - Loss:  0.199, Seconds: 3.07\n",
      "Epoch  43/100 Batch  140/1562 - Loss:  0.226, Seconds: 3.23\n",
      "Epoch  43/100 Batch  160/1562 - Loss:  0.200, Seconds: 2.84\n",
      "Epoch  43/100 Batch  180/1562 - Loss:  0.214, Seconds: 3.71\n",
      "Epoch  43/100 Batch  200/1562 - Loss:  0.192, Seconds: 3.12\n",
      "Epoch  43/100 Batch  220/1562 - Loss:  0.214, Seconds: 3.11\n",
      "Epoch  43/100 Batch  240/1562 - Loss:  0.195, Seconds: 2.87\n",
      "Epoch  43/100 Batch  260/1562 - Loss:  0.214, Seconds: 4.10\n",
      "Epoch  43/100 Batch  280/1562 - Loss:  0.191, Seconds: 3.39\n",
      "Epoch  43/100 Batch  300/1562 - Loss:  0.181, Seconds: 4.11\n",
      "Average loss for this update: 0.214-- No Improvement.\n",
      "Epoch  43/100 Batch  320/1562 - Loss:  0.191, Seconds: 3.78\n",
      "Epoch  43/100 Batch  340/1562 - Loss:  0.190, Seconds: 3.32\n",
      "Epoch  43/100 Batch  360/1562 - Loss:  0.213, Seconds: 3.96\n",
      "Epoch  43/100 Batch  380/1562 - Loss:  0.184, Seconds: 2.91\n",
      "Epoch  43/100 Batch  400/1562 - Loss:  0.191, Seconds: 4.17\n",
      "Epoch  43/100 Batch  420/1562 - Loss:  0.201, Seconds: 3.53\n",
      "Epoch  43/100 Batch  440/1562 - Loss:  0.216, Seconds: 3.32\n",
      "Epoch  43/100 Batch  460/1562 - Loss:  0.214, Seconds: 3.16\n",
      "Epoch  43/100 Batch  480/1562 - Loss:  0.186, Seconds: 3.60\n",
      "Epoch  43/100 Batch  500/1562 - Loss:  0.204, Seconds: 3.78\n",
      "Epoch  43/100 Batch  520/1562 - Loss:  0.190, Seconds: 4.18\n",
      "Epoch  43/100 Batch  540/1562 - Loss:  0.220, Seconds: 3.23\n",
      "Epoch  43/100 Batch  560/1562 - Loss:  0.198, Seconds: 3.56\n",
      "Epoch  43/100 Batch  580/1562 - Loss:  0.186, Seconds: 3.53\n",
      "Epoch  43/100 Batch  600/1562 - Loss:  0.156, Seconds: 3.50\n",
      "Epoch  43/100 Batch  620/1562 - Loss:  0.206, Seconds: 3.78\n",
      "Average loss for this update: 0.197 -- New Record!\n",
      "Epoch  43/100 Batch  640/1562 - Loss:  0.212, Seconds: 3.36\n",
      "Epoch  43/100 Batch  660/1562 - Loss:  0.195, Seconds: 3.56\n",
      "Epoch  43/100 Batch  680/1562 - Loss:  0.179, Seconds: 4.24\n",
      "Epoch  43/100 Batch  700/1562 - Loss:  0.189, Seconds: 3.18\n",
      "Epoch  43/100 Batch  720/1562 - Loss:  0.223, Seconds: 4.01\n",
      "Epoch  43/100 Batch  740/1562 - Loss:  0.238, Seconds: 3.74\n",
      "Epoch  43/100 Batch  760/1562 - Loss:  0.211, Seconds: 3.00\n",
      "Epoch  43/100 Batch  780/1562 - Loss:  0.211, Seconds: 4.15\n",
      "Epoch  43/100 Batch  800/1562 - Loss:  0.199, Seconds: 3.35\n",
      "Epoch  43/100 Batch  820/1562 - Loss:  0.184, Seconds: 3.86\n",
      "Epoch  43/100 Batch  840/1562 - Loss:  0.227, Seconds: 3.60\n",
      "Epoch  43/100 Batch  860/1562 - Loss:  0.195, Seconds: 3.60\n",
      "Epoch  43/100 Batch  880/1562 - Loss:  0.157, Seconds: 3.21\n",
      "Epoch  43/100 Batch  900/1562 - Loss:  0.205, Seconds: 4.02\n",
      "Epoch  43/100 Batch  920/1562 - Loss:  0.208, Seconds: 3.46\n",
      "Average loss for this update: 0.201-- No Improvement.\n",
      "Epoch  43/100 Batch  940/1562 - Loss:  0.178, Seconds: 3.12\n",
      "Epoch  43/100 Batch  960/1562 - Loss:  0.188, Seconds: 3.76\n",
      "Epoch  43/100 Batch  980/1562 - Loss:  0.198, Seconds: 3.88\n",
      "Epoch  43/100 Batch 1000/1562 - Loss:  0.216, Seconds: 3.77\n",
      "Epoch  43/100 Batch 1020/1562 - Loss:  0.218, Seconds: 3.27\n",
      "Epoch  43/100 Batch 1040/1562 - Loss:  0.216, Seconds: 3.63\n",
      "Epoch  43/100 Batch 1060/1562 - Loss:  0.199, Seconds: 3.48\n",
      "Epoch  43/100 Batch 1080/1562 - Loss:  0.213, Seconds: 4.37\n",
      "Epoch  43/100 Batch 1100/1562 - Loss:  0.229, Seconds: 3.22\n",
      "Epoch  43/100 Batch 1120/1562 - Loss:  0.218, Seconds: 3.70\n",
      "Epoch  43/100 Batch 1140/1562 - Loss:  0.192, Seconds: 3.77\n",
      "Epoch  43/100 Batch 1160/1562 - Loss:  0.190, Seconds: 3.42\n",
      "Epoch  43/100 Batch 1180/1562 - Loss:  0.185, Seconds: 2.99\n",
      "Epoch  43/100 Batch 1200/1562 - Loss:  0.225, Seconds: 4.03\n",
      "Epoch  43/100 Batch 1220/1562 - Loss:  0.202, Seconds: 3.48\n",
      "Epoch  43/100 Batch 1240/1562 - Loss:  0.173, Seconds: 3.64\n",
      "Average loss for this update: 0.204-- No Improvement.\n",
      "Epoch  43/100 Batch 1260/1562 - Loss:  0.222, Seconds: 3.49\n",
      "Epoch  43/100 Batch 1280/1562 - Loss:  0.213, Seconds: 3.98\n",
      "Epoch  43/100 Batch 1300/1562 - Loss:  0.213, Seconds: 3.28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-341668ae1d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                       \u001b[0mbase_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                       \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_BI_ATTN_CHECKPOINTDIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                       losses_arr_path=LSTM_BI_ATTN_LOSSES_PATH)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ATTA/deepproj/tensorflow_code.py\u001b[0m in \u001b[0;36mbuild_and_train_model\u001b[0;34m(word_embedding_matrix, rnn_size, num_layers, keep_probability, vocab_to_int, batch_size, sorted_summaries, sorted_reviews, encoder_style, attention, base_cell, checkpoint_file, losses_arr_path)\u001b[0m\n\u001b[1;32m    409\u001b[0m                      keep_probability: keep_prob})\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m                 \u001b[0mupdate_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "\n",
    "# Hyperparameters\n",
    "#epochs = 10\n",
    "rnn_size = 256\n",
    "batch_size = 32\n",
    "num_layers = 2\n",
    "lr = 0.001\n",
    "keep_prob = 0.75\n",
    "\n",
    "LSTM_BI_ATTN_CHECKPOINTDIR = './model_checkpoints/LSTM_BI_ATTN/best_model.ckpt'\n",
    "LSTM_BI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/LSTM_BI_ATTN_LOSS_ARR.p'\n",
    "\n",
    "''' \n",
    "    ENCODER STYLE:    BIDIRECTIONAL\n",
    "    LSTM CELL STYLE:  LSTMCell\n",
    "    ATTENTION:        TRUE\n",
    "'''\n",
    "print(\"\\n#######\\nTraining Bidirectional / LSTMCell / Attention\\n#######\")\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "tc.build_and_train_model(cl.word_embedding_matrix, \n",
    "                      rnn_size,\n",
    "                      num_layers,\n",
    "                      keep_prob,\n",
    "                      cl.vocab_to_int,\n",
    "                      batch_size,\n",
    "                      cl.sorted_summaries,\n",
    "                      cl.sorted_texts,\n",
    "                      encoder_style='bidirectional_rnn',\n",
    "                      attention=True,\n",
    "                      base_cell='LSTM',\n",
    "                      checkpoint_file=LSTM_BI_ATTN_CHECKPOINTDIR,\n",
    "                      losses_arr_path=LSTM_BI_ATTN_LOSSES_PATH)\n",
    "\n",
    "end_time=time.time()\n",
    "print (\"Total time taken for training is =  \",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
